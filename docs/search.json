[
  {
    "objectID": "secondary/code-and-data.html",
    "href": "secondary/code-and-data.html",
    "title": "Code and Data",
    "section": "",
    "text": "All the code used in this project is available on Github.\n\n\n\nThis project uses the Baumgartner et al. (2020) dataset. The columns available are listed below. Definitions were sourced from Baumgartner et al. (2020) and The Reddit Archives (2016).\n\n\n\n\n\n\n\n\n\n\n\nField\nType\nDescription\n\n\n\n\nadserver_click_url\n\n\n\n\nadserver_imp_pixel\n\n\n\n\narchived\n\n\n\n\nauthor\nString\nThe account name of the poster, e.g., “example username”\n\n\nauthor_cakeday\n\n\n\n\nauthor_flair_css_class\nString\nThe CSS class of the author’s flair. This field is specific to subreddit\n\n\nauthor_flair_text\nString\nThe text of the author’s flair. This field is specific to subreddit\n\n\nauthor_id\n\n\n\n\nbrand_safe\n\n\n\n\ncontest_mode\n\n\n\n\ncreated_utc\nInteger\nUNIX timestamp referring to the time of the submission’s creation, e.g., 1483228803\n\n\ncrosspost_parent\n\n\n\n\ncrosspost_parent_list\n\n\n\n\ndisable_comments\n\n\n\n\ndistinguished\nString\nFlag to determine whether the submission is distinguished2 by moderators. “null” means not distinguished\n\n\ndomain\nString\nThe domain of the submission, e.g., self.AskReddit\n\n\ndomain_override\n\n\n\n\nedited\nLong\nIndicates whether the submission has been edited. Either a number indicating the UNIX timestamp that the submission was edited at, “false” otherwise.\n\n\nembed_type\n\n\n\n\nembed_url\n\n\n\n\ngilded\nInteger\nThe number of times this submission received Reddit gold, e.g., 0\n\n\nhidden\nBoolean\ntrue if the post is hidden by the logged in user. false if not logged in or not hidden.\n\n\nhide_score\nBoolean\nFlag indicating if the submission’s score is hidden, e.g., false\n\n\nhref_url\n\n\n\n\nid\nString\nThe submission’s identifier, e.g., “5lcgjh”\n\n\nimp_pixel\n\n\n\n\nis_crosspostable\n\n\n\n\nis_reddit_media_domain\n\n\n\n\nis_self\nBoolean\nFlag that indicates whether the submission is a self post, e.g., true\n\n\nis_video\n\n\n\n\nlink_flair_css_class\nString\nthe CSS class of the link’s flair.\n\n\nlink_flair_text\nString\nthe text of the link’s flair.\n\n\nlocked\nBoolean\nFlag indicating whether the submission is currently closed to new comments, e.g., false\n\n\nmedia\nObject\nUsed for streaming video. Detailed information about the video and it’s origins are placed here\n\n\nmedia_embed\nObject\nUsed for streaming video. Technical embed specific information is found here.\n\n\nmobile_ad_url\n\n\n\n\nnum_comments\nInteger\nThe number of comments associated with this submission, e.g., 7\n\n\nnum_crossposts\n\n\n\n\noriginal_link\n\n\n\n\nover_18\nBoolean\nFlag that indicates whether the submission is Not-Safe-For-Work, e.g., false\n\n\nparent_whitelist_status\n\n\n\n\npermalink\nString\nRelative URL of the permanent link that points to this specific submission, e.g., “/r/AskReddit/comments/5lcgj9/what did you think of the ending of rogue one/”\n\n\npinned\n\n\n\n\npost_hint\n\n\n\n\npreview\n\n\n\n\npromoted\n\n\n\n\npromoted_by\n\n\n\n\npromoted_display_name\n\n\n\n\npromoted_url\n\n\n\n\nretrieved_on\nInteger\nUNIX timestamp referring to the time we crawled the submission, e.g., 1483228803\n\n\nscore\nInteger\nThe score that the submission has accumulated. The score is the number of upvotes minus the number of downvotes. E.g., 5 . NB: Reddit fuzzes the real score to prevent spam bots.\n\n\nsecure_media\n\n\n\n\nsecure_media_embed\n\n\n\n\nselftext\nString\nThe text that is associated with the submission\n\n\nspoiler\n\n\n\n\nstickied\nBoolean\nFlag indicating whether the submission is set as sticky in the subreddit, e.g., false\n\n\nsubreddit\nString\nName of the subreddit that the submission is posted. Note that it excludes the prefix /r/. E.g., ’AskReddit’\n\n\nsubreddit_id\nString\nThe identifier of the subreddit, e.g., “t5 2qh1i”\n\n\nsuggested_sort\n\n\n\n\nthird_party_trackers\n\n\n\n\nthird_party_tracking\n\n\n\n\nthird_party_tracking_2\n\n\n\n\nthumbnail\nString\nfull URL to the thumbnail for this link; “self” if this is a self post; “image” if this is a link to an image but has no thumbnail; “default” if a thumbnail is not available\n\n\nthumbnail_height\n\n\n\n\nthumbnail_width\n\n\n\n\ntitle\nString\nThe title that is associated with the submission, e.g., “What did you think of the ending of Rogue One?”\n\n\nurl\nString\nThe URL that the submission is posting. This is the same with the permalink in cases where the submission is a self post. E.g., “https://www.reddit.com/r/AskReddit/\n\n\nwhitelist_status\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nField\nType\nDescription\n\n\n\n\nauthor\nString\nThe account name of the poster, e.g., “example username”\n\n\nauthor_cakeday\n\n\n\n\nauthor_flair_css_class\nString\nThe CSS class of the author’s flair. This field is specific to subreddit\n\n\nauthor_flair_text\nString\nThe text of the author’s flair. This field is specific to subreddit\n\n\nbody\nString\nThe comment’s text, e.g., “This is an example comment”\n\n\ncan_gild\n\n\n\n\ncontroversiality\nInteger\nNumber that indicates whether the comment is controversial, e.g., 0\n\n\ncreated_utc\nInteger\nUNIX timestamp referring to the time of the submission’s creation, e.g., 1483228803\n\n\ndistinguished\nString\nFlag to determine whether the comment is distinguished by the moderators. “null” meansnot distinguished\n\n\nedited\nLong\nFlag indicating if the comment has been edited. Either the UNIX timestamp that the commentwas edited at, or “false”.\n\n\ngilded\nInteger\nThe number of times this comment received Reddit gold, e.g., 0\n\n\nid\nString\nThe comment’s identifier, e.g., “dbumnq8”\n\n\nis_submitter\n\n\n\n\nlink_id\nString\nIdentifier of the submission that this comment is in, e.g., “t3 5l954r”\n\n\nparent_id\nString\nIdentifier of the parent of this comment, might be the identifier of the submission if it is top-levelcomment or the identifier of another comment, e.g., “t1 dbu5bpp”\n\n\npermalink\nString\nRelative URL of the permanent link that points to this specific submission,e.g., “/r/AskReddit/comments/5lcgj9/what did you think of the ending of rogue one/”\n\n\nretrieved_on\nInteger\nUNIX timestamp that refers to the time that we crawled the comment, e.g., 1483228803\n\n\nscore\nInteger\nThe score of the comment. The score is the number of upvotes minus the number ofdownvotes. Note that Reddit fuzzes the real score to prevent spam bots. E.g., 5\n\n\nstickied\nBoolean\nFlag indicating whether the submission is set as sticky in the subreddit, e.g., false\n\n\nsubreddit\nString\nName of the subreddit that the comment is posted. Note that it excludes the prefix /r/. E.g., ’AskReddit’\n\n\nsubreddit_id\nString\nThe identifier of the subreddit where the comment is posted, e.g., “t5 2qh1i”"
  },
  {
    "objectID": "secondary/code-and-data.html#code",
    "href": "secondary/code-and-data.html#code",
    "title": "Code and Data",
    "section": "",
    "text": "All the code used in this project is available on Github."
  },
  {
    "objectID": "secondary/code-and-data.html#data",
    "href": "secondary/code-and-data.html#data",
    "title": "Code and Data",
    "section": "",
    "text": "This project uses the Baumgartner et al. (2020) dataset. The columns available are listed below. Definitions were sourced from Baumgartner et al. (2020) and The Reddit Archives (2016)."
  },
  {
    "objectID": "secondary/code-and-data.html#submissions-data-card",
    "href": "secondary/code-and-data.html#submissions-data-card",
    "title": "Code and Data",
    "section": "",
    "text": "Field\nType\nDescription\n\n\n\n\nadserver_click_url\n\n\n\n\nadserver_imp_pixel\n\n\n\n\narchived\n\n\n\n\nauthor\nString\nThe account name of the poster, e.g., “example username”\n\n\nauthor_cakeday\n\n\n\n\nauthor_flair_css_class\nString\nThe CSS class of the author’s flair. This field is specific to subreddit\n\n\nauthor_flair_text\nString\nThe text of the author’s flair. This field is specific to subreddit\n\n\nauthor_id\n\n\n\n\nbrand_safe\n\n\n\n\ncontest_mode\n\n\n\n\ncreated_utc\nInteger\nUNIX timestamp referring to the time of the submission’s creation, e.g., 1483228803\n\n\ncrosspost_parent\n\n\n\n\ncrosspost_parent_list\n\n\n\n\ndisable_comments\n\n\n\n\ndistinguished\nString\nFlag to determine whether the submission is distinguished2 by moderators. “null” means not distinguished\n\n\ndomain\nString\nThe domain of the submission, e.g., self.AskReddit\n\n\ndomain_override\n\n\n\n\nedited\nLong\nIndicates whether the submission has been edited. Either a number indicating the UNIX timestamp that the submission was edited at, “false” otherwise.\n\n\nembed_type\n\n\n\n\nembed_url\n\n\n\n\ngilded\nInteger\nThe number of times this submission received Reddit gold, e.g., 0\n\n\nhidden\nBoolean\ntrue if the post is hidden by the logged in user. false if not logged in or not hidden.\n\n\nhide_score\nBoolean\nFlag indicating if the submission’s score is hidden, e.g., false\n\n\nhref_url\n\n\n\n\nid\nString\nThe submission’s identifier, e.g., “5lcgjh”\n\n\nimp_pixel\n\n\n\n\nis_crosspostable\n\n\n\n\nis_reddit_media_domain\n\n\n\n\nis_self\nBoolean\nFlag that indicates whether the submission is a self post, e.g., true\n\n\nis_video\n\n\n\n\nlink_flair_css_class\nString\nthe CSS class of the link’s flair.\n\n\nlink_flair_text\nString\nthe text of the link’s flair.\n\n\nlocked\nBoolean\nFlag indicating whether the submission is currently closed to new comments, e.g., false\n\n\nmedia\nObject\nUsed for streaming video. Detailed information about the video and it’s origins are placed here\n\n\nmedia_embed\nObject\nUsed for streaming video. Technical embed specific information is found here.\n\n\nmobile_ad_url\n\n\n\n\nnum_comments\nInteger\nThe number of comments associated with this submission, e.g., 7\n\n\nnum_crossposts\n\n\n\n\noriginal_link\n\n\n\n\nover_18\nBoolean\nFlag that indicates whether the submission is Not-Safe-For-Work, e.g., false\n\n\nparent_whitelist_status\n\n\n\n\npermalink\nString\nRelative URL of the permanent link that points to this specific submission, e.g., “/r/AskReddit/comments/5lcgj9/what did you think of the ending of rogue one/”\n\n\npinned\n\n\n\n\npost_hint\n\n\n\n\npreview\n\n\n\n\npromoted\n\n\n\n\npromoted_by\n\n\n\n\npromoted_display_name\n\n\n\n\npromoted_url\n\n\n\n\nretrieved_on\nInteger\nUNIX timestamp referring to the time we crawled the submission, e.g., 1483228803\n\n\nscore\nInteger\nThe score that the submission has accumulated. The score is the number of upvotes minus the number of downvotes. E.g., 5 . NB: Reddit fuzzes the real score to prevent spam bots.\n\n\nsecure_media\n\n\n\n\nsecure_media_embed\n\n\n\n\nselftext\nString\nThe text that is associated with the submission\n\n\nspoiler\n\n\n\n\nstickied\nBoolean\nFlag indicating whether the submission is set as sticky in the subreddit, e.g., false\n\n\nsubreddit\nString\nName of the subreddit that the submission is posted. Note that it excludes the prefix /r/. E.g., ’AskReddit’\n\n\nsubreddit_id\nString\nThe identifier of the subreddit, e.g., “t5 2qh1i”\n\n\nsuggested_sort\n\n\n\n\nthird_party_trackers\n\n\n\n\nthird_party_tracking\n\n\n\n\nthird_party_tracking_2\n\n\n\n\nthumbnail\nString\nfull URL to the thumbnail for this link; “self” if this is a self post; “image” if this is a link to an image but has no thumbnail; “default” if a thumbnail is not available\n\n\nthumbnail_height\n\n\n\n\nthumbnail_width\n\n\n\n\ntitle\nString\nThe title that is associated with the submission, e.g., “What did you think of the ending of Rogue One?”\n\n\nurl\nString\nThe URL that the submission is posting. This is the same with the permalink in cases where the submission is a self post. E.g., “https://www.reddit.com/r/AskReddit/\n\n\nwhitelist_status"
  },
  {
    "objectID": "secondary/code-and-data.html#comments-data-card",
    "href": "secondary/code-and-data.html#comments-data-card",
    "title": "Code and Data",
    "section": "",
    "text": "Field\nType\nDescription\n\n\n\n\nauthor\nString\nThe account name of the poster, e.g., “example username”\n\n\nauthor_cakeday\n\n\n\n\nauthor_flair_css_class\nString\nThe CSS class of the author’s flair. This field is specific to subreddit\n\n\nauthor_flair_text\nString\nThe text of the author’s flair. This field is specific to subreddit\n\n\nbody\nString\nThe comment’s text, e.g., “This is an example comment”\n\n\ncan_gild\n\n\n\n\ncontroversiality\nInteger\nNumber that indicates whether the comment is controversial, e.g., 0\n\n\ncreated_utc\nInteger\nUNIX timestamp referring to the time of the submission’s creation, e.g., 1483228803\n\n\ndistinguished\nString\nFlag to determine whether the comment is distinguished by the moderators. “null” meansnot distinguished\n\n\nedited\nLong\nFlag indicating if the comment has been edited. Either the UNIX timestamp that the commentwas edited at, or “false”.\n\n\ngilded\nInteger\nThe number of times this comment received Reddit gold, e.g., 0\n\n\nid\nString\nThe comment’s identifier, e.g., “dbumnq8”\n\n\nis_submitter\n\n\n\n\nlink_id\nString\nIdentifier of the submission that this comment is in, e.g., “t3 5l954r”\n\n\nparent_id\nString\nIdentifier of the parent of this comment, might be the identifier of the submission if it is top-levelcomment or the identifier of another comment, e.g., “t1 dbu5bpp”\n\n\npermalink\nString\nRelative URL of the permanent link that points to this specific submission,e.g., “/r/AskReddit/comments/5lcgj9/what did you think of the ending of rogue one/”\n\n\nretrieved_on\nInteger\nUNIX timestamp that refers to the time that we crawled the comment, e.g., 1483228803\n\n\nscore\nInteger\nThe score of the comment. The score is the number of upvotes minus the number ofdownvotes. Note that Reddit fuzzes the real score to prevent spam bots. E.g., 5\n\n\nstickied\nBoolean\nFlag indicating whether the submission is set as sticky in the subreddit, e.g., false\n\n\nsubreddit\nString\nName of the subreddit that the comment is posted. Note that it excludes the prefix /r/. E.g., ’AskReddit’\n\n\nsubreddit_id\nString\nThe identifier of the subreddit where the comment is posted, e.g., “t5 2qh1i”"
  },
  {
    "objectID": "secondary/authors.html",
    "href": "secondary/authors.html",
    "title": "Authors",
    "section": "",
    "text": "Authors\n\n\n\nAlex Pattarini\n I am a second-year student in Georgetown University’s Data Science and Analytics Accelerated Program after receiving a BA in Government at GU. I am most interested in analyzing geospatial and temporal data. Some of my other interests include sports analytics, history, and programming. amp419@georgetown.edu\n\n\nLandon Carpenter\n I’m currently a second-year student in the Master of Science in the Data Science and Analytics program at Georgetown University. My favorite topics are Natural Language Processing, Computer Vision, and Time-Series Analysis. Outside of my coursework, I enjoy playing soccer and rock climbing. lc1276@georgetown.edu\n\n\n\n\n\n\nMatt Moriarty\n I am currently a second-year student pursuing a Master of Science in Data Science and Analytics at Georgetown University. My main interest involves merging the topics of Time Series and Geographic Information Systems to perform spatio-temporal data analyses. Alongside this, I am very interested in Deep Learning, Data Visualization, and Data Ethics! mdm341@georgetown.edu\n\n\nVictor De Lima\n I am currently a second year student at the MS in Data Science and Analytics program. I am very interested in how machine learning models work. I want to play a part in how these models can be made better and smarter. I am hoping to lay a strong foundation for this during my time at the DSAN program. Some of my other interests are science in general, physics, technology, traveling, and history. I also love programming. vad49@georgetown.edu"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "Summary\nComing soon!"
  },
  {
    "objectID": "nlp.html#processing",
    "href": "nlp.html#processing",
    "title": "NLP",
    "section": "Processing",
    "text": "Processing"
  },
  {
    "objectID": "nlp.html#flair-sentiment-model",
    "href": "nlp.html#flair-sentiment-model",
    "title": "NLP",
    "section": "Flair Sentiment Model",
    "text": "Flair Sentiment Model\nSee in Figure 1.\n\n\n\nFigure 1: Shows the subreddit sentiment by flair.\n\n\nSee in Figure 2.\n\n\n\nFigure 2: Shows the subreddit engagement by flair."
  },
  {
    "objectID": "nlp.html#preparing-reddit-data-for-multi-class-classification",
    "href": "nlp.html#preparing-reddit-data-for-multi-class-classification",
    "title": "NLP",
    "section": "Preparing Reddit data for multi-class classification",
    "text": "Preparing Reddit data for multi-class classification\nSee in Figure 3.\n\n\n\nFigure 3: Shows how age is distributed across sentiment\n\n\nSee in Figure 4.\n\n\n\nFigure 4: Shows how gender is distributed across sentiment\n\n\nSee in Table 1.\n\n\n\n\nTable 1: displays the distribution of sentiment across genders.\n\n\nFemale\nMale\nOther\n\n\n\n\n0.95\n0.95\n0.93\n\n\n0.02\n0.02\n0.02\n\n\n0.03\n0.03\n0.05"
  },
  {
    "objectID": "nlp.html#preparing-reddit-and-external-data-for-training-an-rnn",
    "href": "nlp.html#preparing-reddit-and-external-data-for-training-an-rnn",
    "title": "NLP",
    "section": "Preparing Reddit and External Data for Training an RNN",
    "text": "Preparing Reddit and External Data for Training an RNN\nFor this exercise, we focused on preparing text that contains great storytelling to train a Recurrent Neural Network (RNN) that can generate new stories. We use our 12 months of Reddit submissions data described in the EDA section for the analysis. Additionally, we integrate external data containing the text of famous stories from Project Gutenberg books that have stood the test of time, specifically The Scarlet Letter by Nathaniel Hawthorne, The Odyssey by Homer, Crime and Punishment by Fyodor Dostoyevsky, Metamorphosis by Franz Kafka, and The Great Gatsby by F. Scott Fitzgerald.\nTo prepare the Reddit data, we extracted only the relevant information from the parquets, such as subreddit, title, selftext, score, and URL, and filtered out deleted or empty submissions. To select the best stories, we used a regular expressions pattern to remove any “Edit:” sections to remove post-edit additions that could skew the analysis. Since stories must be at least a few paragraphs, we removed all posts that didn’t have at least 4500 characters (around 750 words). Then, we filtered for only stored with score in the top 85th percentile, thereby focusing on submissions that garnered significant user interaction.\nWe then combined the text sources. The data underwent a series of NLP transformations, including custom tokenization and lowercasing, to prepare it for advanced analysis. We constructed a vocabulary and transformed the individual characters into tokens. The resulting frequency of each token is shown in Figure 5. Lastly, we stored the processed data in a structured Parquet format alongside the character-to-index mappings, crucial for the subsequent machine-learning modeling.\n\n\n\nFigure 5: Shows the count of the Top 10 tokens\n\n\nAs an additionally way to visualize the resulting dataset, we also can see the results of the top 10 N-Grams, where \\(N=5\\) in Table 2.\n\n\n\n\nTable 2: displays the top 10 most frequent N-Grams where \\(N=5\\).\n\n\n5-Gram (incl spaces)\nCount\n\n\n\n\ni was\n22,165\n\n\nand i\n17,933\n\n\nin the\n15,264\n\n\nof the\n13,807\n\n\nthat i\n11,631\n\n\nto be\n10,346\n\n\nit was\n10,172\n\n\nto the\n9,418\n\n\ni had\n8,307\n\n\ni dont\n8,212"
  },
  {
    "objectID": "eda/topics.html",
    "href": "eda/topics.html",
    "title": "Topics",
    "section": "",
    "text": "Topics\nThe questions we will address in this work are:\nIdea 1\n\nBusiness goal: Given a textual post, classify the subreddit to which it belongs.\nTechnical approach: Use NLP techniques to construct a feature set from the textual components of a post. These features may be word “dummy variables” (the existence or non-existence of a word), word counts, n-grams (sequences of n words), or other types of features. Use the newly created features to build a multi-class classification model capable of classifying the subreddit to which a post belongs.\n\nIdea 2\n\nBusiness goal: Given a textual post, predict the age and gender of the author of the post.\nTechnical approach: Use NLP techniques to extract the age and gender of the author of a post, if available (as an example: “My brother (24M) and I (23M) went to the store…”). Use NLP techniques to construct a feature set from the textual components of a post. Again, these features may be word “dummy variables” (the existence or non-existence of a word), word counts, n-grams (sequences of n words), or other types of features. Use the newly created features to build two models: a regression model for predicting the age of the author of the post, and a classification model for classifying the gender of the author of the post.\n\nIdea 3\n\nBusiness goal: Use a pre-trained model to build features surrounding NLP for our ML tasks.\nTechnical approach: Identify available pre-trained models in the realm of NLP and what they are trained to extract from textual data. Use a pre-trained model, or models, to perform NLP tasks for downstream tasks. For instance, use a pre-trained model to obtain word embeddings (vector representations of words) that can be used as features in a subsequent ML model.\n\nIdea 4\n\nBusiness goal: Predict the popularity of text-based submissions based on their text content.\nTechnical approach: Using NLP techniques on the text posts of various similarly sized subreddits (by number of subscribers) that typically contain posts with moderate to high word counts, extract the most pertinent features. Apply supervised machine learning models (e.g., regression) to predict the number of upvotes and/or comments a given text post will receive. Identify the most influential/important words and phrases that predict a post’s popularity and calculate accuracy metrics based on actual post popularity.\n\nIdea 5\n\nBusiness goal: Determine/predict “flairs” of Reddit posts in r/AITA based on their text content.\nTechnical approach: Focusing primarily on the subreddit r/AITA and its flairs (Asshole, Not the A-hole, Everyone Sucks, No A-holes here), apply NLP techniques such as tokenization on text-based submissions to extract the important contents of each post. Apply a multi-class classification model trained on labelled r/AITA posts (i.e., text posts with a flair) to predict which flair a given post will receive based on its text content. Present confusion matrices on testing dataset and identify the words/phrases most commonly associated with each flair type.\n\nIdea 6\n\nBusiness goal: Determine which subreddit posts belong to based on their sentiment.\nTechnical approach: Use NLP techniques to clean content of various text based subreddits. Apply sentiment modeling to these posts. Train a classification model on these posts. Assess accuracy of the model using unlabelled posts (i.e., posts where the subreddit is not identified). Present findings in confusion matrices and calculate various accuracy metrics.\n\nIdea 7\n\nBusiness goal: Evaluate the relationship between the number of comments and the score of Reddit posts to establish an ‘interaction_score’ as an aggregate engagement metric.\nTechnical approach: We plan to analyze the relationship between the number of comments and post scores on social media platforms. This involves collecting data grouped by subreddits or similar categories and using pyspark.sql.functions to calculate the correlation between these two metrics. We will develop an interaction_score metric based on our findings, averaging the number of comments and post scores. This new metric aims to provide a unified measure of user engagement across various posts and platforms.\n\nIdea 8\n\nBusiness goal: Assess the impact of not-safe-for-work (NSFW) content on user engagement.\nTechnical approach: To analyze the influence of NSFW content on user engagement, we will utilize a dataset of submissions, focusing on those marked with the over_18 flag. Considering the limited proportion of such posts, we’ll create a balanced dataset by randomly selecting an equivalent number of submissions without the NSFW tag. This approach ensures a fair comparison between NSFW and non-NSFW content. We will employ the interaction_score from Topic 1 as a primary measure of user engagement. Our methodology includes generating a boxplot to visualize the distribution of interaction scores for both NSFW and non-NSFW posts.\n\nIdea 9\n\nBusiness goal: Identify the times of the day when posts typically receive the most engagement.\nTechnical approach: Implement a data analysis process that focuses on understanding the temporal patterns of user engagement on social media posts. Utilize the created_utc column from the dataset to create two new variables: week_of_the_year and hour_of_the_day. Exclude the first two days of 2022 to maintain accurate weekly categorization, as these days are part of week 53 of 2021. Aggregate and analyze the data based on these new variables to reveal patterns in user engagement across different times of the day and weeks of the year. The outcome will be visualized through a comprehensive plot, illustrating the times when posts receive the most engagement, thus guiding content strategies for optimal post timing.\n\nIdea 10\n\nBusiness goal: Is there any correlation between engagement and how controversial a comment is?\nTechnical approach: Use NLP to determine if a controversial comment is more likely to correlate with different engagement metrics.\n\nIdea 11\n\nBusiness goal: Identify whether current events are shown in different subreddits and their level of engagement.\nTechnical approach: Use NLP to identify current events in different subreddits and their level of engagement.\n\nIdea 12\n\nBusiness goal: Summarise a reddit comment.\nTechnical approach: Use a pretrained machine learning model to summarize the contents within a comment."
  },
  {
    "objectID": "eda/exploratory-analysis.html",
    "href": "eda/exploratory-analysis.html",
    "title": "Exploratory Analysis",
    "section": "",
    "text": "We selected a subset of the data related to subreddits dedicated to storytelling during 2022. Namely, we chose the 12 subreddits AITA, AskMen, AskWomen, TrueOffMyChest, unpopularopinion, tifu, socialskills, antiwork, relationship_advice, explainlikeimfive, OutOfTheLoop, and NoStupidQuestions. The data we acquired has a shape of 3,444,283 x 68 for the submissions table and 76,503,363 x 21 for the comments table."
  },
  {
    "objectID": "eda/exploratory-analysis.html#the-data-subset",
    "href": "eda/exploratory-analysis.html#the-data-subset",
    "title": "Exploratory Analysis",
    "section": "",
    "text": "We selected a subset of the data related to subreddits dedicated to storytelling during 2022. Namely, we chose the 12 subreddits AITA, AskMen, AskWomen, TrueOffMyChest, unpopularopinion, tifu, socialskills, antiwork, relationship_advice, explainlikeimfive, OutOfTheLoop, and NoStupidQuestions. The data we acquired has a shape of 3,444,283 x 68 for the submissions table and 76,503,363 x 21 for the comments table."
  },
  {
    "objectID": "eda/exploratory-analysis.html#external-data",
    "href": "eda/exploratory-analysis.html#external-data",
    "title": "Exploratory Analysis",
    "section": "External Data",
    "text": "External Data\nWe have two primary sources of external data. The first is a community members dataset detailing the number of members each of the 12 subreddits has. By combining this data into the submissions table, we will get a valuable extra data point for our analysis related to the engagement of posts. This data was collected from Reddit itself. Our second source is the text of the books Metamorphosis by Franz Kafka and The Scarlet Letter by Nathaniel Hawthorne. We aim to perform an NLP time-series sentiment analysis on these books and the most engaging long-form story posts, and by calculating the correlations, we’ll be able to determine if these take the reader through a similar sentiment pattern and infer whether that is the reason for their popularity. This data was collected from Project Gutenberg. These data sources are available at here."
  },
  {
    "objectID": "eda/exploratory-analysis.html#cleaning",
    "href": "eda/exploratory-analysis.html#cleaning",
    "title": "Exploratory Analysis",
    "section": "Cleaning",
    "text": "Cleaning\nOur cleaning process includes removing from the comments database both datasets the columns that are not needed for each particular set of analyses. Also, in the comments table, we remove the rows where the body has been either removed or deleted. In the submissions table, we also remove where the selftext has been removed or deleted. The resulting rows are 977,181 for the submissions table and 70,594,314 for the comments table.\nThe count of posts per each subreddit is detailed below:\n\n\n\n\n\nSubreddit\nCount\n\n\n\n\nrelationship_advice\n311,882\n\n\nNoStupidQuestions\n234,253\n\n\nTrueOffMyChest\n125,159\n\n\nAmItheAsshole\n115,659\n\n\nantiwork\n76,647\n\n\nunpopularopinion\n39,642\n\n\nsocialskills\n23,005\n\n\nAskMen\n18,240\n\n\nexplainlikeimfive\n15,002\n\n\ntifu\n11,921\n\n\nOutOfTheLoop\n3,054\n\n\nAskWomen\n2,717\n\n\n\n\n\nAnother component of the data that we’d like to observe is how many submissions and comments we can actually extract textual information from. Below, we can see the distribution of “valid” versus “invalid” posts for each subreddit, with “invalid” posts being those that have been removed or deleted. It seems very common that posts are actually removed or deleted. The plot below shows the count of valid comments per Subreddit:\n\n\n\n        \n        \n\n\n\n\n\n\n\n\nThe code used for this section is available here."
  },
  {
    "objectID": "eda/exploratory-analysis.html#data-transformations-and-additional-variables",
    "href": "eda/exploratory-analysis.html#data-transformations-and-additional-variables",
    "title": "Exploratory Analysis",
    "section": "Data transformations and additional variables",
    "text": "Data transformations and additional variables\nAlthough we summarize the new variables below, they are are described within the EDA sections below.\n\nengagements: the sum of submissions and comments for a particular subreddit.\ninteraction_score an equal-weighted average of the number of comments and the score in each post.\nweek_of_the_year: created from the created_utc column, it describes the week of the year corresponding to the particular post’s date.\nhour_of_the_day: created from the created_utc column, it describes the hour of the day corresponding to the particular post’s date."
  },
  {
    "objectID": "eda/exploratory-analysis.html#regex-search-and-dummies",
    "href": "eda/exploratory-analysis.html#regex-search-and-dummies",
    "title": "Exploratory Analysis",
    "section": "Regex Search and Dummies",
    "text": "Regex Search and Dummies\nTo gauge the overall engagement in the posts, we used regex to create dummy variables that indicate whether the words ‘fascinating,’ ‘entertaining,’ and ‘boring’ appear on a post. We then aggregated them, with the results shown in the following table:\n\n\n\n\n\ncount\nfascinating\nentertaining\nboring\n\n\n\n\n1\n51,424\n30,870\n99,068\n\n\n0\n76,451,939\n76,472,493\n76,404,295\n\n\n\n\n\n\n\n\n\n\n\nThe code used for this section is available here."
  },
  {
    "objectID": "eda/exploratory-analysis.html#the-relationship-between-the-number-of-comments-and-the-score-of-reddit-posts",
    "href": "eda/exploratory-analysis.html#the-relationship-between-the-number-of-comments-and-the-score-of-reddit-posts",
    "title": "Exploratory Analysis",
    "section": "The relationship between the number of comments and the score of Reddit posts",
    "text": "The relationship between the number of comments and the score of Reddit posts\nThe number of comments (num_comments) and the score of a post (score), which is the upvotes minus the downvotes the post has received, are ways to gauge engagement with the post. Determining whether these variables are correlated can justify their combination into an aggregate engagement metric. To do this, we group the submissions by subreddit and leverage the corr function from pyspark.sql.functions. The table below shows the results:\n\n\n\n\n\nSubreddit\nCorrelation Coefficient\n\n\n\n\nexplainlikeimfive\n0.88\n\n\nOutOfTheLoop\n0.86\n\n\nAskMen\n0.85\n\n\nunpopularopinion\n0.83\n\n\nantiwork\n0.82\n\n\ntifu\n0.82\n\n\nAmItheAsshole\n0.81\n\n\nTrueOffMyChest\n0.79\n\n\nNoStupidQuestions\n0.78\n\n\nAskWomen\n0.77\n\n\nsocialskills\n0.72\n\n\nrelationship_advice\n0.64\n\n\n\n\n\nWe can also visualize them separately as in the figure below:\n\nWe can see in both the table and figure that they are significantly correlated, which leads to the creation of the interaction_score additional variable. This metric is an equal-weighted average of the number of comments and the score in each post.\n\n\n\n\n\n\nThe code used for this section is available here."
  },
  {
    "objectID": "eda/exploratory-analysis.html#the-impact-of-not-safe-for-work-nsfw-content-on-user-engagement.",
    "href": "eda/exploratory-analysis.html#the-impact-of-not-safe-for-work-nsfw-content-on-user-engagement.",
    "title": "Exploratory Analysis",
    "section": "The impact of not-safe-for-work (NSFW) content on user engagement.",
    "text": "The impact of not-safe-for-work (NSFW) content on user engagement.\nTo determine if not safe for work post affects user interactions, first, we filter the submissions dataset for where the over_18 flag is true (which in this tiny percentage of them). Then, we randomly sample an equal amount of false cases, and with this, we create a small, balanced dataset with the same amount of posts flagged as NSFW as those that are not.\nWe can create a boxplot with this small dataset to see the distribution. Since we know from Topic 1 that the interaction_score is a good gauge of overall interaction, we can plot that variable as shown below:\n\nWe can infer from the plot that NSFW content increases the engagement with the post, although more analysis will be conducted in subsequent sections.\n\n\n\n\n\n\nThe code used for this section is available here."
  },
  {
    "objectID": "eda/exploratory-analysis.html#the-times-of-the-day-when-posts-typically-receive-the-most-engagement.",
    "href": "eda/exploratory-analysis.html#the-times-of-the-day-when-posts-typically-receive-the-most-engagement.",
    "title": "Exploratory Analysis",
    "section": "The times of the day when posts typically receive the most engagement.",
    "text": "The times of the day when posts typically receive the most engagement.\nTo determine the times of day when a post typically receives the most engagement, we create two additional variables: week_of_the_year and hour_of_the_day, both coming from the created_utc column. We remove the first two days of 2022 as these would be considered part of week 53 of 2021. Then, we can group and pivot the count of our new variables, resulting in the plot below:\n\nThis analysis clearly shows from roughly 6:00 AM to 11:00 AM UTC (or 1:00 AM to 6:00 AM Eastern time) is low on activity in the story time subreddits.\n\n\n\n\n\n\nThe code used for this section is available here."
  },
  {
    "objectID": "eda/exploratory-analysis.html#subreddit-community-prediction",
    "href": "eda/exploratory-analysis.html#subreddit-community-prediction",
    "title": "Exploratory Analysis",
    "section": "Subreddit community prediction",
    "text": "Subreddit community prediction\nOne interesting task that we have our sights set on is predicting the subreddit to which a post belongs, given the textual components of the post. In doing so, there are many components of the data that we would like to explore. For this, we also generated additional variable engagements as the sum of submissions and comments for a particular subreddit.\nOne component of the data that we’d like to look at is the distribution of subreddits among submissions and comments. Below, we can see this distribution, with many engagements coming from the AmItheAsshole, relationship_advice, and antiwork subreddits. These subreddits invoke a lot of engagement from other users, in the form of comments, so this level of engagement can be expected.\n\n\n\n        \n        \n\n\n\n\n\n\n\n\nTip with Title\n\n\n\nClick on the bars of each Subreddit to focus them!\n\n\n\n\n\n\n\n\nThe code used for this section is available here."
  },
  {
    "objectID": "eda/exploratory-analysis.html#flair-prediction",
    "href": "eda/exploratory-analysis.html#flair-prediction",
    "title": "Exploratory Analysis",
    "section": "Flair prediction",
    "text": "Flair prediction\nIn this section we take a closer look at the subreddit r/AmItheAsshole (henceforth referred to as r/AITA) with the goal of both analyzing and predicting what “flair” is assigned to each post based on its text content. The exploratory segment of this analysis involves analyzing and visualizing the frequency counts of each “flair” in r/AITA for 2022.\nIn r/AITA, users post stories about situations in the real world where they have performed some sort of action or behaved in some certain manner, but are questioning whether their actions are good/bad, in a sense. Other users on the subreddit then comment on these story-like submissions and state whether they think the way the original poster acted was good or bad. Thus, each post is assigned a “flair” (i.e., tag) denoting the “judgment” of the post and can be any one of the following: Asshole, Not the A-hole, Everyone Sucks, and Not the A-hole. The first flair indicates the original poster acted in a reprehensible/poor manner, the second is the opposite, the third flair denotes a situation in which all parties are at fault, and the final flair indicates that no one acted in a particularly poor manner.\nThe number of posts that are flaired as each of the flairs in the r/AITA is show below:\n\nThe treemap below shows the relative proportion of them:\n\nAs we can see, Redditors by and large “judge” the majority of original posters to be “Not the A-hole,” but there are certainly plenty of posts where the judgments resulted in different outcomes. The frequency of these flairs’ occurrences as well as the possible reasons behind these occurrences will be explored further in the NLP and ML sections.\n\n\n\n\n\n\nThe code used for this section is available here."
  },
  {
    "objectID": "eda/exploratory-analysis.html#nlp-eda-for-emerging-trends-and-controversial-comments",
    "href": "eda/exploratory-analysis.html#nlp-eda-for-emerging-trends-and-controversial-comments",
    "title": "Exploratory Analysis",
    "section": "NLP EDA for Emerging Trends and Controversial Comments",
    "text": "NLP EDA for Emerging Trends and Controversial Comments\nThe plot below shows a regex count of the current events per Subreddit:\n\nThe plot below shows the performance of controversial posts:\n\n\n\n\n\n\n\nThe code used for this section is available here and here."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Overview",
    "section": "",
    "text": "Overview\nIn this project, we dive into the intersection of story telling in Reddit and machine learning (ML). Our exploration spans various aspects from classifying posts into specific subreddits to predicting the age and gender of posters based on their language. We’re also examining the influence of NSFW posts on user engagement and the correlation between post score and its comments. The project will utilize advanced Natural Language Processing (NLP) techniques to unearth trends within communities, predict post flairs, and delve into the sentiment analysis of subreddit posts. We also aim to use ML to distill meaningful insights from vast quantities of data.\n\n\n\nImage generated with OpenAI DALL·E 3 with prompt “a group of four friends around a campfire sharing stories in modern digital illustration style”"
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "ML",
    "section": "",
    "text": "ML\nComing soon!"
  },
  {
    "objectID": "secondary/references.html",
    "href": "secondary/references.html",
    "title": "It's Storytime!",
    "section": "",
    "text": "References\n\n\nBaumgartner, Jason, Savvas Zannettou, Brian Keegan, Megan Squire, and Jeremy Blackburn. 2020. “The Pushshift Reddit Dataset.” arXiv. https://doi.org/10.48550/arXiv.2001.08435.\n\n\nThe Reddit Archives. 2016. “JSON.” GitHub. https://github.com/reddit-archive/reddit/wiki/JSON."
  }
]