<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.333">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>It's Storytime! – ml</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">It’s Storytime!</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" rel="" target="" aria-current="page">
 <span class="menu-text">Main</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./secondary/code-and-data.html" rel="" target="">
 <span class="menu-text">Code and Data</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./secondary/authors.html" rel="" target="">
 <span class="menu-text">Authors</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./secondary/references.html" rel="" target="">
 <span class="menu-text">References</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ml.html">ML</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EDA</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nlp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">NLP</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ml.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">ML</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conclusion</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./discussion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Feedback Discussion</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#executive-summary" id="toc-executive-summary" class="nav-link active" data-scroll-target="#executive-summary">Executive Summary</a></li>
  <li><a href="#analysis-report" id="toc-analysis-report" class="nav-link" data-scroll-target="#analysis-report">Analysis Report</a>
  <ul class="collapse">
  <li><a href="#sec-subreddit-prediction" id="toc-sec-subreddit-prediction" class="nav-link" data-scroll-target="#sec-subreddit-prediction">Subreddit Prediction</a></li>
  <li><a href="#sec-flair-prediction" id="toc-sec-flair-prediction" class="nav-link" data-scroll-target="#sec-flair-prediction">Flair Prediction Using Random Forest Classification</a></li>
  <li><a href="#sec-story-generation" id="toc-sec-story-generation" class="nav-link" data-scroll-target="#sec-story-generation">Story Generation</a></li>
  <li><a href="#sec-pre-trained-models" id="toc-sec-pre-trained-models" class="nav-link" data-scroll-target="#sec-pre-trained-models">Top Comment Summary Generation</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">ML</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="executive-summary" class="level2">
<h2 class="anchored" data-anchor-id="executive-summary">Executive Summary</h2>
<p>This section focuses on Machine Learning (ML) methods to answer our research questions. In particular, our first two goals for this section involve identifying characteristics of a Reddit post, while our last two goals are more text-based, involving Reddit post generation and summarization.</p>
<p>First, we focus on predicting which subreddit a post belongs to based on its text. We provide a Random Forest model for this classification task, as well as a baseline model for comparison. In doing so, we find significant improvement from the baseline model to the Random Forest model, with areas of improvement still to address.</p>
<p>Subsequently, we attempt to predict the flairs of posts in <code>r/AmItheA**hole</code> (<code>r/AITA</code>) using various possible predictors. We apply two Random Forest models using the text of posts in <code>r/AITA</code> and the user engagement on these posts, respectively. Similar to our first classification task, we find that these models perform better than a blind guess or baseline, but still have a lot of room for improvement.</p>
<p>Then, we aim to create a model that can generate stories for new Reddit posts. We train a recurrent neural network (RNN) with a Long Short-Term Memory architecture on text from a mix of top stories from various subreddits and popular books. While the model successfully generates text that demonstrates an understanding of basic linguistic structures, it has yet to produce fully cohesive stories, marking a significant step towards more complex narrative generation.</p>
<p>Lastly, we use two pre-trained models, one for summarization and one for sentiment analysis, to understand topics selected in the natural language processing portion of our project within the <code>r/NoStupidQuestions</code> subreddit. With the summarization model, we identify popular comments of interest and are able to greatly reduce the amount of text while keeping the meaning of the comment. Additionally, the sentiment analysis model is able to effectively classify the sentiment of the comments in a subreddit, furthering our understanding of the discourse in the <code>r/NoStupidQuestions</code> subreddit.</p>
<p>Overall, these studies highlight the challenges and progress in using ML for subreddit content analysis, demonstrating advancements from simple probabilistic approaches to more sophisticated models like Random Forest and RNNs. The models have varying degrees of success, suggesting room for further improvement in these areas.</p>
</section>
<section id="analysis-report" class="level2">
<h2 class="anchored" data-anchor-id="analysis-report">Analysis Report</h2>
<section id="sec-subreddit-prediction" class="level3">
<h3 class="anchored" data-anchor-id="sec-subreddit-prediction">Subreddit Prediction</h3>
<p>For our subreddit prediction task, we aim to take only the textual content of a post and classify the subreddit to which that post belongs. By using the 500 most common words across all posts, we hope to obtain important textual information that helps us determine which subreddit a post belongs to. For instance, the word “relationship” may be much more likely to appear in the <code>r/relationship_advice</code> subreddit than any others.</p>
<section id="baseline-model" class="level4">
<h4 class="anchored" data-anchor-id="baseline-model">Baseline Model</h4>
<p>Before we dive into complex Machine Learning models, though, we start with a baseline model. The baseline model provides us with a point of comparison for our more complex Machine Learning models, allowing us to evaluate the performance of those models in comparison to the simple baseline. Our baseline model is very naïve - it simply predicts subreddits with probability equal to the proportion with which they make up the training dataset. For instance, if <code>50%</code> of our training dataset contains observations from <code>r/relationship_advice</code>, <code>30%</code> from <code>r/NoStupidQuestions</code>, and <code>20%</code> from <code>r/TrueOffMyChest</code>, our baseline model will predict that a post belongs to the subreddit <code>r/relationship_advice</code> with probability <code>0.50</code>, the subreddit <code>r/NoStupidQuestions</code> with probability <code>0.30</code>, and the subreddit <code>r/TrueOffMyChest</code> with probability <code>0.20</code>. In this case, of course, the model has 12 subreddits to choose from, each with their own associated probabilities. Note that the baseline model does not consider additional information, such as the textual content of the post, because it is so simple.</p>
<p>Below, in <a href="#fig-baseline-training">Figure&nbsp;1</a>, we can see the results of the model predictions on the training data. As expected, the model predicts the more prevalent subreddits, such as <code>r/relationship_advice</code> and <code>r/NoStupidQuestions</code>, more often. Since the model only predicts subreddits proportionally to how they appear in the training data, it does not do a good job of actually identifying these subreddits correctly. In fact, its expected classification accuracy is equal to the sum of the squares of the probabilities with which each subreddit occurs, which amounts to approximately 0.20.</p>
<div id="fig-baseline-training" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ml-plots/baseline-cv-train-cm.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Shows the confusion matrix for the Baseline Model, evaluated on the training data.</figcaption>
</figure>
</div>
<p>Below, in <a href="#fig-baseline-testing">Figure&nbsp;2</a>, we can see the results of the model predictions on the testing data. As expected, the model’s performance on the testing set is no different than on the training set. We find the same characteristics, with the model performing quite poorly.</p>
<div id="fig-baseline-testing" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ml-plots/baseline-cv-test-cm.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Shows the confusion matrix for the Baseline Model, evaluated on the testing data.</figcaption>
</figure>
</div>
<p>Below, in <a href="#fig-baseline-eval">Figure&nbsp;3</a>, is a summary table of the performance metrics for the baseline model on both the training and testing sets. Each metric reports values of approximately 0.20, which is to be expected with such a simple model. We look to improve this performance with a Random Forest model below.</p>
<div class="cell" data-execution_count="2">
<div id="fig-baseline-eval" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">

        <iframe width="100%" height="500" src="img/ml-plots/baseline-eval.html" frameborder="0" allowfullscreen=""></iframe>
        
<figcaption class="figure-caption">Figure&nbsp;3: Shows the evaluation metrics for the Baseline Model Classifier.</figcaption>
</figure>
</div>
</div>
</section>
<section id="random-forest-model" class="level4">
<h4 class="anchored" data-anchor-id="random-forest-model">Random Forest Model</h4>
<p>In order to predict the subreddit to which a post belongs more effectively, we turn to the Random Forest. <add rf="" explanation="" here="">.</add></p>
<p>Below, in <a href="#fig-random-forest-training">Figure&nbsp;4</a>, we can see the results of the model predictions on the training data. Here, we find that the performance of the model seems to outperform that of the baseline model, but still has its downfalls. The model predicts the two most prevalent subreddits, <code>r/relationship_advice</code> and <code>r/NoStupidQuestions</code>, nearly every time, failing to predict any of the less prevalent subreddits. In this sense, the model is vastly underperforming, as it is heavily biased to the subreddits that it has seen more often.</p>
<div id="fig-random-forest-training" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ml-plots/random-forest-cv-train-cm.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Shows the confusion matrix for the Random Forest, evaluated on the training data.</figcaption>
</figure>
</div>
<p>Below, in <a href="#fig-random-forest-testing">Figure&nbsp;5</a>, we can see the results of the model predictions on the testing data. As expected, the model’s performance on the testing set is no different than on the training set. We find the same characteristics, with the model performing well in some aspects, but with plenty of room for improvement.</p>
<div id="fig-random-forest-testing" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ml-plots/random-forest-cv-test-cm.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Shows the confusion matrix for the Random Forest, evaluated on the testing data.</figcaption>
</figure>
</div>
<p>Below, in <a href="#fig-random-forest-eval">Figure&nbsp;6</a>, is a summary table of the performance metrics for the Random Forest model on both the training and testing sets. Each metric reports values of approximately 0.50, which is a great improvement over the baseline model. However, we feel that further improvements can be made in order to achieve higher performance on our subreddit prediction task.</p>
<div class="cell" data-execution_count="3">
<div id="fig-random-forest-eval" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">

        <iframe width="100%" height="500" src="img/ml-plots/random-forest-eval.html" frameborder="0" allowfullscreen=""></iframe>
        
<figcaption class="figure-caption">Figure&nbsp;6: Shows the evaluation metrics for the Random Forest Classifier.</figcaption>
</figure>
</div>
</div>
</section>
<section id="random-forest-model---balanced-classes" class="level4">
<h4 class="anchored" data-anchor-id="random-forest-model---balanced-classes">Random Forest Model - Balanced Classes</h4>
<p><img src="img/ml-plots/random-forest-cv-train-cm-balanced.png" id="fig-random-forest-cv-train-cm-balanced" class="img-fluid" style="width:70.0%" alt="Shows"> <img src="img/ml-plots/random-forest-cv-test-cm-balanced.png" id="fig-random-forest-cv-test-cm-balanced" class="img-fluid" style="width:70.0%" alt="Shows"></p>
<div class="cell" data-execution_count="4">
<div id="fig-random-forest-eval-balanced.html" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">

        <iframe width="100%" height="500" src="img/ml-plots/random-forest-eval-balanced.html" frameborder="0" allowfullscreen=""></iframe>
        
<figcaption class="figure-caption">Figure&nbsp;7: Shows</figcaption>
</figure>
</div>
</div>
</section>
<section id="random-forest-model---class-subset" class="level4">
<h4 class="anchored" data-anchor-id="random-forest-model---class-subset">Random Forest Model - Class Subset</h4>
<p><img src="img/ml-plots/random-forest-cv-train-cm-subset.png" id="fig-random-forest-cv-train-cm-subset" class="img-fluid" style="width:70.0%" alt="Shows"> <img src="img/ml-plots/random-forest-cv-test-cm-subset.png" id="fig-random-forest-cv-test-cm-subset" class="img-fluid" style="width:70.0%" alt="Shows"></p>
<div class="cell" data-execution_count="5">
<div id="fig-random-forest-eval-subset.html" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">

        <iframe width="100%" height="500" src="img/ml-plots/random-forest-eval-subset.html" frameborder="0" allowfullscreen=""></iframe>
        
<figcaption class="figure-caption">Figure&nbsp;8: Shows</figcaption>
</figure>
</div>
</div>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>The code used for this section is available <a href="https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17/blob/main/code/project-ml/project-ml-predicting-subreddits.ipynb">here</a>.</p>
</div>
</div>
</div>
</section>
</section>
<section id="sec-flair-prediction" class="level3">
<h3 class="anchored" data-anchor-id="sec-flair-prediction">Flair Prediction Using Random Forest Classification</h3>
<p>In this section we attempted to predict what flair is assigned to posts in <code>r/AmItheA**hole</code> (<code>r/AITA</code>) based on various different predictors using a Random Forest (RF) model to attempt to predict how Redditors “judge” these stories posted on <code>r/AITA</code>. We then compared these models with their varying predictors and compared them to a baseline model (random chance).</p>
<p>The first RF model we applied to the <code>r/AITA</code> data using token counts of the five hundred most common words which were extracted using CountVectorizer in the NLP section previously. We chose fifty trees as our hyperparameter to be used across all models used in this section to allow for consistent comparisons. However, due to the imbalanced nature of the <code>r/AITA</code> posts (as established in the EDA section of this project), the dataset was downsampled so that none of the four primary flairs (A**hole, Not the A-hole, Everyone Sucks, No A-holes here) are overrepresented to the extent that they would significantly hinder model performance. After a training and testing data split, the model was trained on the training subset and various model metrics were calculated for both the training and testing subsets via a SparkML pipeline. Measures and visualizations of this model’s efficacy are displayed below.</p>
<div id="fig-flair-text-train" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ml-plots/flair-text-cm-train-plot.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;9: Shows the confusion matrix for the Random Forest, evaluated on the training data.</figcaption>
</figure>
</div>
<div id="fig-flair-text-test" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ml-plots/flair-text-cm-test-plot.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;10: Shows the confusion matrix for the Random Forest, evaluated on the testing data.</figcaption>
</figure>
</div>
<div id="fig-flair-text-metrics" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ml-plots/flair-text-model-metrics-plot.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;11: Shows the evalutation metrics for the Random Forest.</figcaption>
</figure>
</div>
<p>Based on the metrics above, this model did not predict the flairs of these posts particularly accurately, but performed better than a blind random guess, which would have a theoretical accuracy of 25% compared to our model’s ~30-40%. For both the training and testing subsets, the model did an extremely poor job at predicting “Not the A-hole posts”. This model does perform reasonably well when predicting “Everyone Sucks” and “Asshole” flaired posts, but does not predict the posts with the more positively connoted flairs (No A-holes here and Not the A-hole).</p>
<p>Another potential set of predictors we identified were measures of user engagement, namely post “score” (number of upvotes minus number of downvotes) and the number of comments under a post. We applied a similar model using these predictors via another SparkML pipeline and compared them to the previous text-based model. The measures of model performance and confusion matrices are visualized below as such.</p>
<div id="fig-flair-engagement-train" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ml-plots/flair-engagement-cm-train-plot.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;12: Shows the confusion matrix for the Random Forest, evaluated on the training data.</figcaption>
</figure>
</div>
<div id="fig-flair-engagement-test" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ml-plots/flair-engagement-cm-test-plot.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;13: Shows the confusion matrix for the Random Forest, evaluated on the training data.</figcaption>
</figure>
</div>
<div id="fig-flair-engagement-metrics" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ml-plots/flair-engagement-model-metrics-plot.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;14: Shows the evaluation metrics for the Random Forest.</figcaption>
</figure>
</div>
<p>As shown above, this model performs fairly similarly to the previous text-based model but with some slight improvements in some of the model performance metrics along with more comparative performance metrics of the model for the training and test sets. This model more effectively predicted posts with the flairs “Asshole” and “Everyone Sucks” compared to the text-based model, but similarly struggled to correctly identify posts with more positive flairs. Ultimately, while this model does perform slightly better than the previous text-based model, especially at predicting the posts with more negative flairs attached, it still would not serve as an effective tool for accurately predicting these flairs on a larger scale. It is possible that these data are too homogeneous to be easily differentiated using a machine learning model, or using different models and/or hyperparameters may generate more accurate predictions.</p>
<p>We also include the evaluation metrics in <a href="#tbl-flair-model-metrics-df">Table&nbsp;1</a> below:</p>
<div class="cell tbl-cap-location-bottom" data-execution_count="6">
<div class="cell-output cell-output-display" data-execution_count="6">
<div id="tbl-flair-model-metrics-df" class="anchored">
<table class="table table-sm table-striped small">
<caption>Table&nbsp;1: Displays the evaluation metrics of both engagement and text-based models.</caption>
<colgroup>
<col style="width: 13%">
<col style="width: 27%">
<col style="width: 22%">
<col style="width: 20%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Metric</th>
<th style="text-align: right;">Engagement Training</th>
<th style="text-align: right;">Engagement Test</th>
<th style="text-align: right;">Text Training</th>
<th style="text-align: right;">Text Test</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">accuracy</td>
<td style="text-align: right;">0.396378</td>
<td style="text-align: right;">0.396137</td>
<td style="text-align: right;">0.420226</td>
<td style="text-align: right;">0.329193</td>
</tr>
<tr class="even">
<td style="text-align: left;">f1</td>
<td style="text-align: right;">0.393809</td>
<td style="text-align: right;">0.392595</td>
<td style="text-align: right;">0.382704</td>
<td style="text-align: right;">0.28115</td>
</tr>
<tr class="odd">
<td style="text-align: left;">precision</td>
<td style="text-align: right;">0.395841</td>
<td style="text-align: right;">0.394806</td>
<td style="text-align: right;">0.459258</td>
<td style="text-align: right;">0.309424</td>
</tr>
<tr class="even">
<td style="text-align: left;">recall</td>
<td style="text-align: right;">0.396378</td>
<td style="text-align: right;">0.396137</td>
<td style="text-align: right;">0.420226</td>
<td style="text-align: right;">0.329193</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>The code used for this section is available <a href="https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17/blob/main/code/project-ml/project-ml-aita-flair-prediction.ipynb">here</a>.</p>
</div>
</div>
</div>
</section>
<section id="sec-story-generation" class="level3">
<h3 class="anchored" data-anchor-id="sec-story-generation">Story Generation</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The saved model used for this section is available <a href="https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17/blob/main/data/ml-data/rnn_model_250_0.15.pth">here</a>.</p>
</div>
</div>
<p>In our project, we developed a story generation model using a recurrent neural network (RNN) model, which we built and trained using <code>PySpark</code> and <code>PyTorch</code>. To enhance the computation speed, we integrated CUDA into the process. Our data is the mix of top stories from various subreddits and popular books sourced externally, developed during the NLP portion of the project. The preprocessed portion of the dataset usable for training purposes is 1037 MB. We found that a smaller subset of 160.59 MB was adequate for the analysis.</p>
<p>The model’s architecture is based on a Long Short-Term Memory (LSTM) layer, which captures long-term dependencies in sequential data. In our setup, we defined hyperparameters such as the input size of 128, hidden state at 256, and used a two-layer LSTM. The model has 12,766,510 trainable parameters.</p>
<p>For the training process, we set the learning rate at 0.01, a maximum of 100 epochs, and a batch size of 64. To ensure the model didn’t overfit, we employed an early stopping mechanism with a patience of 5 epochs and a validation loss improvement threshold of 0.01. The Adam optimizer was chosen for optimization, paired with a cross-entropy loss function for calculating the model’s error rate. The total training time was 1h 41 mins.</p>
<p>The training and validation perplexities are shown in <a href="#fig-rnn-training-validation-perplexity">Figure&nbsp;15</a>:</p>
<div id="fig-rnn-training-validation-perplexity" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ml-plots/training-validation-perplexity-plot-rnn.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;15: Shows the training and validation perplexities of the RNN training process</figcaption>
</figure>
</div>
<p>To evaluate the model’s effectiveness, we focused on loss and perplexity. A lower perplexity value suggests a higher predictive accuracy of the model. The model achieved a test loss of 1.6227 and a perplexity value of 5.0667, indicating a strong performance in predictive capabilities.</p>
<p>We were ready to generate stories with the trained. Some examples are shown in <a href="#tbl-rnn-generation">Table&nbsp;2</a>:</p>
<div id="tbl-rnn-generation" class="anchored">
<table class="table">
<caption>Table&nbsp;2: Shows the prompt and generated text by the RNN model</caption>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Prompt</th>
<th>Generated Text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Once upon a time</td>
<td>Once upon a time to of a cause the gachen friends these any olden lands. it was the school all as the sach could boypheal, and they letes saying cut that ended about the told the asking.the said she so a kyastellow specially will wrong me have a glories and how in s</td>
</tr>
<tr class="even">
<td>The sun set over the ancient, whispering forest</td>
<td>The sun set over the ancient forest and the sating the told the thought the pressated the hassed has all she was hands and the and the and of didnt conday her that there you hands my like i was the and i was the told when and the put all into the done to the down the sately and stouse</td>
</tr>
<tr class="odd">
<td>The sound of sirens pierced the night</td>
<td>The sound of sirens pierced the night stack and the down, my fear that my bly and were expetes his slaring when it becheads icky that my feelt and want and contores she givated hours. we let me processings that i only and low that on a mord of the past finding to this because oulling th</td>
</tr>
</tbody>
</table>
</div>
<p>Although our model cannot yet generate cohesive stories, it’s important to recognize the success in the underlying process. The characters produced by the model consistently combine to form coherent words, an ability that demonstrates the model’s understanding of basic linguistic structures, a foundational step toward more complex story generation. This aspect of the model’s output aligns well with the objectives of our project.</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>The code used for this section is available <a href="https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17/blob/main/code/project-ml/project-nlp-posts-and-books-model.ipynb">here</a>.</p>
</div>
</div>
</div>
</section>
<section id="sec-pre-trained-models" class="level3">
<h3 class="anchored" data-anchor-id="sec-pre-trained-models">Top Comment Summary Generation</h3>
<p>After all of the NLP work to identify comments that were scored high and contained the topic we had chosen, in this case comments related to COVID-19 in the subreddit <code>r/NoStupidQuestions</code>. We were successfully able to identify comments that we would be useful to summarize to better gain an understanding of the narrative in a particular subreddit. One example of this is below.</p>
<p>The model used to perform this summarization was a “facebook/bart-large-cnn” <span class="citation" data-cites="lewis_bart_2019">[<a href="#ref-lewis_bart_2019" role="doc-biblioref">1</a>]</span>.</p>
<div id="fig-rouge-scores-plot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ml-plots/rouge-scores-plot.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;16: Shows the result of the sentiment analysis using the pre-trained model.</figcaption>
</figure>
</div>
<section id="before-summarization-after-stemming-and-removing-stopwords" class="level5">
<h5 class="anchored" data-anchor-id="before-summarization-after-stemming-and-removing-stopwords">Before Summarization (After Stemming and removing StopWords):</h5>
<blockquote class="blockquote">
<p>I can understand that frustration and getting tired of the cynicism or generation of toxic beliefs, but it should be noted that about that bit from his 1999 special about the immune system and all that, his family has outright said:</p>
<p>Several times during the pandemic, Carlin has drawn attention for a routine from his 1999 special, “You Are All Diseased,” in which he mischievously suggests that a childhood spent swimming in the polluted Hudson River was the reason he didn’t catch polio.</p>
<p>(“In my neighborhood, no one ever got polio,” he fulminates. “No one, ever. You know why? ’Cause we swam in raw sewage. It strengthened our immune systems. The polio never had a prayer.”)</p>
<p>As Kelly Carlin explained, some viewers concluded — wrongly — that her father would have opposed coronavirus vaccines.</p>
<p>“Everyone’s like, see? George Carlin would have been anti-vaccination,” she said. “And I’m like, no. My dad was pro-science, pro-rational thinking, pro-evidence-based medicine. The man was a heart patient for 30 years. When he was a kid and the polio vaccine became available, he got the polio vaccine.”</p>
<p>…</p>
<p>In efforts to divine his opinion, some Carlin fans pointed to a 1990 interview he gave to Larry King, when he expressed his misgivings about the crude standup of Andrew Dice Clay: “His targets are underdogs, and comedy has traditionally picked on power — people who abuse their power,” Carlin said at the time.</p>
<p>Kelly Carlin said her father “always took the stand that more speech is better than less speech” and would have supported Chappelle’s right to perform the special. But, she added, “if you’re a comedian, you’ve got to be funny.”</p>
</blockquote>
</section>
<section id="after-summarization" class="level5">
<h5 class="anchored" data-anchor-id="after-summarization">After Summarization:</h5>
<blockquote class="blockquote">
<p>Carlin has drawn attention for a routine from his 1999 special, “You Are All Diseased.” He mischievously suggests that a childhood spent swimming in the polluted Hudson River was the reason he didn’t catch polio. Some viewers concluded — wrongly — that her father would have opposed coronavirus vaccines. “Everyone’s like, see? George Carlin would have been anti-vaccination,” she said. ’I’m like, no. My dad was pro-science,. pro-rational thinking, pro-evidence-based medicine.</p>
</blockquote>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>The code used for this section is available <a href="https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17/blob/main/code/project-ml/topic_summarization.ipynb">here</a>.</p>
</div>
</div>
</div>



</section>
</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" role="list">
<div id="ref-lewis_bart_2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">Lewis M, Liu Y, Goyal N, Ghazvininejad M, Mohamed A, Levy O, Stoyanov V, Zettlemoyer L. <span>BART</span>: <span>Denoising</span> <span>Sequence</span>-to-<span>Sequence</span> <span>Pre</span>-training for <span>Natural</span> <span>Language</span> <span>Generation</span>, <span>Translation</span>, and <span>Comprehension</span>. 2019 [accessed 2023 Nov 30]. <a href="https://arxiv.org/abs/1910.13461">https://arxiv.org/abs/1910.13461</a>. doi:<a href="https://doi.org/10.48550/ARXIV.1910.13461">10.48550/ARXIV.1910.13461</a></div>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">A project by Team 17.</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">Made with and <a href="https://quarto.org/">Quarto</a><br> <a href="https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17">View the source at GitHub</a></div>
  </div>
</footer>



</body></html>