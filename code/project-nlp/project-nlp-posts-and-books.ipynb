{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-29 23:43:16 sagemaker-studio-692960231031-wo7kgoszj2g\n",
      "2023-08-29 23:50:01 sagemaker-us-east-1-692960231031\n",
      "2023-08-30 00:34:21 vad49\n",
      "2023-09-16 16:02:10 vad49-labdata\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-17 22:45:03     717850 pg1727.txt\n",
      "2023-11-17 22:45:03    1201729 pg2554.txt\n",
      "2023-11-17 22:45:03     513776 pg33.txt\n",
      "2023-11-17 22:45:03     142082 pg5200.txt\n",
      "2023-11-17 22:45:03     306317 pg64317.txt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://project17-bucket-alex/books/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../../data/external-data/books/pg1727.txt to s3://project17-bucket-alex/books/pg1727.txt\n",
      "upload: ../../data/external-data/books/pg33.txt to s3://project17-bucket-alex/books/pg33.txt\n",
      "upload: ../../data/external-data/books/.ipynb_checkpoints/pg64317-checkpoint.txt to s3://project17-bucket-alex/books/.ipynb_checkpoints/pg64317-checkpoint.txt\n",
      "upload: ../../data/external-data/books/pg2554.txt to s3://project17-bucket-alex/books/pg2554.txt\n",
      "upload: ../../data/external-data/books/pg5200.txt to s3://project17-bucket-alex/books/pg5200.txt\n",
      "upload: ../../data/external-data/books/.ipynb_checkpoints/pg2554-checkpoint.txt to s3://project17-bucket-alex/books/.ipynb_checkpoints/pg2554-checkpoint.txt\n",
      "upload: ../../data/external-data/books/.ipynb_checkpoints/pg1727-checkpoint.txt to s3://project17-bucket-alex/books/.ipynb_checkpoints/pg1727-checkpoint.txt\n",
      "upload: ../../data/external-data/books/.ipynb_checkpoints/pg33-checkpoint.txt to s3://project17-bucket-alex/books/.ipynb_checkpoints/pg33-checkpoint.txt\n",
      "upload: ../../data/external-data/books/.ipynb_checkpoints/pg5200-checkpoint.txt to s3://project17-bucket-alex/books/.ipynb_checkpoints/pg5200-checkpoint.txt\n",
      "upload: ../../data/external-data/books/pg64317.txt to s3://project17-bucket-alex/books/pg64317.txt\n",
      "delete: s3://project17-bucket-alex/books/.ipynb_checkpoints/pg1727-checkpoint.txt\n",
      "delete: s3://project17-bucket-alex/books/.ipynb_checkpoints/pg33-checkpoint.txt\n",
      "delete: s3://project17-bucket-alex/books/.ipynb_checkpoints/pg5200-checkpoint.txt\n",
      "delete: s3://project17-bucket-alex/books/.ipynb_checkpoints/pg2554-checkpoint.txt\n",
      "delete: s3://project17-bucket-alex/books/.ipynb_checkpoints/pg64317-checkpoint.txt\n"
     ]
    }
   ],
   "source": [
    "# save books into bucket if needed\n",
    "if True is False:\n",
    "    !aws s3 cp ../../data/external-data/books/ s3://project17-bucket-alex/books --recursive --exclude \"*\" --exclude \".ipynb_checkpoints/*\" --include \"*.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.10.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.10.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyspark==3.2.0 in /opt/conda/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.10/site-packages (0.4.2)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (13.0.0)\n",
      "Requirement already satisfied: spark-nlp in /opt/conda/lib/python3.10/site-packages (5.1.2)\n",
      "Requirement already satisfied: py4j==0.10.9.2 in /opt/conda/lib/python3.10/site-packages (from pyspark==3.2.0) (0.10.9.2)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /opt/conda/lib/python3.10/site-packages (from s3fs) (1.31.63)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from s3fs) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.10/site-packages (from pyarrow) (1.26.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from botocore>=1.12.91->s3fs) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore>=1.12.91->s3fs) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore>=1.12.91->s3fs) (2.0.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.12.91->s3fs) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "if True is True: # set to true only for the first un\n",
    "    # Setup - Run only once per Kernel App\n",
    "    %conda install openjdk -y\n",
    "\n",
    "    # install PySpark\n",
    "    %pip install pyspark==3.2.0 s3fs pyarrow spark-nlp\n",
    "\n",
    "    # restart kernel\n",
    "    from IPython.core.display import HTML\n",
    "    HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, length, isnan, when, count, regexp_extract, weekofyear, hour, avg, to_date, unix_timestamp, lit, corr\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_colwidth', 150) \n",
    "#pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.0\n"
     ]
    }
   ],
   "source": [
    "# Import pyspark and build Spark session\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"PySparkApp\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.2.2\")\n",
    "    .config(\n",
    "        \"fs.s3a.aws.credentials.provider\",\n",
    "        \"com.amazonaws.auth.ContainerCredentialsProvider\",\n",
    "    )\n",
    "    #.config(\"spark-jars-packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3\")\\\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from sparknlp.base import DocumentAssembler\n",
    "#from sparknlp.annotator import LowerCase, Tokenizer\n",
    "#import sparknlp\n",
    "\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring in submissions and comments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/17 22:11:18 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "23/11/17 22:11:25 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.1 ms, sys: 8.47 ms, total: 67.5 ms\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "required_columns = ['subreddit', 'title', 'selftext', 'score', 'created_utc', 'url']\n",
    "\n",
    "\n",
    "# read the full year\n",
    "\n",
    "# Read in data from project bucket\n",
    "bucket = \"project17-bucket-alex\"\n",
    "\n",
    "# List of 12 directories each containing 1 month of data\n",
    "directories = [\"project_2022_\"+str(i)+\"/submissions\" for i in range(1,13)]\n",
    "\n",
    "# Iterate through 12 directories and merge each monthly data set to create one big data set\n",
    "submissions = None\n",
    "for directory in directories:\n",
    "    s3_path = f\"s3a://{bucket}/{directory}\"\n",
    "    month_df = spark.read.parquet(s3_path).select(*required_columns)\n",
    "    \n",
    "    if submissions is None:\n",
    "        submissions = month_df\n",
    "    else:\n",
    "        submissions = submissions.union(month_df)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_small = submissions.sample(withReplacement=False, fraction=0.001, seed=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create small dfs\n",
    "\n",
    "use_small = True  # to easily swap between the small and small dfs\n",
    "submissions_active = submissions_small if use_small else submissions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[subreddit: string, title: string, selftext: string, score: bigint, created_utc: timestamp, url: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cache - only for when working with the small version\n",
    "#submissions_active.cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Process Submissions Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- selftext: string (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- created_utc: timestamp (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "submissions_active.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Conduct basic data quality checks! Make sure there are no missing values, check the length of the comments, and remove rows of data that might be corrupted. Even if you think all your data is perfect, you still need to demonstrate that with your analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove submissions without a body should obviously go, but what about the submissions without a self text (deleted, removed or empty). We can keep where the author is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_submissions(df: DataFrame) -> DataFrame:\n",
    "    \n",
    "    # define conditions\n",
    "    conditions = (col('selftext') != \"[removed]\") & (col('selftext') != \"[deleted]\") & (col('selftext').isNotNull() & (col('selftext') != \"\"))\n",
    "\n",
    "    \n",
    "    # apply filter\n",
    "    cleaned_df = df.filter(conditions)\n",
    "  \n",
    "\n",
    "    return cleaned_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submissions_active = clean_submissions(submissions_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>I need advice</td>\n",
       "      <td>So my gf and I are both 19 and live separately but both in college and she works. We will live together within 2ish years after she graduates but ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-25 17:01:32</td>\n",
       "      <td>https://www.reddit.com/r/relationship_advice/comments/scid7f/i_need_advice/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>Too smart to be this stupid; logics vs heart.</td>\n",
       "      <td>My estranged bf of the last almost 2yrs has vowed to make his life mission, along others aid, to make me have misery and regret. \\n   Call me cr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-18 17:12:58</td>\n",
       "      <td>https://www.reddit.com/r/relationship_advice/comments/s72fh8/too_smart_to_be_this_stupid_logics_vs_heart/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>antiwork</td>\n",
       "      <td>High hopes for the future</td>\n",
       "      <td>Just kidding, this sub is doomed\\n\\nHey mods, stop doing interviews \\n\\nYou don’t speak for the people of this sub. You are a janitor who’s only p...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-27 19:05:44</td>\n",
       "      <td>https://www.reddit.com/r/antiwork/comments/se5xf0/high_hopes_for_the_future/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>I think I just ejaculated without trying</td>\n",
       "      <td>Okay so has anyone else have this happen. Right altering peeing. I get extreme pain I mean like eye shutting crouching over pain and there this cl...</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-05 19:26:45</td>\n",
       "      <td>https://www.reddit.com/r/NoStupidQuestions/comments/rwuuej/i_think_i_just_ejaculated_without_trying/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>socialskills</td>\n",
       "      <td>Is it weird to tell my depressed friend I'm \"proud of him\" after he's overcome a bad mental phase?</td>\n",
       "      <td>One of my best friends suffers from depression and experiences \"down phases\" in irregular intervals. He always has a particularly bad one in winte...</td>\n",
       "      <td>131</td>\n",
       "      <td>2022-01-13 18:13:09</td>\n",
       "      <td>https://www.reddit.com/r/socialskills/comments/s35q0j/is_it_weird_to_tell_my_depressed_friend_im_proud/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             subreddit  \\\n",
       "0  relationship_advice   \n",
       "1  relationship_advice   \n",
       "2             antiwork   \n",
       "3    NoStupidQuestions   \n",
       "4         socialskills   \n",
       "\n",
       "                                                                                                title  \\\n",
       "0                                                                                       I need advice   \n",
       "1                                                       Too smart to be this stupid; logics vs heart.   \n",
       "2                                                                           High hopes for the future   \n",
       "3                                                            I think I just ejaculated without trying   \n",
       "4  Is it weird to tell my depressed friend I'm \"proud of him\" after he's overcome a bad mental phase?   \n",
       "\n",
       "                                                                                                                                                selftext  \\\n",
       "0  So my gf and I are both 19 and live separately but both in college and she works. We will live together within 2ish years after she graduates but ...   \n",
       "1    My estranged bf of the last almost 2yrs has vowed to make his life mission, along others aid, to make me have misery and regret. \\n   Call me cr...   \n",
       "2  Just kidding, this sub is doomed\\n\\nHey mods, stop doing interviews \\n\\nYou don’t speak for the people of this sub. You are a janitor who’s only p...   \n",
       "3  Okay so has anyone else have this happen. Right altering peeing. I get extreme pain I mean like eye shutting crouching over pain and there this cl...   \n",
       "4  One of my best friends suffers from depression and experiences \"down phases\" in irregular intervals. He always has a particularly bad one in winte...   \n",
       "\n",
       "   score         created_utc  \\\n",
       "0      1 2022-01-25 17:01:32   \n",
       "1      1 2022-01-18 17:12:58   \n",
       "2      0 2022-01-27 19:05:44   \n",
       "3      1 2022-01-05 19:26:45   \n",
       "4    131 2022-01-13 18:13:09   \n",
       "\n",
       "                                                                                                         url  \n",
       "0                                https://www.reddit.com/r/relationship_advice/comments/scid7f/i_need_advice/  \n",
       "1  https://www.reddit.com/r/relationship_advice/comments/s72fh8/too_smart_to_be_this_stupid_logics_vs_heart/  \n",
       "2                               https://www.reddit.com/r/antiwork/comments/se5xf0/high_hopes_for_the_future/  \n",
       "3       https://www.reddit.com/r/NoStupidQuestions/comments/rwuuej/i_think_i_just_ejaculated_without_trying/  \n",
       "4    https://www.reddit.com/r/socialskills/comments/s35q0j/is_it_weird_to_tell_my_depressed_friend_im_proud/  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display(f\"submissions shape: ({submissions_active.count()}, {len(submissions_active.columns)})\")\n",
    "\n",
    "display(submissions_active.limit(5).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use regex the remove text after 'Edit: ' or 'edit: '\n",
    "\n",
    "# The regular expression pattern\n",
    "pattern = r\"(?i)^(.*?)(?=Edit:|$)\"\n",
    "\n",
    "# Apply the regular expression to create a new column with the modified text\n",
    "submissions_active = submissions_active.withColumn(\"selftext_modified\", regexp_extract(col(\"selftext\"), pattern, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define stories as posts longer than a certain length \n",
    "\n",
    "story_length = 4500\n",
    "\n",
    "submissions_active = submissions_active.filter(length(col(\"selftext\")) > story_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# keep only the 25% most engaging posts\n",
    "\n",
    "\n",
    "# Calculate the approximate percentile of the 'score' column\n",
    "quantile_value = submissions_active.approxQuantile(\"score\", [0.85], 0.05)  # 0.05 is the relative error\n",
    "\n",
    "# Filter the DataFrame to keep scores above or equal to this value\n",
    "submissions_active = submissions_active.filter(col(\"score\") >= quantile_value[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>url</th>\n",
       "      <th>selftext_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>Is dating online cheating.. the whole story</td>\n",
       "      <td>Due to the overwhelming messages and requests for the whole story on about my last post. I decided to do a tell-all. So I hope you have a minute. ...</td>\n",
       "      <td>29</td>\n",
       "      <td>2022-07-13 15:48:56</td>\n",
       "      <td>https://www.reddit.com/r/relationship_advice/comments/vy6fh0/is_dating_online_cheating_the_whole_story/</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>AITA for expecting my son to share his room?</td>\n",
       "      <td>Background: My (40sf) husband (40sm) and I bought a 3-bedroom house a few years ago, shortly before the panini. We of course took the master bedro...</td>\n",
       "      <td>16459</td>\n",
       "      <td>2022-10-26 08:51:01</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comments/ydt2w5/aita_for_expecting_my_son_to_share_his_room/</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>WIBTA for taking my (15f) laundry basket full of clothes, which my stepdad (49m) threw out for not putting them away, out of the trash?</td>\n",
       "      <td>Sorry for bad English!\\n\\nThe morning before my clothes were thrown away my mom put them in a laundry basket beside my door. She did tell me ofcou...</td>\n",
       "      <td>95</td>\n",
       "      <td>2022-11-07 19:59:01</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comments/yoyf1r/wibta_for_taking_my_15f_laundry_basket_full_of/</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>My housemate (25f) did something I (20f) consider morally unacceptable and its causing a lot of conflict in the house (6 students).</td>\n",
       "      <td>Tl;dr version: I live in a student houseshare. One of my housemates is a student nurse and was extremely inappropriate with a patient which I foun...</td>\n",
       "      <td>421</td>\n",
       "      <td>2022-11-04 20:32:06</td>\n",
       "      <td>https://www.reddit.com/r/relationship_advice/comments/ym9kw7/my_housemate_25f_did_something_i_20f_consider/</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>socialskills</td>\n",
       "      <td>How to Talk About Yourself (and How to Have Good Conversation)</td>\n",
       "      <td>**TL:DR talk about yourself by saying just a little bit in a way that's relevant to the topic at hand, and give the other person the implicit choi...</td>\n",
       "      <td>27</td>\n",
       "      <td>2022-12-01 14:46:48</td>\n",
       "      <td>https://www.reddit.com/r/socialskills/comments/z9polj/how_to_talk_about_yourself_and_how_to_have_good/</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             subreddit  \\\n",
       "0  relationship_advice   \n",
       "1        AmItheAsshole   \n",
       "2        AmItheAsshole   \n",
       "3  relationship_advice   \n",
       "4         socialskills   \n",
       "\n",
       "                                                                                                                                     title  \\\n",
       "0                                                                                              Is dating online cheating.. the whole story   \n",
       "1                                                                                             AITA for expecting my son to share his room?   \n",
       "2  WIBTA for taking my (15f) laundry basket full of clothes, which my stepdad (49m) threw out for not putting them away, out of the trash?   \n",
       "3      My housemate (25f) did something I (20f) consider morally unacceptable and its causing a lot of conflict in the house (6 students).   \n",
       "4                                                                           How to Talk About Yourself (and How to Have Good Conversation)   \n",
       "\n",
       "                                                                                                                                                selftext  \\\n",
       "0  Due to the overwhelming messages and requests for the whole story on about my last post. I decided to do a tell-all. So I hope you have a minute. ...   \n",
       "1  Background: My (40sf) husband (40sm) and I bought a 3-bedroom house a few years ago, shortly before the panini. We of course took the master bedro...   \n",
       "2  Sorry for bad English!\\n\\nThe morning before my clothes were thrown away my mom put them in a laundry basket beside my door. She did tell me ofcou...   \n",
       "3  Tl;dr version: I live in a student houseshare. One of my housemates is a student nurse and was extremely inappropriate with a patient which I foun...   \n",
       "4  **TL:DR talk about yourself by saying just a little bit in a way that's relevant to the topic at hand, and give the other person the implicit choi...   \n",
       "\n",
       "   score         created_utc  \\\n",
       "0     29 2022-07-13 15:48:56   \n",
       "1  16459 2022-10-26 08:51:01   \n",
       "2     95 2022-11-07 19:59:01   \n",
       "3    421 2022-11-04 20:32:06   \n",
       "4     27 2022-12-01 14:46:48   \n",
       "\n",
       "                                                                                                           url  \\\n",
       "0      https://www.reddit.com/r/relationship_advice/comments/vy6fh0/is_dating_online_cheating_the_whole_story/   \n",
       "1          https://www.reddit.com/r/AmItheAsshole/comments/ydt2w5/aita_for_expecting_my_son_to_share_his_room/   \n",
       "2       https://www.reddit.com/r/AmItheAsshole/comments/yoyf1r/wibta_for_taking_my_15f_laundry_basket_full_of/   \n",
       "3  https://www.reddit.com/r/relationship_advice/comments/ym9kw7/my_housemate_25f_did_something_i_20f_consider/   \n",
       "4       https://www.reddit.com/r/socialskills/comments/z9polj/how_to_talk_about_yourself_and_how_to_have_good/   \n",
       "\n",
       "  selftext_modified  \n",
       "0                    \n",
       "1                    \n",
       "2                    \n",
       "3                    \n",
       "4                    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display(f\"submissions shape: ({submissions_active.count()}, {len(submissions_active.columns)})\")\n",
    "\n",
    "\n",
    "display(submissions_active.limit(5).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "#def process_gutenberg_books(directory_path):\n",
    "#    all_text = []\n",
    "#    for filename in os.listdir(directory_path):\n",
    "#        if filename.endswith('.txt'):  # Assuming the files are in .txt format\n",
    "#            file_path = os.path.join(directory_path, filename)\n",
    "#            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#                content = file.read()\n",
    "#                start_idx = content.find(\"*** START OF THE PROJECT GUTENBERG\")\n",
    "#                if start_idx != -1:\n",
    "#                    # Find the end of the line and start from the next line\n",
    "#                    start_idx = content.find('\\n', start_idx) + 1\n",
    "#                    content = content[start_idx:]\n",
    "#                all_text.append(content)\n",
    "#    return ' '.join(all_text)\n",
    "\n",
    "\n",
    "#gutenberg_text = process_gutenberg_books('../../data/external-data/books')\n",
    "\n",
    "#display(len(gutenberg_text))\n",
    "#gutenberg_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#submissions_text = submissions_active.select(\"selftext\").rdd.flatMap(lambda x: x).collect()\n",
    "#submissions_text = ' '.join(submissions_text)\n",
    "\n",
    "#display(len(submissions_text))\n",
    "#submissions_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#combined_text = gutenberg_text + \" \" + submissions_text\n",
    "\n",
    "#display(len(combined_text))\n",
    "#display(combined_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./project-nlp-posts-and-books-processing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./project-nlp-posts-and-books-processing.py\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "# Import pyspark and build Spark session\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import (\n",
    "    DoubleType,\n",
    "    IntegerType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    ")\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s,%(levelname)s,%(module)s,%(filename)s,%(lineno)d,%(message)s', level=logging.DEBUG)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"app inputs and outputs\")\n",
    "    #parser.add_argument(\"--s3_dataset_path_commments\", type=str, help=\"Path of dataset in S3 for reddit comments\")\n",
    "    parser.add_argument(\"--s3_dataset_path_submissions\", type=str, help=\"Path of dataset in S3 for reddit submissions\")\n",
    "    parser.add_argument(\"--s3_dataset_path_books\", type=str, help=\"Path of dataset in S3 for gubenberg books\")\n",
    "    parser.add_argument(\"--s3_output_bucket\", type=str, help=\"s3 output bucket\")\n",
    "    parser.add_argument(\"--s3_output_prefix\", type=str, help=\"s3 output prefix\")\n",
    "    #parser.add_argument(\"--subreddits\", type=str, help=\"comma separate list of subreddits of interest\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    spark = SparkSession.builder.appName(\"PySparkApp\").getOrCreate()\n",
    "    logger.info(f\"spark version = {spark.version}\")\n",
    "    \n",
    "    # This is needed to save RDDs which is the only way to write nested Dataframes into CSV format\n",
    "    sc = spark.sparkContext\n",
    "    sc._jsc.hadoopConfiguration().set(\n",
    "        \"mapred.output.committer.class\", \"org.apache.hadoop.mapred.FileOutputCommitter\"\n",
    "    )\n",
    "\n",
    "    ###### Submissions ###\n",
    "    \n",
    "    \n",
    "    required_columns = ['subreddit', 'title', 'selftext', 'score', 'created_utc', 'url']\n",
    "\n",
    "    # read the full year\n",
    "\n",
    "    # Read in data from project bucket\n",
    "    #bucket = \"project17-bucket-alex\"\n",
    "\n",
    "    # List of 12 directories each containing 1 month of data\n",
    "    directories = [\"project_2022_\"+str(i)+\"/submissions\" for i in range(1,13)]\n",
    "\n",
    "    # Iterate through 12 directories and merge each monthly data set to create one big data set\n",
    "    submissions = None\n",
    "    for directory in directories:\n",
    "        s3_path = f\"s3a://{args.s3_output_bucket}/{directory}\"\n",
    "        month_df = spark.read.parquet(s3_path).select(*required_columns)\n",
    "\n",
    "        if submissions is None:\n",
    "            submissions = month_df\n",
    "        else:\n",
    "            submissions = submissions.union(month_df)\n",
    "\n",
    "    \n",
    "    #submissions = spark.read.parquet(args.s3_dataset_path_submissions, header=True)\n",
    "    #submissions = spark.read.text(args.s3_dataset_path_submissions)\n",
    "    s3_path = f\"s3://{args.s3_output_bucket}/{args.s3_output_prefix}/submissions\"\n",
    "    logger.info(f\"going to write submissions for submissions in {s3_path}\")\n",
    "    submissions.write.mode(\"overwrite\").parquet(s3_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    books = spark.read.text(args.s3_dataset_path_books)\n",
    "    s3_path = f\"s3://{args.s3_output_bucket}/{args.s3_output_prefix}/books\"\n",
    "    logger.info(f\"going to write submissions for books in {s3_path}\")\n",
    "    books.write.mode(\"overwrite\").parquet(s3_path)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name sm-spark-project-2023-11-18-00-41-31-232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................!CPU times: user 639 ms, sys: 77.6 ms, total: 716 ms\n",
      "Wall time: 7min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker.spark.processing import PySparkProcessor\n",
    "\n",
    "# Setup the PySpark processor to run the job. Note the instance type and instance count parameters. SageMaker will create these many instances of this type for the spark job.\n",
    "role = sagemaker.get_execution_role()\n",
    "spark_processor = PySparkProcessor(\n",
    "    base_job_name=\"sm-spark-project\",\n",
    "    framework_version=\"3.3\",\n",
    "    role=role,\n",
    "    instance_count=8,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "\n",
    "# s3 paths\n",
    "session = sagemaker.Session()\n",
    "bucket = \"project17-bucket-alex\"\n",
    "s3_dataset_path_submissions = \"s3://project17-bucket-alex/books/*.txt\"\n",
    "s3_dataset_path_books = \"s3://project17-bucket-alex/books/*.txt\"\n",
    "output_prefix_data = \"stories-and-books-nlp\"\n",
    "output_prefix_logs = f\"spark_logs\"\n",
    "    \n",
    "# run the job now, the arguments array is provided as command line to the Python script (Spark code in this case).\n",
    "spark_processor.run(\n",
    "    submit_app=\"./project-nlp-posts-and-books-processing.py\",\n",
    "    arguments=[\n",
    "        \"--s3_dataset_path_submissions\",\n",
    "        s3_dataset_path_submissions,\n",
    "        \"--s3_dataset_path_books\",\n",
    "        s3_dataset_path_books,\n",
    "        \"--s3_output_bucket\",\n",
    "        bucket,\n",
    "        \"--s3_output_prefix\",\n",
    "        output_prefix_data,\n",
    "\n",
    "    ],\n",
    "    spark_event_logs_s3_uri=\"s3://{}/{}/spark_event_logs\".format(bucket, output_prefix_logs),\n",
    "    logs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the Gutenberg books into a Spark DataFrame\n",
    "gutenberg_df = spark.read.text(\"../../data/external-data/books/*.txt\")\n",
    "gutenberg_df = gutenberg_df.withColumnRenamed(\"value\", \"text\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws, col\n",
    "\n",
    "# Process `submissions_active` to extract and transform the 'selftext' column\n",
    "submissions_df = submissions_active.select(\"selftext\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For the Project Gutenberg DataFrame\n",
    "gutenberg_df = gutenberg_df.withColumnRenamed(\"value\", \"text\")\n",
    "\n",
    "# For the submissions DataFrame\n",
    "submissions_df = submissions_df.withColumnRenamed(\"selftext\", \"text\")\n",
    "\n",
    "# Now you can union them\n",
    "combined_df = gutenberg_df.unionByName(submissions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker.spark.processing import PySparkProcessor\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "spark_processor = PySparkProcessor(\n",
    "    base_job_name=\"sm-spark-nlp-project\",\n",
    "    framework_version=\"3.3\",\n",
    "    role=role,\n",
    "    instance_count=2,  # Adjust as needed\n",
    "    instance_type=\"ml.t3.xlarge\",\n",
    "    max_runtime_in_seconds=7200,\n",
    ")\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# Define your S3 paths and other parameters\n",
    "s3_dataset_path_submissions_bucket = \"project17-bucket-alex\"\n",
    "s3_dataset_path_gutenberg = \"s3://project17-bucket-alex/books/*.txt\"\n",
    "output_bucket = \"project17-bucket-alex/stories-and-books-nlp/\"\n",
    "\n",
    "# Run the PySpark job\n",
    "spark_processor.run(\n",
    "    submit_app=\"project-nlp-posts-and-books-processing.py\",\n",
    "    arguments=[\n",
    "        \"--s3_dataset_path_submissions_bucket\", s3_dataset_path_submissions_bucket,\n",
    "        \"--s3_dataset_path_gutenberg\", s3_dataset_path_gutenberg,\n",
    "        \"--s3_output_bucket\", output_bucket,\n",
    "    ],\n",
    "    spark_event_logs_s3_uri=f\"s3://{output_bucket}/spark_event_logs\",\n",
    "    logs=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
