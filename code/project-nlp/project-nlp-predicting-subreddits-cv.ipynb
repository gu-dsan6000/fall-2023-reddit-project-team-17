{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Here, we start back up again with a spark session that is capable of working with NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup - Run only once per Kernel App\n",
    "%conda install openjdk -y\n",
    "\n",
    "# install PySpark\n",
    "%pip install pyspark==3.4.0\n",
    "\n",
    "# install spark-nlp\n",
    "%pip install spark-nlp==5.1.3\n",
    "\n",
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sparknlp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sparknlp.base import *\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.annotator import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "from pyspark.sql.functions import col, lower, regexp_extract, regexp_replace, array, lit\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.sql.types import IntegerType, ArrayType, DoubleType\n",
    "# from pyspark.sql.functions import udf\n",
    "from pyspark.ml.linalg import SparseVector, Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pyspark and build Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"32G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3,org.apache.hadoop:hadoop-aws:3.2.2\")\\\n",
    "    .config(\"fs.s3a.aws.credentials.provider\", \"com.amazonaws.auth.ContainerCredentialsProvider\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.4.0\n",
      "sparknlp version: 5.1.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"sparknlp version: {sparknlp.version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Saved Data\n",
    "\n",
    "Here, we will read in the saved data above as a fresh starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/25 22:39:33 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.36 ms, sys: 2.59 ms, total: 8.95 ms\n",
      "Wall time: 7.07 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/25 22:39:39 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read in data from project bucket\n",
    "bucket = \"project17-bucket-alex\"\n",
    "directory = \"matt-submissions-age-gender\"\n",
    "\n",
    "s3_path = f\"s3a://{bucket}/{directory}\"\n",
    "submissions_age_gender = spark.read.parquet(s3_path, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+------------+\n",
      "|               title|            selftext|regex_age|regex_gender|\n",
      "+--------------------+--------------------+---------+------------+\n",
      "|my boyfriend(27) ...|So my boyfriend(m...|       27|           f|\n",
      "|Confused in an in...|\\nIn a new relati...|       21|           f|\n",
      "|Asking for phone ...|So, I (21M) was a...|       21|           m|\n",
      "|LDR bf of 3 month...|I(25F) met my bf(...|       25|           f|\n",
      "|I break up with m...|I (23m) shared a ...|       23|           m|\n",
      "|How can I get mor...|My boyfriend(32M)...|       23|           f|\n",
      "|I (35F) can't get...|So I live with an...|       35|           f|\n",
      "|I think I'm a les...|I (25f) have been...|       25|           f|\n",
      "|I (24F) snore too...|So, I (24 F) am i...|       24|           f|\n",
      "|One of my best fr...|I’m on mobile so ...|       21|           f|\n",
      "+--------------------+--------------------+---------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "submissions_age_gender.select(['title', 'selftext', 'regex_age', 'regex_gender']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = submissions_age_gender.select(['selftext', 'regex_age', 'regex_gender'])\n",
    "del(submissions_age_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'sentimentdl_use_twitter'\n",
    "\n",
    "documentAssembler = DocumentAssembler().setInputCol(\"selftext\").setOutputCol(\"document\")\n",
    "    \n",
    "use = UniversalSentenceEncoder.pretrained(name = \"tfhub_use\", lang = \"en\")\\\n",
    " .setInputCols([\"document\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "\n",
    "sentimentdl = SentimentDLModel.pretrained(name=MODEL_NAME, lang = \"en\")\\\n",
    "    .setInputCols([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"sentiment\")\n",
    "\n",
    "nlpPipeline = Pipeline(\n",
    "      stages = [\n",
    "          documentAssembler,\n",
    "          use,\n",
    "          sentimentdl\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pyspark == 3.4.0 works, pyspark == 3.5.0 does not\n",
    "pipelineModel = nlpPipeline.fit(df)\n",
    "results = pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------+---------+\n",
      "|            selftext|regex_age|regex_gender|sentiment|\n",
      "+--------------------+---------+------------+---------+\n",
      "|So my boyfriend(m...|       27|           f| negative|\n",
      "|\\nIn a new relati...|       21|           f|  neutral|\n",
      "|So, I (21M) was a...|       21|           m| negative|\n",
      "|I(25F) met my bf(...|       25|           f| negative|\n",
      "|I (23m) shared a ...|       23|           m| negative|\n",
      "|My boyfriend(32M)...|       23|           f| negative|\n",
      "|So I live with an...|       35|           f| negative|\n",
      "|I (25f) have been...|       25|           f| negative|\n",
      "|So, I (24 F) am i...|       24|           f| negative|\n",
      "|I’m on mobile so ...|       21|           f| negative|\n",
      "|TDLR: can ex’s be...|       22|           f| negative|\n",
      "|I (22m) have been...|       22|           m| negative|\n",
      "|I (21f) am having...|       21|           f| negative|\n",
      "|I (16f) am thinki...|       16|           f| negative|\n",
      "|Hi everyone. I (2...|       21|           f| negative|\n",
      "|I (32f) and my pa...|       32|           f| negative|\n",
      "|This is a throwaw...|       39|           f| negative|\n",
      "|I (13B) have gott...|       13|           b| negative|\n",
      "|i(22F) have crush...|       22|           f| negative|\n",
      "|My bf (22M) and I...|       20|           f| negative|\n",
      "+--------------------+---------+------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = results.withColumn('sentiment', F.explode(results.sentiment.result))\n",
    "final_data = results.select('selftext', 'regex_age', 'regex_gender', 'sentiment')\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_data.write.parquet(\n",
    "    \"s3a://project17-bucket-alex/matt-age-gender-sentiment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_data = final_data.select('regex_age', 'regex_gender', 'sentiment').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save the results to CSV for visualization\n",
    "final_data.toPandas().to_csv('../../data/nlp-data/submission_age_gender_sentiment_new.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------+\n",
      "|            selftext|regex_age|regex_gender|\n",
      "+--------------------+---------+------------+\n",
      "|So my boyfriend(m...|       27|           f|\n",
      "|\\nIn a new relati...|       21|           f|\n",
      "|So, I (21M) was a...|       21|           m|\n",
      "|I(25F) met my bf(...|       25|           f|\n",
      "|I (23m) shared a ...|       23|           m|\n",
      "|My boyfriend(32M)...|       23|           f|\n",
      "|So I live with an...|       35|           f|\n",
      "|I (25f) have been...|       25|           f|\n",
      "|So, I (24 F) am i...|       24|           f|\n",
      "|I’m on mobile so ...|       21|           f|\n",
      "+--------------------+---------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the initial data\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------+\n",
      "|            selftext|regex_age|regex_gender|\n",
      "+--------------------+---------+------------+\n",
      "|So my boyfriend(m...|       27|           f|\n",
      "|\\nIn a new relati...|       21|           f|\n",
      "|So, I (21M) was a...|       21|           m|\n",
      "|I(25F) met my bf(...|       25|           f|\n",
      "|I (23m) shared a ...|       23|           m|\n",
      "|My boyfriend(32M)...|       23|           f|\n",
      "|So I live with an...|       35|           f|\n",
      "|I (25f) have been...|       25|           f|\n",
      "|So, I (24 F) am i...|       24|           f|\n",
      "|I’m on mobile so ...|       21|           f|\n",
      "+--------------------+---------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take a 10-row sample just for testing\n",
    "df_test = df.limit(128).cache()\n",
    "df_test.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------+\n",
      "|            selftext|regex_age|regex_gender|\n",
      "+--------------------+---------+------------+\n",
      "|so my boyfriendm ...|       27|           f|\n",
      "|in a new relation...|       21|           f|\n",
      "|so i m was at a p...|       21|           m|\n",
      "|if met my bfm on ...|       25|           f|\n",
      "|i m shared a tikt...|       23|           m|\n",
      "|my boyfriendm and...|       23|           f|\n",
      "|so i live with an...|       35|           f|\n",
      "|i f have been ref...|       25|           f|\n",
      "|so i  f am in a r...|       24|           f|\n",
      "|i’m on mobile so ...|       21|           f|\n",
      "+--------------------+---------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# keep only alphanumeric characters and spaces\n",
    "df_test = df_test.withColumn('selftext', lower(regexp_replace('selftext', '[\\(\\)\\{\\},.:;\\'\\\"\\n\\*0-9]', '')))\n",
    "df_test.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documentAssembler = DocumentAssembler().setInputCol(\"selftext\").setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"tokenized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner().pretrained(\"stopwords_iso\", \"en\").setInputCols([\"tokenized\"]).setOutputCol(\"cleaned\")\n",
    "\n",
    "stemmer = Stemmer().setInputCols([\"cleaned\"]).setOutputCol(\"stemmed\")\n",
    "\n",
    "lemmatizer = LemmatizerModel.pretrained().setInputCols([\"stemmed\"]).setOutputCol(\"lemmatized\")\n",
    "\n",
    "# countvectorizer = CountVectorizer().setInputCol(\"lemmatized\").setOutputCol(\"cv\")\n",
    "\n",
    "nlpPipeline = Pipeline(\n",
    "      stages = [\n",
    "          documentAssembler,\n",
    "          tokenizer,\n",
    "          stopwords_cleaner,\n",
    "          stemmer,\n",
    "          lemmatizer\n",
    "          # countvectorizer\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fit and transform the data using the pipeline\n",
    "pipelineModel = nlpPipeline.fit(df_test)\n",
    "results = pipelineModel.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            selftext|              result|\n",
      "+--------------------+--------------------+\n",
      "|so my boyfriendm ...|[boyfriendm, f, d...|\n",
      "|in a new relation...|[new, relationshi...|\n",
      "|so i m was at a p...|[m, parti, night,...|\n",
      "|if met my bfm on ...|[meet, bfm, cruis...|\n",
      "|i m shared a tikt...|[m, share, tiktok...|\n",
      "|my boyfriendm and...|[boyfriendm, date...|\n",
      "|so i live with an...|[live, hous, yr, ...|\n",
      "|i f have been ref...|[f, reflect, rece...|\n",
      "|so i  f am in a r...|[f, relationship,...|\n",
      "|i’m on mobile so ...|[i’m, mobil, sorr...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract the result from the lemmatizer (has other unneeded data)\n",
    "results = results.withColumn('result', col('lemmatized').result)\n",
    "results.select('selftext', 'result').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# build the countvectorizer\n",
    "n_words = 500\n",
    "countvectorizer = CountVectorizer(vocabSize = n_words).setInputCol(\"result\").setOutputCol(\"cv\")\n",
    "\n",
    "# fit and transform the data using CV\n",
    "fitted = countvectorizer.fit(results)\n",
    "transformed = fitted.transform(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|            selftext|              result|                  cv|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|so my boyfriendm ...|[boyfriendm, f, d...|(500,[0,1,2,4,5,9...|\n",
      "|in a new relation...|[new, relationshi...|(500,[0,1,2,3,5,6...|\n",
      "|so i m was at a p...|[m, parti, night,...|(500,[2,3,4,7,12,...|\n",
      "|if met my bfm on ...|[meet, bfm, cruis...|(500,[0,2,3,5,7,1...|\n",
      "|i m shared a tikt...|[m, share, tiktok...|(500,[6,15,20,33,...|\n",
      "|my boyfriendm and...|[boyfriendm, date...|(500,[0,1,3,4,5,6...|\n",
      "|so i live with an...|[live, hous, yr, ...|(500,[0,1,2,3,4,5...|\n",
      "|i f have been ref...|[f, reflect, rece...|(500,[0,3,7,9,10,...|\n",
      "|so i  f am in a r...|[f, relationship,...|(500,[6,9,14,15,1...|\n",
      "|i’m on mobile so ...|[i’m, mobil, sorr...|(500,[1,2,3,4,5,7...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed.select('selftext', 'result', 'cv').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like',\n",
       " 'feel',\n",
       " 'want',\n",
       " 'know',\n",
       " 'friend',\n",
       " 'time',\n",
       " 'tell',\n",
       " 'think',\n",
       " 'i’m',\n",
       " 'year']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary, which is sorted by frequency of use in the dataset\n",
    "top_n_words = fitted.vocabulary\n",
    "top_n_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------------------+\n",
      "|              result|result_exploded|                  cv|\n",
      "+--------------------+---------------+--------------------+\n",
      "|[boyfriendm, f, d...|     boyfriendm|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|              f|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|          drink|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|          night|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|     dissappear|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|             fo|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|           half|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|           hour|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|           turn|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|             go|(500,[0,1,2,4,5,9...|\n",
      "+--------------------+---------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explode the lemmatized results\n",
    "transformed = transformed.withColumn('result_exploded', F.explode(transformed.result))\n",
    "transformed.select('result', 'result_exploded', 'cv').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------------------+\n",
      "|              result|result_exploded|                  cv|\n",
      "+--------------------+---------------+--------------------+\n",
      "|[boyfriendm, f, d...|              f|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|          drink|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|          night|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|           half|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|           hour|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|           turn|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|             go|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|           call|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|         answer|(500,[0,1,2,4,5,9...|\n",
      "|[boyfriendm, f, d...|            sit|(500,[0,1,2,4,5,9...|\n",
      "+--------------------+---------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter for words in the top-n vocabulary\n",
    "transformed = transformed.filter(col('result_exploded').isin(top_n_words))\n",
    "transformed.select('result', 'result_exploded', 'cv').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a user-defined-function to apply to the cv column to extract dense vector representations\n",
    "to_dense = udf(lambda v: v.toArray().tolist(), ArrayType(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                  cv|            cv_array|\n",
      "+--------------------+--------------------+\n",
      "|(2976,[0,1,2,4,5,...|[3.0, 2.0, 1.0, 0...|\n",
      "|(2976,[0,1,2,3,5,...|[10.0, 1.0, 1.0, ...|\n",
      "|(2976,[2,3,4,7,8,...|[0.0, 0.0, 1.0, 1...|\n",
      "|(2976,[0,2,3,5,7,...|[1.0, 0.0, 7.0, 2...|\n",
      "|(2976,[6,8,16,21,...|[0.0, 0.0, 0.0, 0...|\n",
      "|(2976,[0,1,3,4,5,...|[4.0, 4.0, 0.0, 2...|\n",
      "|(2976,[0,1,2,3,4,...|[2.0, 9.0, 3.0, 2...|\n",
      "|(2976,[0,3,7,10,1...|[1.0, 0.0, 0.0, 1...|\n",
      "|(2976,[6,10,15,16...|[0.0, 0.0, 0.0, 0...|\n",
      "|(2976,[1,2,3,4,5,...|[0.0, 2.0, 1.0, 1...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# apply the UDF and see the result of the transformation\n",
    "transformed_array = transformed.withColumn('cv_array', to_dense('cv')).cache()\n",
    "transformed_array.select('cv', 'cv_array').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# calculate the word frequencies by summing the cv_array column\n",
    "word_freqs = (\n",
    "    transformed_array\n",
    "    .repartition(8, 'cv_array')\n",
    "    .rdd\n",
    "    .map(lambda row: row['cv_array'])\n",
    "    .reduce(lambda x, y: [x[i] + y[i] for i in range(len(x))])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[275.0, 262.0, 252.0, 206.0, 185.0, 182.0, 176.0, 160.0, 154.0, 153.0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer FULL DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------+-------+\n",
      "|            selftext|regex_age|regex_gender|mono_id|\n",
      "+--------------------+---------+------------+-------+\n",
      "|so my boyfriendm ...|       27|           f|      0|\n",
      "|in a new relation...|       21|           f|      1|\n",
      "|so i m was at a p...|       21|           m|      2|\n",
      "|if met my bfm on ...|       25|           f|      3|\n",
      "|i m shared a tikt...|       23|           m|      4|\n",
      "|my boyfriendm and...|       23|           f|      5|\n",
      "|so i live with an...|       35|           f|      6|\n",
      "|i f have been ref...|       25|           f|      7|\n",
      "|so i  f am in a r...|       24|           f|      8|\n",
      "|i’m on mobile so ...|       21|           f|      9|\n",
      "+--------------------+---------+------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the initial data\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------+-------+\n",
      "|            selftext|regex_age|regex_gender|mono_id|\n",
      "+--------------------+---------+------------+-------+\n",
      "|so my boyfriendm ...|       27|           f|      0|\n",
      "|in a new relation...|       21|           f|      1|\n",
      "|so i m was at a p...|       21|           m|      2|\n",
      "|if met my bfm on ...|       25|           f|      3|\n",
      "|i m shared a tikt...|       23|           m|      4|\n",
      "|my boyfriendm and...|       23|           f|      5|\n",
      "|so i live with an...|       35|           f|      6|\n",
      "|i f have been ref...|       25|           f|      7|\n",
      "|so i  f am in a r...|       24|           f|      8|\n",
      "|i’m on mobile so ...|       21|           f|      9|\n",
      "+--------------------+---------+------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# keep only alphanumeric characters and spaces\n",
    "df = df.withColumn('mono_id', F.monotonically_increasing_id())\n",
    "df = df.withColumn('selftext', F.lower(F.regexp_replace('selftext', '[\\(\\)\\{\\},.:;\\'\\\"\\?\\n\\*0-9]', '')))\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL_NAME = 'sentimentdl_use_twitter'\n",
    "\n",
    "documentAssembler = DocumentAssembler().setInputCol(\"selftext\").setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"tokenized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner().pretrained(\"stopwords_iso\", \"en\").setInputCols([\"tokenized\"]).setOutputCol(\"cleaned\")\n",
    "\n",
    "stemmer = Stemmer().setInputCols([\"cleaned\"]).setOutputCol(\"stemmed\")\n",
    "\n",
    "lemmatizer = LemmatizerModel.pretrained().setInputCols([\"stemmed\"]).setOutputCol(\"lemmatized\")\n",
    "\n",
    "# countvectorizer = CountVectorizer().setInputCol(\"lemmatized\").setOutputCol(\"cv\")\n",
    "\n",
    "nlpPipeline = Pipeline(\n",
    "      stages = [\n",
    "          documentAssembler,\n",
    "          tokenizer,\n",
    "          stopwords_cleaner,\n",
    "          stemmer,\n",
    "          lemmatizer\n",
    "          # countvectorizer\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fit and transform the data using the pipeline\n",
    "pipelineModel = nlpPipeline.fit(df)\n",
    "results = pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            selftext|              result|\n",
      "+--------------------+--------------------+\n",
      "|so my boyfriendm ...|[boyfriendm, f, d...|\n",
      "|in a new relation...|[new, relationshi...|\n",
      "|so i m was at a p...|[m, parti, night,...|\n",
      "|if met my bfm on ...|[meet, bfm, cruis...|\n",
      "|i m shared a tikt...|[m, share, tiktok...|\n",
      "|my boyfriendm and...|[boyfriendm, date...|\n",
      "|so i live with an...|[live, hous, yr, ...|\n",
      "|i f have been ref...|[f, reflect, rece...|\n",
      "|so i  f am in a r...|[f, relationship,...|\n",
      "|i’m on mobile so ...|[i’m, mobil, sorr...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract the result from the lemmatizer (has other unneeded data)\n",
    "results = results.withColumn('result', F.col('lemmatized').result)\n",
    "results.select('selftext', 'result').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# build the countvectorizer\n",
    "n_words = 500\n",
    "countvectorizer = CountVectorizer(vocabSize = n_words).setInputCol(\"result\").setOutputCol(\"cv\")\n",
    "\n",
    "# fit and transform the data using CV\n",
    "fitted = countvectorizer.fit(results)\n",
    "transformed = fitted.transform(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+\n",
      "|mono_id|            selftext|              result|                  cv|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "|      0|so my boyfriendm ...|[boyfriendm, f, d...|(500,[0,1,2,3,6,1...|\n",
      "|      1|in a new relation...|[new, relationshi...|(500,[0,1,2,3,4,5...|\n",
      "|      2|so i m was at a p...|[m, parti, night,...|(500,[2,4,6,7,15,...|\n",
      "|      3|if met my bfm on ...|[meet, bfm, cruis...|(500,[1,2,3,4,7,9...|\n",
      "|      4|i m shared a tikt...|[m, share, tiktok...|(500,[5,17,21,30,...|\n",
      "|      5|my boyfriendm and...|[boyfriendm, date...|(500,[0,1,3,4,5,6...|\n",
      "|      6|so i live with an...|[live, hous, yr, ...|(500,[0,1,2,3,4,6...|\n",
      "|      7|i f have been ref...|[f, reflect, rece...|(500,[1,4,7,8,10,...|\n",
      "|      8|so i  f am in a r...|[f, relationship,...|(500,[5,8,10,11,1...|\n",
      "|      9|i’m on mobile so ...|[i’m, mobil, sorr...|(500,[0,2,3,4,6,7...|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed.select('mono_id', 'selftext', 'result', 'cv').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|              result|                  cv|            cv_array|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[boyfriendm, f, d...|(500,[0,1,2,3,6,1...|[2.0, 3.0, 1.0, 1...|\n",
      "|[new, relationshi...|(500,[0,1,2,3,4,5...|[1.0, 10.0, 1.0, ...|\n",
      "|[m, parti, night,...|(500,[2,4,6,7,15,...|[0.0, 0.0, 1.0, 0...|\n",
      "|[meet, bfm, cruis...|(500,[1,2,3,4,7,9...|[0.0, 1.0, 7.0, 2...|\n",
      "|[m, share, tiktok...|(500,[5,17,21,30,...|[0.0, 0.0, 0.0, 0...|\n",
      "|[boyfriendm, date...|(500,[0,1,3,4,5,6...|[4.0, 4.0, 0.0, 2...|\n",
      "|[live, hous, yr, ...|(500,[0,1,2,3,4,6...|[9.0, 2.0, 3.0, 1...|\n",
      "|[f, reflect, rece...|(500,[1,4,7,8,10,...|[0.0, 1.0, 0.0, 0...|\n",
      "|[f, relationship,...|(500,[5,8,10,11,1...|[0.0, 0.0, 0.0, 0...|\n",
      "|[i’m, mobil, sorr...|(500,[0,2,3,4,6,7...|[2.0, 0.0, 1.0, 2...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# make a user-defined-function to apply to the cv column to extract dense vector representations\n",
    "to_dense = F.udf(lambda v: v.toArray().tolist(), ArrayType(DoubleType()))\n",
    "\n",
    "# apply the UDF and see the result of the transformation\n",
    "transformed_array = transformed.withColumn('cv_array', to_dense('cv'))\n",
    "transformed_array.select('result', 'cv', 'cv_array').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feel',\n",
       " 'like',\n",
       " 'want',\n",
       " 'time',\n",
       " 'know',\n",
       " 'tell',\n",
       " 'friend',\n",
       " 'think',\n",
       " 'relationship',\n",
       " 'thing']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab the sorted vocabulary from the CV model\n",
    "top_n_words = fitted.vocabulary\n",
    "top_n_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a dataframe with one column per word, with values as their frequencies within each post\n",
    "word_counts_df = transformed_array.select(\n",
    "    ['mono_id', 'regex_age', 'regex_gender'] + [(F.col(\"cv_array\")[x]).alias(top_n_words[x]) for x in range(0, len(top_n_words))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+----+----+----+----+----+----+------+-----+------------+-----+\n",
      "|regex_age|regex_gender|feel|like|want|time|know|tell|friend|think|relationship|thing|\n",
      "+---------+------------+----+----+----+----+----+----+------+-----+------------+-----+\n",
      "|       27|           f| 2.0| 3.0| 1.0| 1.0| 0.0| 0.0|   1.0|  0.0|         0.0|  0.0|\n",
      "|       21|           f| 1.0|10.0| 1.0| 2.0| 2.0| 2.0|   0.0|  3.0|         1.0|  1.0|\n",
      "|       21|           m| 0.0| 0.0| 1.0| 0.0| 1.0| 0.0|   2.0|  1.0|         0.0|  0.0|\n",
      "|       25|           f| 0.0| 1.0| 7.0| 2.0| 2.0| 0.0|   0.0|  1.0|         0.0|  1.0|\n",
      "|       23|           m| 0.0| 0.0| 0.0| 0.0| 0.0| 1.0|   0.0|  0.0|         0.0|  0.0|\n",
      "|       23|           f| 4.0| 4.0| 0.0| 2.0| 2.0| 3.0|   4.0|  1.0|         0.0|  3.0|\n",
      "|       35|           f| 9.0| 2.0| 3.0| 1.0| 2.0| 0.0|   2.0|  1.0|         2.0|  1.0|\n",
      "|       25|           f| 0.0| 1.0| 0.0| 0.0| 1.0| 0.0|   0.0|  2.0|         2.0|  0.0|\n",
      "|       24|           f| 0.0| 0.0| 0.0| 0.0| 0.0| 1.0|   0.0|  0.0|         1.0|  0.0|\n",
      "|       21|           f| 2.0| 0.0| 1.0| 2.0| 1.0| 0.0|   3.0|  2.0|         0.0|  0.0|\n",
      "+---------+------------+----+----+----+----+----+----+------+-----+------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# show the result\n",
    "word_counts_df_sample = word_counts_df.select(['regex_age', 'regex_gender'] + top_n_words[:10]).limit(10).cache()\n",
    "word_counts_df_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save off to CSV for visualization later\n",
    "word_counts_df_sample.toPandas().to_csv('../../data/nlp-data/age-gender-cv-sample.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
