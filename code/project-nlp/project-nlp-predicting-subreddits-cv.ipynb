{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Here, we start back up again with a spark session that is capable of working with NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup - Run only once per Kernel App\n",
    "%conda install openjdk -y\n",
    "\n",
    "# install PySpark\n",
    "%pip install pyspark==3.4.0\n",
    "\n",
    "# install spark-nlp\n",
    "%pip install spark-nlp==5.1.3\n",
    "\n",
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sparknlp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sparknlp.base import *\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.annotator import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "from pyspark.sql.functions import col, lower, regexp_extract, regexp_replace, array, lit\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.sql.types import IntegerType, ArrayType, DoubleType\n",
    "# from pyspark.sql.functions import udf\n",
    "from pyspark.ml.linalg import SparseVector, Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pyspark and build Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"32G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3,org.apache.hadoop:hadoop-aws:3.2.2\")\\\n",
    "    .config(\"fs.s3a.aws.credentials.provider\", \"com.amazonaws.auth.ContainerCredentialsProvider\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.4.0\n",
      "sparknlp version: 5.1.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"sparknlp version: {sparknlp.version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Saved Data\n",
    "\n",
    "Here, we will read in the saved data above as a fresh starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.61 ms, sys: 0 ns, total: 3.61 ms\n",
      "Wall time: 483 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read in data from project bucket\n",
    "bucket = \"project17-bucket-alex\"\n",
    "directory = \"matt-submissions-age-gender\"\n",
    "\n",
    "s3_path = f\"s3a://{bucket}/{directory}\"\n",
    "submissions_age_gender = spark.read.parquet(s3_path, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+------------+\n",
      "|               title|            selftext|regex_age|regex_gender|\n",
      "+--------------------+--------------------+---------+------------+\n",
      "|my boyfriend(27) ...|So my boyfriend(m...|       27|           f|\n",
      "|Confused in an in...|\\nIn a new relati...|       21|           f|\n",
      "|Asking for phone ...|So, I (21M) was a...|       21|           m|\n",
      "|LDR bf of 3 month...|I(25F) met my bf(...|       25|           f|\n",
      "|I break up with m...|I (23m) shared a ...|       23|           m|\n",
      "|How can I get mor...|My boyfriend(32M)...|       23|           f|\n",
      "|I (35F) can't get...|So I live with an...|       35|           f|\n",
      "|I think I'm a les...|I (25f) have been...|       25|           f|\n",
      "|I (24F) snore too...|So, I (24 F) am i...|       24|           f|\n",
      "|One of my best fr...|I’m on mobile so ...|       21|           f|\n",
      "+--------------------+--------------------+---------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "submissions_age_gender.select(['title', 'selftext', 'regex_age', 'regex_gender']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = submissions_age_gender.select(['selftext', 'regex_age', 'regex_gender'])\n",
    "del(submissions_age_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'sentimentdl_use_twitter'\n",
    "\n",
    "documentAssembler = DocumentAssembler().setInputCol(\"selftext\").setOutputCol(\"document\")\n",
    "    \n",
    "use = UniversalSentenceEncoder.pretrained(name = \"tfhub_use\", lang = \"en\")\\\n",
    " .setInputCols([\"document\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "\n",
    "sentimentdl = SentimentDLModel.pretrained(name=MODEL_NAME, lang = \"en\")\\\n",
    "    .setInputCols([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"sentiment\")\n",
    "\n",
    "nlpPipeline = Pipeline(\n",
    "      stages = [\n",
    "          documentAssembler,\n",
    "          use,\n",
    "          sentimentdl\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pyspark == 3.4.0 works, pyspark == 3.5.0 does not\n",
    "pipelineModel = nlpPipeline.fit(df)\n",
    "results = pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------+---------+\n",
      "|            selftext|regex_age|regex_gender|sentiment|\n",
      "+--------------------+---------+------------+---------+\n",
      "|So my boyfriend(m...|       27|           f| negative|\n",
      "|\\nIn a new relati...|       21|           f|  neutral|\n",
      "|So, I (21M) was a...|       21|           m| negative|\n",
      "|I(25F) met my bf(...|       25|           f| negative|\n",
      "|I (23m) shared a ...|       23|           m| negative|\n",
      "|My boyfriend(32M)...|       23|           f| negative|\n",
      "|So I live with an...|       35|           f| negative|\n",
      "|I (25f) have been...|       25|           f| negative|\n",
      "|So, I (24 F) am i...|       24|           f| negative|\n",
      "|I’m on mobile so ...|       21|           f| negative|\n",
      "|TDLR: can ex’s be...|       22|           f| negative|\n",
      "|I (22m) have been...|       22|           m| negative|\n",
      "|I (21f) am having...|       21|           f| negative|\n",
      "|I (16f) am thinki...|       16|           f| negative|\n",
      "|Hi everyone. I (2...|       21|           f| negative|\n",
      "|I (32f) and my pa...|       32|           f| negative|\n",
      "|This is a throwaw...|       39|           f| negative|\n",
      "|I (13B) have gott...|       13|           b| negative|\n",
      "|i(22F) have crush...|       22|           f| negative|\n",
      "|My bf (22M) and I...|       20|           f| negative|\n",
      "+--------------------+---------+------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = results.withColumn('sentiment', F.explode(results.sentiment.result))\n",
    "final_data = results.select('selftext', 'regex_age', 'regex_gender', 'sentiment')\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_data.write.parquet(\n",
    "    \"s3a://project17-bucket-alex/matt-age-gender-sentiment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_data = final_data.select('regex_age', 'regex_gender', 'sentiment').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save the results to CSV for visualization\n",
    "final_data.toPandas().to_csv('../../data/nlp-data/submission_age_gender_sentiment_new.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer on `relationship_advice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------+\n",
      "|            selftext|regex_age|regex_gender|\n",
      "+--------------------+---------+------------+\n",
      "|So my boyfriend(m...|       27|           f|\n",
      "|\\nIn a new relati...|       21|           f|\n",
      "|So, I (21M) was a...|       21|           m|\n",
      "|I(25F) met my bf(...|       25|           f|\n",
      "|I (23m) shared a ...|       23|           m|\n",
      "|My boyfriend(32M)...|       23|           f|\n",
      "|So I live with an...|       35|           f|\n",
      "|I (25f) have been...|       25|           f|\n",
      "|So, I (24 F) am i...|       24|           f|\n",
      "|I’m on mobile so ...|       21|           f|\n",
      "+--------------------+---------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the initial data\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------+-------+\n",
      "|            selftext|regex_age|regex_gender|mono_id|\n",
      "+--------------------+---------+------------+-------+\n",
      "|so my boyfriendm ...|       27|           f|      0|\n",
      "|in a new relation...|       21|           f|      1|\n",
      "|so i m was at a p...|       21|           m|      2|\n",
      "|if met my bfm on ...|       25|           f|      3|\n",
      "|i m shared a tikt...|       23|           m|      4|\n",
      "|my boyfriendm and...|       23|           f|      5|\n",
      "|so i live with an...|       35|           f|      6|\n",
      "|i f have been ref...|       25|           f|      7|\n",
      "|so i  f am in a r...|       24|           f|      8|\n",
      "|i’m on mobile so ...|       21|           f|      9|\n",
      "+--------------------+---------+------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# keep only alphanumeric characters and spaces\n",
    "df = df.withColumn('mono_id', F.monotonically_increasing_id())\n",
    "df = df.withColumn('selftext', F.lower(F.regexp_replace('selftext', '[\\(\\)\\{\\},.:;\\'\\\"\\?\\n\\*0-9]', '')))\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "documentAssembler = DocumentAssembler().setInputCol(\"selftext\").setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"tokenized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner().pretrained(\"stopwords_iso\", \"en\").setInputCols([\"tokenized\"]).setOutputCol(\"cleaned\")\n",
    "\n",
    "stemmer = Stemmer().setInputCols([\"cleaned\"]).setOutputCol(\"stemmed\")\n",
    "\n",
    "lemmatizer = LemmatizerModel.pretrained().setInputCols([\"stemmed\"]).setOutputCol(\"lemmatized\")\n",
    "\n",
    "# countvectorizer = CountVectorizer().setInputCol(\"lemmatized\").setOutputCol(\"cv\")\n",
    "\n",
    "nlpPipeline = Pipeline(\n",
    "      stages = [\n",
    "          documentAssembler,\n",
    "          tokenizer,\n",
    "          stopwords_cleaner,\n",
    "          stemmer,\n",
    "          lemmatizer\n",
    "          # countvectorizer\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fit and transform the data using the pipeline\n",
    "pipelineModel = nlpPipeline.fit(df)\n",
    "results = pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            selftext|              result|\n",
      "+--------------------+--------------------+\n",
      "|so my boyfriendm ...|[boyfriendm, f, d...|\n",
      "|in a new relation...|[new, relationshi...|\n",
      "|so i m was at a p...|[m, parti, night,...|\n",
      "|if met my bfm on ...|[meet, bfm, cruis...|\n",
      "|i m shared a tikt...|[m, share, tiktok...|\n",
      "|my boyfriendm and...|[boyfriendm, date...|\n",
      "|so i live with an...|[live, hous, yr, ...|\n",
      "|i f have been ref...|[f, reflect, rece...|\n",
      "|so i  f am in a r...|[f, relationship,...|\n",
      "|i’m on mobile so ...|[i’m, mobil, sorr...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract the result from the lemmatizer (has other unneeded data)\n",
    "results = results.withColumn('result', F.col('lemmatized').result)\n",
    "results.select('selftext', 'result').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# build the countvectorizer\n",
    "n_words = 500\n",
    "countvectorizer = CountVectorizer(vocabSize = n_words).setInputCol(\"result\").setOutputCol(\"cv\")\n",
    "\n",
    "# fit and transform the data using CV\n",
    "fitted = countvectorizer.fit(results)\n",
    "transformed = fitted.transform(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+\n",
      "|mono_id|            selftext|              result|                  cv|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "|      0|so my boyfriendm ...|[boyfriendm, f, d...|(500,[0,1,2,3,6,1...|\n",
      "|      1|in a new relation...|[new, relationshi...|(500,[0,1,2,3,4,5...|\n",
      "|      2|so i m was at a p...|[m, parti, night,...|(500,[2,4,6,7,15,...|\n",
      "|      3|if met my bfm on ...|[meet, bfm, cruis...|(500,[1,2,3,4,7,9...|\n",
      "|      4|i m shared a tikt...|[m, share, tiktok...|(500,[5,17,21,30,...|\n",
      "|      5|my boyfriendm and...|[boyfriendm, date...|(500,[0,1,3,4,5,6...|\n",
      "|      6|so i live with an...|[live, hous, yr, ...|(500,[0,1,2,3,4,6...|\n",
      "|      7|i f have been ref...|[f, reflect, rece...|(500,[1,4,7,8,10,...|\n",
      "|      8|so i  f am in a r...|[f, relationship,...|(500,[5,8,10,11,1...|\n",
      "|      9|i’m on mobile so ...|[i’m, mobil, sorr...|(500,[0,2,3,4,6,7...|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed.select('mono_id', 'selftext', 'result', 'cv').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|              result|                  cv|            cv_array|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[boyfriendm, f, d...|(500,[0,1,2,3,6,1...|[2.0, 3.0, 1.0, 1...|\n",
      "|[new, relationshi...|(500,[0,1,2,3,4,5...|[1.0, 10.0, 1.0, ...|\n",
      "|[m, parti, night,...|(500,[2,4,6,7,15,...|[0.0, 0.0, 1.0, 0...|\n",
      "|[meet, bfm, cruis...|(500,[1,2,3,4,7,9...|[0.0, 1.0, 7.0, 2...|\n",
      "|[m, share, tiktok...|(500,[5,17,21,30,...|[0.0, 0.0, 0.0, 0...|\n",
      "|[boyfriendm, date...|(500,[0,1,3,4,5,6...|[4.0, 4.0, 0.0, 2...|\n",
      "|[live, hous, yr, ...|(500,[0,1,2,3,4,6...|[9.0, 2.0, 3.0, 1...|\n",
      "|[f, reflect, rece...|(500,[1,4,7,8,10,...|[0.0, 1.0, 0.0, 0...|\n",
      "|[f, relationship,...|(500,[5,8,10,11,1...|[0.0, 0.0, 0.0, 0...|\n",
      "|[i’m, mobil, sorr...|(500,[0,2,3,4,6,7...|[2.0, 0.0, 1.0, 2...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# make a user-defined-function to apply to the cv column to extract dense vector representations\n",
    "to_dense = F.udf(lambda v: v.toArray().tolist(), ArrayType(DoubleType()))\n",
    "\n",
    "# apply the UDF and see the result of the transformation\n",
    "transformed_array = transformed.withColumn('cv_array', to_dense('cv'))\n",
    "transformed_array.select('result', 'cv', 'cv_array').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feel',\n",
       " 'like',\n",
       " 'want',\n",
       " 'time',\n",
       " 'know',\n",
       " 'tell',\n",
       " 'friend',\n",
       " 'think',\n",
       " 'relationship',\n",
       " 'thing']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab the sorted vocabulary from the CV model\n",
    "top_n_words = fitted.vocabulary\n",
    "top_n_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a dataframe with one column per word, with values as their frequencies within each post\n",
    "word_counts_df = transformed_array.select(\n",
    "    ['mono_id', 'regex_age', 'regex_gender'] + [(F.col(\"cv_array\")[x]).alias(top_n_words[x]) for x in range(0, len(top_n_words))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+----+----+----+----+----+----+------+-----+------------+-----+\n",
      "|regex_age|regex_gender|feel|like|want|time|know|tell|friend|think|relationship|thing|\n",
      "+---------+------------+----+----+----+----+----+----+------+-----+------------+-----+\n",
      "|       27|           f| 2.0| 3.0| 1.0| 1.0| 0.0| 0.0|   1.0|  0.0|         0.0|  0.0|\n",
      "|       21|           f| 1.0|10.0| 1.0| 2.0| 2.0| 2.0|   0.0|  3.0|         1.0|  1.0|\n",
      "|       21|           m| 0.0| 0.0| 1.0| 0.0| 1.0| 0.0|   2.0|  1.0|         0.0|  0.0|\n",
      "|       25|           f| 0.0| 1.0| 7.0| 2.0| 2.0| 0.0|   0.0|  1.0|         0.0|  1.0|\n",
      "|       23|           m| 0.0| 0.0| 0.0| 0.0| 0.0| 1.0|   0.0|  0.0|         0.0|  0.0|\n",
      "|       23|           f| 4.0| 4.0| 0.0| 2.0| 2.0| 3.0|   4.0|  1.0|         0.0|  3.0|\n",
      "|       35|           f| 9.0| 2.0| 3.0| 1.0| 2.0| 0.0|   2.0|  1.0|         2.0|  1.0|\n",
      "|       25|           f| 0.0| 1.0| 0.0| 0.0| 1.0| 0.0|   0.0|  2.0|         2.0|  0.0|\n",
      "|       24|           f| 0.0| 0.0| 0.0| 0.0| 0.0| 1.0|   0.0|  0.0|         1.0|  0.0|\n",
      "|       21|           f| 2.0| 0.0| 1.0| 2.0| 1.0| 0.0|   3.0|  2.0|         0.0|  0.0|\n",
      "+---------+------------+----+----+----+----+----+----+------+-----+------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# show the result\n",
    "word_counts_df_sample = word_counts_df.select(['regex_age', 'regex_gender'] + top_n_words[:10]).limit(10).cache()\n",
    "word_counts_df_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save off to CSV for visualization later\n",
    "word_counts_df_sample.toPandas().to_csv('../../data/nlp-data/age-gender-cv-sample.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer on Full DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/26 15:32:19 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "23/11/26 15:32:24 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.9 ms, sys: 3.15 ms, total: 31.1 ms\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read in data from project bucket\n",
    "bucket = \"project17-bucket-alex\"\n",
    "#output_prefix_data = \"project_2022\"\n",
    "\n",
    "# List of 12 directories each containing 1 month of data\n",
    "directories = [\"project_2022_\" + str(i) + \"/submissions\" for i in range(1, 13)]\n",
    "\n",
    "# Iterate through 12 directories and merge each monthly data set to create one big data set\n",
    "submissions = None\n",
    "for directory in directories:\n",
    "    s3_path = f\"s3a://{bucket}/{directory}\"\n",
    "    month_df = spark.read.parquet(s3_path, header = True)\n",
    "    \n",
    "    if submissions is None:\n",
    "        submissions = month_df\n",
    "    else:\n",
    "        submissions = submissions.union(month_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+--------------------+--------------------+-------------------+------------+\n",
      "|        subreddit|             author|               title|            selftext|        created_utc|num_comments|\n",
      "+-----------------+-------------------+--------------------+--------------------+-------------------+------------+\n",
      "|NoStupidQuestions|          [deleted]|Who do you call w...|           [deleted]|2022-01-22 18:14:03|           4|\n",
      "|    AmItheAsshole|          [deleted]|AITA for blowing ...|           [removed]|2022-01-22 18:14:04|           7|\n",
      "|    AmItheAsshole|       go_awaythrow|AITA if I cut my ...|           [removed]|2022-01-22 18:14:12|           1|\n",
      "|NoStupidQuestions|          [deleted]|   [deleted by user]|           [removed]|2022-01-22 18:14:16|           1|\n",
      "|           AskMen|          [deleted]|Do men actually l...|           [removed]|2022-01-22 18:14:21|           1|\n",
      "|         antiwork|        Vivid_Steel|For Those of You ...|In most states in...|2022-01-22 18:14:28|           1|\n",
      "|NoStupidQuestions|   throwaway7329173|How do I destroy ...|           [removed]|2022-01-22 18:14:29|           2|\n",
      "|NoStupidQuestions|          [deleted]|   [deleted by user]|           [removed]|2022-01-22 18:14:34|           9|\n",
      "|         antiwork|Future_Instance1150|Bank of America’s...|                    |2022-01-22 18:14:47|           3|\n",
      "|NoStupidQuestions|   DifficultContext|Do dogs recognize...|                    |2022-01-22 18:14:57|           2|\n",
      "+-----------------+-------------------+--------------------+--------------------+-------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "submissions.select(['subreddit', 'author', 'title', 'selftext', 'created_utc', 'num_comments']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+--------------------+-------------------+------------+\n",
      "|          subreddit|              author|               title|            selftext|        created_utc|num_comments|\n",
      "+-------------------+--------------------+--------------------+--------------------+-------------------+------------+\n",
      "|           antiwork|         Vivid_Steel|For Those of You ...|In most states in...|2022-01-22 18:14:28|           1|\n",
      "|   unpopularopinion| ballonfightaddicted|Waking up 15-30 m...|I like waking up ...|2022-01-22 18:15:24|           5|\n",
      "|      AmItheAsshole|       geosunsetmoth|AITA for refusing...|I (NB 19) am auti...|2022-01-22 18:15:30|         425|\n",
      "|  NoStupidQuestions|           Killdreth|Can I do anything...|I don’t know why,...|2022-01-22 18:15:45|           2|\n",
      "|     TrueOffMyChest|          sadness_18|I hate people who...|I've been called ...|2022-01-22 18:15:46|           5|\n",
      "|relationship_advice|  Natural_Rabbit8936|I went thru my gi...|But I’m still in ...|2022-01-22 18:15:50|           6|\n",
      "|relationship_advice|  throwawaybrrbrrbrr|I (NB15) think my...|apologies if this...|2022-01-22 18:16:22|          25|\n",
      "|  NoStupidQuestions|           [deleted]|In basketball, wh...|I never really un...|2022-01-22 18:16:42|           9|\n",
      "|relationship_advice|          rkunreal93|How do I know If ...|Is it if  she smi...|2022-01-22 18:17:23|           4|\n",
      "|relationship_advice|Personal_Memory_5099|(20f) found out b...|throwaway because...|2022-01-22 18:17:39|           5|\n",
      "+-------------------+--------------------+--------------------+--------------------+-------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# filter out deleted/removed/empty submissions\n",
    "invalid_submissions = ['[deleted]', '[removed]', '']\n",
    "df = submissions.filter(~col('selftext').isin(invalid_submissions))\n",
    "df.select(['subreddit', 'author', 'title', 'selftext', 'created_utc', 'num_comments']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+--------------------+-------------------+------------+\n",
      "|          subreddit|              author|               title|            selftext|        created_utc|num_comments|\n",
      "+-------------------+--------------------+--------------------+--------------------+-------------------+------------+\n",
      "|           antiwork|         Vivid_Steel|For Those of You ...|in most states in...|2022-01-22 18:14:28|           1|\n",
      "|   unpopularopinion| ballonfightaddicted|Waking up 15-30 m...|i like waking up ...|2022-01-22 18:15:24|           5|\n",
      "|      AmItheAsshole|       geosunsetmoth|AITA for refusing...|i nb  am autistic...|2022-01-22 18:15:30|         425|\n",
      "|  NoStupidQuestions|           Killdreth|Can I do anything...|i don’t know why ...|2022-01-22 18:15:45|           2|\n",
      "|     TrueOffMyChest|          sadness_18|I hate people who...|ive been called c...|2022-01-22 18:15:46|           5|\n",
      "|relationship_advice|  Natural_Rabbit8936|I went thru my gi...|but i’m still in ...|2022-01-22 18:15:50|           6|\n",
      "|relationship_advice|  throwawaybrrbrrbrr|I (NB15) think my...|apologies if this...|2022-01-22 18:16:22|          25|\n",
      "|  NoStupidQuestions|           [deleted]|In basketball, wh...|i never really un...|2022-01-22 18:16:42|           9|\n",
      "|relationship_advice|          rkunreal93|How do I know If ...|is it if  she smi...|2022-01-22 18:17:23|           4|\n",
      "|relationship_advice|Personal_Memory_5099|(20f) found out b...|throwaway because...|2022-01-22 18:17:39|           5|\n",
      "+-------------------+--------------------+--------------------+--------------------+-------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# keep only alphanumeric characters and spaces\n",
    "df = df.withColumn('mono_id', F.monotonically_increasing_id())\n",
    "df = df.withColumn('selftext', F.lower(F.regexp_replace('selftext', '[\\(\\)\\{\\},.:;\\'\\\"\\?\\n\\*0-9]', '')))\n",
    "df.select(['subreddit', 'author', 'title', 'selftext', 'created_utc', 'num_comments']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "documentAssembler = DocumentAssembler().setInputCol(\"selftext\").setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"tokenized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner().pretrained(\"stopwords_iso\", \"en\").setInputCols([\"tokenized\"]).setOutputCol(\"cleaned\")\n",
    "\n",
    "stemmer = Stemmer().setInputCols([\"cleaned\"]).setOutputCol(\"stemmed\")\n",
    "\n",
    "lemmatizer = LemmatizerModel.pretrained().setInputCols([\"stemmed\"]).setOutputCol(\"lemmatized\")\n",
    "\n",
    "# countvectorizer = CountVectorizer().setInputCol(\"lemmatized\").setOutputCol(\"cv\")\n",
    "\n",
    "nlpPipeline = Pipeline(\n",
    "      stages = [\n",
    "          documentAssembler,\n",
    "          tokenizer,\n",
    "          stopwords_cleaner,\n",
    "          stemmer,\n",
    "          lemmatizer\n",
    "          # countvectorizer\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/opt/conda/lib/python3.10/site-packages/pyspark/jars/spark-core_2.12-3.4.0.jar) to field java.util.regex.Pattern.pattern\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    }
   ],
   "source": [
    "# fit and transform the data using the pipeline\n",
    "pipelineModel = nlpPipeline.fit(df)\n",
    "results = pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            selftext|              result|\n",
      "+--------------------+--------------------+\n",
      "|in most states in...|[state, countri, ...|\n",
      "|i like waking up ...|[like, wake, -, m...|\n",
      "|i nb  am autistic...|[nb, autist, thin...|\n",
      "|i don’t know why ...|[don’t, know, rea...|\n",
      "|ive been called c...|[iv, call, close,...|\n",
      "|but i’m still in ...|         [i’m, love]|\n",
      "|apologies if this...|[apologi, mess, i...|\n",
      "|i never really un...|[stand, shoot, go...|\n",
      "|is it if  she smi...|[smile, lot, laug...|\n",
      "|throwaway because...|[throwawai, boyfr...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# extract the result from the lemmatizer (has other unneeded data)\n",
    "results = results.withColumn('result', F.col('lemmatized').result)\n",
    "results.select('selftext', 'result').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# build the countvectorizer\n",
    "n_words = 500\n",
    "countvectorizer = CountVectorizer(vocabSize = n_words).setInputCol(\"result\").setOutputCol(\"cv\")\n",
    "\n",
    "# fit and transform the data using CV\n",
    "fitted = countvectorizer.fit(results)\n",
    "transformed = fitted.transform(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+--------------------+--------------------+--------------------+\n",
      "|mono_id|          subreddit|            selftext|              result|                  cv|\n",
      "+-------+-------------------+--------------------+--------------------+--------------------+\n",
      "|      0|           antiwork|in most states in...|[state, countri, ...|(500,[0,2,4,11,12...|\n",
      "|      1|   unpopularopinion|i like waking up ...|[like, wake, -, m...|(500,[0,1,8,35,43...|\n",
      "|      2|      AmItheAsshole|i nb  am autistic...|[nb, autist, thin...|(500,[0,1,2,4,6,7...|\n",
      "|      3|  NoStupidQuestions|i don’t know why ...|[don’t, know, rea...|(500,[0,1,3,5,8,1...|\n",
      "|      4|     TrueOffMyChest|ive been called c...|[iv, call, close,...|(500,[2,3,5,16,22...|\n",
      "|      5|relationship_advice|but i’m still in ...|         [i’m, love]|(500,[15,26],[1.0...|\n",
      "|      6|relationship_advice|apologies if this...|[apologi, mess, i...|(500,[1,3,5,7,9,1...|\n",
      "|      7|  NoStupidQuestions|i never really un...|[stand, shoot, go...|(500,[3,16,33,82,...|\n",
      "|      8|relationship_advice|is it if  she smi...|[smile, lot, laug...|(500,[39,439],[1....|\n",
      "|      9|relationship_advice|throwaway because...|[throwawai, boyfr...|(500,[2,3,4,5,11,...|\n",
      "+-------+-------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "transformed.select('mono_id', 'subreddit', 'selftext', 'result', 'cv').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|              result|                  cv|            cv_array|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[state, countri, ...|(500,[0,2,4,11,12...|[1.0, 0.0, 1.0, 0...|\n",
      "|[like, wake, -, m...|(500,[0,1,8,35,43...|[2.0, 1.0, 0.0, 0...|\n",
      "|[nb, autist, thin...|(500,[0,1,2,4,6,7...|[2.0, 2.0, 2.0, 0...|\n",
      "|[don’t, know, rea...|(500,[0,1,3,5,8,1...|[1.0, 1.0, 0.0, 1...|\n",
      "|[iv, call, close,...|(500,[2,3,5,16,22...|[0.0, 0.0, 3.0, 1...|\n",
      "|         [i’m, love]|(500,[15,26],[1.0...|[0.0, 0.0, 0.0, 0...|\n",
      "|[apologi, mess, i...|(500,[1,3,5,7,9,1...|[0.0, 1.0, 0.0, 1...|\n",
      "|[stand, shoot, go...|(500,[3,16,33,82,...|[0.0, 0.0, 0.0, 1...|\n",
      "|[smile, lot, laug...|(500,[39,439],[1....|[0.0, 0.0, 0.0, 0...|\n",
      "|[throwawai, boyfr...|(500,[2,3,4,5,11,...|[0.0, 0.0, 1.0, 5...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# make a user-defined-function to apply to the cv column to extract dense vector representations\n",
    "to_dense = F.udf(lambda v: v.toArray().tolist(), ArrayType(DoubleType()))\n",
    "\n",
    "# apply the UDF and see the result of the transformation\n",
    "transformed_array = transformed.withColumn('cv_array', to_dense('cv'))\n",
    "transformed_array.select('result', 'cv', 'cv_array').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like',\n",
       " 'feel',\n",
       " 'want',\n",
       " 'know',\n",
       " 'time',\n",
       " 'tell',\n",
       " 'get',\n",
       " 'im',\n",
       " 'think',\n",
       " 'friend']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab the sorted vocabulary from the CV model\n",
    "top_n_words = fitted.vocabulary\n",
    "top_n_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a dataframe with one column per word, with values as their frequencies within each post\n",
    "remove_cols = ['document', 'tokenized', 'cleaned', 'stemmed', 'lemmatized', 'result', 'cv']\n",
    "keep_cols = [col for col in transformed_array.columns if col not in remove_cols]\n",
    "\n",
    "word_counts_df = transformed_array.select(\n",
    "    keep_cols + [(F.col(\"cv_array\")[x]).alias('word_' + top_n_words[x]) for x in range(0, len(top_n_words))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------+---------+---------+---------+---------+--------+-------+----------+-----------+\n",
      "|          subreddit|word_like|word_feel|word_want|word_know|word_time|word_tell|word_get|word_im|word_think|word_friend|\n",
      "+-------------------+---------+---------+---------+---------+---------+---------+--------+-------+----------+-----------+\n",
      "|           antiwork|      1.0|      0.0|      1.0|      0.0|      2.0|      0.0|     0.0|    0.0|       0.0|        0.0|\n",
      "|   unpopularopinion|      2.0|      1.0|      0.0|      0.0|      0.0|      0.0|     0.0|    0.0|       1.0|        0.0|\n",
      "|      AmItheAsshole|      2.0|      2.0|      2.0|      0.0|      1.0|      0.0|     1.0|    4.0|       4.0|        0.0|\n",
      "|  NoStupidQuestions|      1.0|      1.0|      0.0|      1.0|      0.0|      1.0|     0.0|    0.0|       3.0|        0.0|\n",
      "|     TrueOffMyChest|      0.0|      0.0|      3.0|      1.0|      0.0|      1.0|     0.0|    0.0|       0.0|        0.0|\n",
      "|relationship_advice|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|     0.0|    0.0|       0.0|        0.0|\n",
      "|relationship_advice|      0.0|      1.0|      0.0|      1.0|      0.0|      2.0|     0.0|    1.0|       0.0|        2.0|\n",
      "|  NoStupidQuestions|      0.0|      0.0|      0.0|      1.0|      0.0|      0.0|     0.0|    0.0|       0.0|        0.0|\n",
      "|relationship_advice|      0.0|      0.0|      0.0|      0.0|      0.0|      0.0|     0.0|    0.0|       0.0|        0.0|\n",
      "|relationship_advice|      0.0|      0.0|      1.0|      5.0|      2.0|      3.0|     0.0|    0.0|       0.0|        0.0|\n",
      "+-------------------+---------+---------+---------+---------+---------+---------+--------+-------+----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/26 00:07:01 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "# show the result\n",
    "show_cols = ['subreddit'] + ['word_' + word for word in top_n_words[:10]]\n",
    "word_counts_df_sample = word_counts_df.select(show_cols).limit(10).cache()\n",
    "word_counts_df_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save off to CSV for visualization later\n",
    "word_counts_df_sample.toPandas().to_csv('../../data/nlp-data/full-df-cv-sample.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DF for later ML Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "word_counts_df.write.mode(\"overwrite\").parquet(\n",
    "    \"s3a://project17-bucket-alex/matt-submissions-cv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(977181, 570)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_df.count(), len(word_counts_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
