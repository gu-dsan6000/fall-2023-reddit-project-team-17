{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd55221-3271-46c8-aa98-02a85921f218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b76c7db-91bf-44c9-bb2d-b10af7cbd63b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44b1cbd3-c8a0-49f7-abe6-94d5aa855526",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==3.3.0 in c:\\users\\lando\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.3.0)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in c:\\users\\lando\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pyspark==3.3.0) (0.10.9.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup - Run only once per Kernel App\n",
    "%conda install openjdk -y\n",
    "\n",
    "# install PySpark\n",
    "%pip install pyspark==3.3.0\n",
    "\n",
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "533ca912-7eb6-4ec0-b306-947fe740cc86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9002a493-1e1d-41ec-9fcf-36e9495cbec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pyspark and build Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"PySparkApp\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.2.2\")\n",
    "    .config(\n",
    "        \"fs.s3a.aws.credentials.provider\",\n",
    "        \"com.amazonaws.auth.ContainerCredentialsProvider\",\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df3a2d43-ad92-4e78-bf35-ec13d61e2bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/fall-2023-reddit-project-team-17/code/project-ml\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2a62f35-2474-4a11-becd-81f143a5cfab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE books/\n",
      "                           PRE covid-no-stupid-questions.parquet/\n",
      "                           PRE flairs/\n",
      "                           PRE lab8/\n",
      "                           PRE matt-age-gender-sentiment/\n",
      "                           PRE matt-comment-subreddit-counts/\n",
      "                           PRE matt-submission-subreddit-counts/\n",
      "                           PRE matt-submissions-age-gender/\n",
      "                           PRE matt-submissions-cv/\n",
      "                           PRE project_2022/\n",
      "                           PRE project_2022_1/\n",
      "                           PRE project_2022_10/\n",
      "                           PRE project_2022_11/\n",
      "                           PRE project_2022_12/\n",
      "                           PRE project_2022_2/\n",
      "                           PRE project_2022_3/\n",
      "                           PRE project_2022_4/\n",
      "                           PRE project_2022_5/\n",
      "                           PRE project_2022_6/\n",
      "                           PRE project_2022_7/\n",
      "                           PRE project_2022_8/\n",
      "                           PRE project_2022_9/\n",
      "                           PRE project_jan2021/\n",
      "                           PRE spark_logs/\n",
      "                           PRE stories-and-books-nlp/\n",
      "2023-11-07 20:13:10       1216 eda_ideas.txt\n",
      "2023-11-07 20:55:17         12 hello-from-victor.txt\n",
      "2023-11-07 20:43:23         10 matt-test-file.txt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://project17-bucket-alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44cc1709-da8e-457b-8c03-e3bffe602da2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/11/30 00:06:24 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.73 ms, sys: 4.75 ms, total: 8.48 ms\n",
      "Wall time: 5.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read in data from project bucket\n",
    "bucket = \"project17-bucket-alex\"\n",
    "\n",
    "path = f\"s3a://{bucket}/covid-no-stupid-questions.parquet\"\n",
    "\n",
    "df = spark.read.parquet(path, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a3cdcb3-561b-4141-bdd6-b656218f782f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+----------------------+-----------------+--------------------+--------+----------------+-------------------+-------------+------+------+-------+------------+---------+----------+--------------------+-------------------+-----+--------+-----------------+------------+--------------------+--------------------+\n",
      "|              author|author_cakeday|author_flair_css_class|author_flair_text|                body|can_gild|controversiality|        created_utc|distinguished|edited|gilded|     id|is_submitter|  link_id| parent_id|           permalink|       retrieved_on|score|stickied|        subreddit|subreddit_id|               words|      filtered_words|\n",
      "+--------------------+--------------+----------------------+-----------------+--------------------+--------+----------------+-------------------+-------------+------+------+-------+------------+---------+----------+--------------------+-------------------+-----+--------+-----------------+------------+--------------------+--------------------+\n",
      "|             Blam320|          null|                  null|             null|Yes.  And that do...|    true|               0|2022-12-31 23:55:57|         null| false|     0|j2fx4h5|       false|t3_zy9fy4|t1_j2f0hxm|/r/NoStupidQuesti...|2023-01-06 16:14:33|    1|   false|NoStupidQuestions|    t5_2w844|[yes., , and, tha...|[yes., , doesn’t,...|\n",
      "|         Netherprcek|          null|                  null|             null|Thanks, I appreci...|    true|               0|2022-12-14 21:56:56|         null| false|     0|j08s9s2|       false|t3_zlya0l|t1_j08rjx6|/r/NoStupidQuesti...|2023-01-07 13:43:05|   23|   false|NoStupidQuestions|    t5_2w844|[thanks,, i, appr...|[thanks,, appreci...|\n",
      "|Glendathegoodwitch64|          true|                  null|             null|This is different...|    true|               0|2022-12-11 16:48:14|         null| false|     0|izsx68y|       false|t3_zie581|t1_izrfg17|/r/NoStupidQuesti...|2023-01-07 18:09:04|    2|   false|NoStupidQuestions|    t5_2w844|[this, is, differ...|[different, pande...|\n",
      "|     GratefulOctopus|          null|                  null|             null|So you could stil...|    true|               0|2022-12-11 16:48:48|         null| false|     0|izsx94g|       false|t3_ziyvlj| t3_ziyvlj|/r/NoStupidQuesti...|2023-01-07 18:09:01|    4|   false|NoStupidQuestions|    t5_2w844|[so, you, could, ...|[still, covid,, m...|\n",
      "|            slash178|          null|                  null|             null|Most democrats ar...|    true|               0|2022-12-11 16:52:12|         null| false|     0|izsxqcf|       false|t3_ziz8of| t3_ziz8of|/r/NoStupidQuesti...|2023-01-07 18:08:48|    6|   false|NoStupidQuestions|    t5_2w844|[most, democrats,...|[democrats, arent...|\n",
      "+--------------------+--------------+----------------------+-----------------+--------------------+--------+----------------+-------------------+-------------+------+------+-------+------------+---------+----------+--------------------+-------------------+-----+--------+-----------------+------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 706 µs, sys: 4.06 ms, total: 4.76 ms\n",
      "Wall time: 2.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81855fa7-26d7-474e-b127-210aaea1cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick note, I got a bit ahead of myself and already used spark.ml to tokenize and remove stopwords in the NLP portion of my work, but it should probably be in the ml section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27db868c-9ca1-480c-8e0a-e4053100be48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31275\n",
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- author_cakeday: boolean (nullable = true)\n",
      " |-- author_flair_css_class: string (nullable = true)\n",
      " |-- author_flair_text: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- can_gild: boolean (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- created_utc: timestamp (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- edited: string (nullable = true)\n",
      " |-- gilded: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- is_submitter: boolean (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- permalink: string (nullable = true)\n",
      " |-- retrieved_on: timestamp (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- stickied: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered_words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(df.count())\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f220779-7b08-45ae-9908-0766cbc8a92c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import size\n",
    "df_filtered = df.filter(size(df.filtered_words) > 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "699091f3-3984-4af3-ba1d-b30262148b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+----------------------+-----------------+--------------------+--------+----------------+-------------------+-------------+------+------+-------+------------+---------+----------+--------------------+-------------------+-----+--------+-----------------+------------+--------------------+--------------------+\n",
      "|             author|author_cakeday|author_flair_css_class|author_flair_text|                body|can_gild|controversiality|        created_utc|distinguished|edited|gilded|     id|is_submitter|  link_id| parent_id|           permalink|       retrieved_on|score|stickied|        subreddit|subreddit_id|               words|      filtered_words|\n",
      "+-------------------+--------------+----------------------+-----------------+--------------------+--------+----------------+-------------------+-------------+------+------+-------+------------+---------+----------+--------------------+-------------------+-----+--------+-----------------+------------+--------------------+--------------------+\n",
      "|       BardicLasher|          null|                  null|             null|Right. Good jobs....|    true|               0|2022-12-14 22:48:36|         null| false|     0|j08zt28|       false|t3_zm45rv|t1_j08y37o|/r/NoStupidQuesti...|2023-01-07 13:39:36|    1|   false|NoStupidQuestions|    t5_2w844|[right., good, jo...|[right., good, jo...|\n",
      "|        Wjbskinsfan|          null|                  null|             null|https://www.value...|    true|               0|2022-12-05 13:54:14|         null| false|     0|iz01pp7|       false|t3_zcn4s1|t1_iyz2qc7|/r/NoStupidQuesti...|2023-01-08 02:12:23|    2|   false|NoStupidQuestions|    t5_2w844|[https://www.valu...|[https://www.valu...|\n",
      "|         PonyBoy107|          null|                  null|             null|Man I feel like i...|    true|               0|2022-12-07 15:58:38|         null| false|     0|iz9z6b1|       false|t3_zess82|t1_iz8laed|/r/NoStupidQuesti...|2023-01-07 23:25:06|   11|   false|NoStupidQuestions|    t5_2w844|[man, i, feel, li...|[man, feel, like,...|\n",
      "|           adamcp90|          null|                  null|             null|I didn't say anyt...|    true|               1|2022-12-07 16:05:23|         null| false|     0|iza05qh|       false|t3_zf2aia|t1_iz9wyza|/r/NoStupidQuesti...|2023-01-07 23:24:40|    1|   false|NoStupidQuestions|    t5_2w844|[i, didn't, say, ...|[say, anything, f...|\n",
      "|Educational-Ad-9189|          null|                  null|             null|Of course you got...|    true|               0|2022-12-28 15:50:04|         null| false|     0|j1zikac|       false|t3_zwfugb|t1_j1yzs30|/r/NoStupidQuesti...|2023-01-06 20:44:55|    1|   false|NoStupidQuestions|    t5_2w844|[of, course, you,...|[course, got, two...|\n",
      "+-------------------+--------------+----------------------+-----------------+--------------------+--------+----------------+-------------------+-------------+------+------+-------+------------+---------+----------+--------------------+-------------------+-----+--------+-----------------+------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.count()\n",
    "df_filtered.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f2bd614-9adb-4b3a-ab31-1a2ab193c11a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- author_cakeday: boolean (nullable = true)\n",
      " |-- author_flair_css_class: string (nullable = true)\n",
      " |-- author_flair_text: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- can_gild: boolean (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- created_utc: timestamp (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- edited: string (nullable = true)\n",
      " |-- gilded: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- is_submitter: boolean (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- permalink: string (nullable = true)\n",
      " |-- retrieved_on: timestamp (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- stickied: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered_words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "216de3b4-0bf6-46c3-ae4c-25806357d53d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import month, dayofmonth, year\n",
    "\n",
    "#for eac uniqu month create 2 new df\n",
    "unique_months_years = df_filtered.select(month(\"created_utc\").alias(\"month\"), year(\"created_utc\").alias(\"year\")).distinct().collect()\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for row in unique_months_years:\n",
    "    mth, yr = row['month'], row['year']\n",
    "    \n",
    "    df_first_half = df_filtered.filter((month(df_filtered.created_utc) == mth) & (dayofmonth(df_filtered.created_utc) <= 15) & (year(df_filtered.created_utc) == yr))\n",
    "    df_second_half = df_filtered.filter((month(df_filtered.created_utc) == mth) & (dayofmonth(df_filtered.created_utc) > 15) & (year(df_filtered.created_utc) == yr))\n",
    "\n",
    "    dfs[f\"df_{yr}_{mth:02d}_1st\"] = df_first_half\n",
    "    dfs[f\"df_{yr}_{mth:02d}_2nd\"] = df_second_half\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b746b1c3-4e58-4a2d-a215-78df79993343",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'df_2022_01_1st': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_01_2nd': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_09_1st': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_09_2nd': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_04_1st': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_04_2nd': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_10_1st': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_10_2nd': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_12_1st': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_12_2nd': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_11_1st': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_11_2nd': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_03_1st': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_03_2nd': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_06_1st': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_06_2nd': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_05_1st': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_05_2nd': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_02_1st': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_02_2nd': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_08_1st': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_08_2nd': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_07_1st': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>],\n",
       " 'df_2022_07_2nd': DataFrame[author: string, author_cakeday: boolean, author_flair_css_class: string, author_flair_text: string, body: string, can_gild: boolean, controversiality: bigint, created_utc: timestamp, distinguished: string, edited: string, gilded: bigint, id: string, is_submitter: boolean, link_id: string, parent_id: string, permalink: string, retrieved_on: timestamp, score: bigint, stickied: boolean, subreddit: string, subreddit_id: string, words: array<string>, filtered_words: array<string>]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dfs))\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86caa2ee-d2e1-467f-9b2a-31360e973796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "for key, df in dfs.items():\n",
    "    dfs[key] = df.orderBy(desc(\"score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ba00841-c80f-40dd-8048-02586092a17e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+----------------------+-----------------+--------------------+--------+----------------+-------------------+-------------+-------------+------+-------+------------+---------+----------+--------------------+-------------------+-----+--------+-----------------+------------+--------------------+--------------------+\n",
      "|          author|author_cakeday|author_flair_css_class|author_flair_text|                body|can_gild|controversiality|        created_utc|distinguished|       edited|gilded|     id|is_submitter|  link_id| parent_id|           permalink|       retrieved_on|score|stickied|        subreddit|subreddit_id|               words|      filtered_words|\n",
      "+----------------+--------------+----------------------+-----------------+--------------------+--------+----------------+-------------------+-------------+-------------+------+-------+------------+---------+----------+--------------------+-------------------+-----+--------+-----------------+------------+--------------------+--------------------+\n",
      "|      ThenaCykez|          null|                  null|             null|There are two imp...|    true|               0|2022-01-09 19:31:44|         null|        false|     0|hryccby|       false|t3_rzyuz0| t3_rzyuz0|/r/NoStupidQuesti...|2022-02-21 22:28:32|  744|   false|NoStupidQuestions|    t5_2w844|[there, are, two,...|[two, implicit, p...|\n",
      "|         sanddem|          null|                  null|             null|As someone who wo...|    true|               0|2022-01-03 01:54:36|         null|        false|     0|hr0lx0n|       false|t3_ruoss6| t3_ruoss6|/r/NoStupidQuesti...|2022-02-22 19:15:14|  665|   false|NoStupidQuestions|    t5_2w844|[as, someone, who...|[someone, works, ...|\n",
      "|gracefulmunchkin|          null|                  null|             null|I was diagnosed w...|    true|               0|2022-01-03 02:49:03|         null|1.641189532E9|     0|hr0tqep|       false|t3_ruoss6| t3_ruoss6|/r/NoStupidQuesti...|2022-02-22 19:06:16|  181|   false|NoStupidQuestions|    t5_2w844|[i, was, diagnose...|[diagnosed, cance...|\n",
      "|       Fatlantis|          true|                  null|             null|Oh my god. I'm Au...|    true|               0|2022-01-03 04:06:02|         null|1.641183384E9|     0|hr1454n|       false|t3_ruoss6|t1_hr0u6ag|/r/NoStupidQuesti...|2022-02-22 18:55:42|  164|   false|NoStupidQuestions|    t5_2w844|[oh, my, god., i'...|[oh, god., austra...|\n",
      "|BooRadleysFriend|          null|                  null|             null|“For Profit” has ...|    true|               0|2022-01-03 15:57:59|         null|        false|     0|hr32lit|       false|t3_ruoss6|t1_hr2vupe|/r/NoStupidQuesti...|2022-02-22 17:42:40|  116|   false|NoStupidQuestions|    t5_2w844|[“for, profit”, h...|[“for, profit”, b...|\n",
      "+----------------+--------------+----------------------+-----------------+--------------------+--------+----------------+-------------------+-------------+-------------+------+-------+------------+---------+----------+--------------------+-------------------+-----+--------+-----------------+------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "key_1, df_1 = next(iter(dfs.items()))\n",
    "\n",
    "df_1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95ae521c-426b-49a8-af1b-acfa39f7b6c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base = \"../../data/ml-data/nsq/\"\n",
    "\n",
    "# for df_name, df in dfs.items():\n",
    "#     path = f\"{base}{df_name}.parquet\"\n",
    "#     df.write.parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f494802-fb52-4f53-8418-3df2972b4bcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_01_1st has 1231 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_01_2nd has 865 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_09_1st has 309 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_09_2nd has 468 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_04_1st has 343 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_04_2nd has 552 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_10_1st has 308 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_10_2nd has 524 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_12_1st has 379 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_12_2nd has 864 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_11_1st has 383 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_11_2nd has 516 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_03_1st has 462 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_03_2nd has 365 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_06_1st has 435 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_06_2nd has 310 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_05_1st has 286 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_05_2nd has 300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_02_1st has 814 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_02_2nd has 405 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_08_1st has 248 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_08_2nd has 382 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_07_1st has 311 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 91:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_07_2nd has 292 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#print the length of each df\n",
    "for df_name, df in dfs.items():\n",
    "    my_count = df.count()\n",
    "    print(f'{df_name} has {my_count} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58212d8d-933d-4afb-ae15-23a90f5213a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#saved my work and stopped here so I'm reloading the data\n",
    "base = \"../../data/ml-data/nsq/\"\n",
    "\n",
    "dirs = [d for d in os.listdir(base) if d.endswith('.parquet')]\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for p in dirs:\n",
    "    path = os.path.join(base, p)\n",
    "    df_name = p.split('.')[0]\n",
    "    dfs[df_name] = spark.read.parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04e371e6-6fbb-4fc0-bda3-908cfa985dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdfs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdf_2022_12_1st\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "dfs['df_2022_12_1st']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bf06982-6126-489a-b46c-09b3dbf0dbc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 130, but your input_length is only 128. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=64)\n",
      "Your max_length is set to 130, but your input_length is only 101. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, BartTokenizer\n",
    "\n",
    "# Init\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "max_tokens = 512  # Reduced max tokens\n",
    "\n",
    "summaries = {}\n",
    "\n",
    "for df_name, df in dfs.items():\n",
    "    first_body = df.select(\"body\").first()[\"body\"]\n",
    "    \n",
    "    # Check for empty text\n",
    "    if not first_body:\n",
    "        summaries[df_name] = \"Empty body text\"\n",
    "        continue\n",
    "\n",
    "    # Truncate the text more aggressively\n",
    "    tokens = tokenizer(first_body, truncation=True, max_length=max_tokens, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    truncated_text = tokenizer.decode(tokens[0])\n",
    "\n",
    "    # Summarize the truncated text\n",
    "    summary = summarizer(truncated_text, max_length=130, min_length=100, do_sample=False)[0]['summary_text']\n",
    "    summaries[df_name] = summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76e9b02f-46cf-45fe-a945-dfa89c7519ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_12_1st\n"
     ]
    }
   ],
   "source": [
    "test1_body = next(iter(dfs))\n",
    "\n",
    "print(test1_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1201f08-690d-4143-b64c-6eba19bdd81f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_12_1st: \n",
      " Carlin has drawn attention for a routine from his 1999 special, “You Are All Diseased.” He mischievously suggests that a childhood spent swimming in the polluted Hudson River was the reason he didn’t catch polio. Some viewers concluded — wrongly — that her father would have opposed coronavirus vaccines. “Everyone’s like, see? George Carlin would have been anti-vaccination,” she said. ‘I’m like, no. My dad was pro-science,. pro-rational thinking, pro-evidence-based medicine. The man was a heart\n"
     ]
    }
   ],
   "source": [
    "test1 = next(iter(summaries))\n",
    "\n",
    "print(f\"{test1}: \\n {summaries[test1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29727327-7adc-45b9-b766-6cb7080a6737",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can understand that frustration and getting tired of the cynicism or generation of toxic beliefs, but it should be noted that about that bit from his 1999 special about the immune system and all that, his family [has outright said](https://www.nytimes.com/2022/05/11/arts/george-carlin-comedy.html):\n",
      "\n",
      "&gt; Several times during the pandemic, Carlin has drawn attention for a routine from his 1999 special, “You Are All Diseased,” in which he mischievously suggests that a childhood spent swimming in the polluted Hudson River was the reason he didn’t catch polio.\n",
      "&gt; \n",
      "&gt; (“In my neighborhood, no one ever got polio,” he fulminates. “*No one*, **ever**. You know why? ’Cause *we swam in raw sewage*. It *strengthened our immune systems*. The polio never had a prayer.”)\n",
      "&gt; \n",
      "&gt; As Kelly Carlin explained, some viewers concluded — wrongly — that her father would have opposed coronavirus vaccines.\n",
      "&gt; \n",
      "&gt; “Everyone’s like, see? George Carlin would have been anti-vaccination,” she said. “And I’m like, no. My dad was pro-science, pro-rational thinking, pro-evidence-based medicine. The man was a heart patient for 30 years. When he was a kid and the polio vaccine became available, he got the polio vaccine.”\n",
      "&gt; \n",
      "&gt;...\n",
      "&gt;\n",
      "&gt; In efforts to divine his opinion, some Carlin fans pointed to a 1990 interview he gave to Larry King, when he expressed his misgivings about the crude standup of Andrew Dice Clay: “His targets are underdogs, and comedy has traditionally picked on power — people who abuse their power,” Carlin said at the time.\n",
      "&gt; \n",
      "&gt; Kelly Carlin said her father “always took the stand that more speech is better than less speech” and would have supported Chappelle’s right to perform the special. But, she added, “if you’re a comedian, you’ve got to be funny.”\n"
     ]
    }
   ],
   "source": [
    "test1_key = dfs[test1]\n",
    "\n",
    "test1_body_txt = test1_key.select(\"body\").first()[\"body\"]\n",
    "\n",
    "print(test1_body_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3bb8e4d-dbe2-46cf-bccd-d7f04273cc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336326e50e0f4f4d9961098a185bd874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/533 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9403d9239b6b4aa0a4eaa50ebbf4b8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439d08bb80c142a6b1cbfe6000573cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Initialize the FinBERT model and tokenizer\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone', num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "nlp = pipeline(\"sentiment-analysis\", model=finbert, tokenizer=tokenizer)\n",
    "\n",
    "#function to get sentiment\n",
    "def apply_sentiment_analysis(text):\n",
    "    try:\n",
    "        result = nlp(text)\n",
    "        return str(result[0]['label'])\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "apply_sentiment_analysis_udf = udf(apply_sentiment_analysis, StringType())\n",
    "\n",
    "sentiment_results = {}\n",
    "\n",
    "# Iterate over each df\n",
    "for df_name, df in dfs.items():\n",
    "    # Sample \n",
    "    sampled_df = df.sample(fraction=0.25)\n",
    "\n",
    "    # Perform sentiment analysis \n",
    "    sentiment_df = sampled_df.withColumn(\"sentiment\", apply_sentiment_analysis_udf(sampled_df[\"body\"]))\n",
    "    sentiment_results[df_name] = sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c1418c9-d332-4982-8d46-606fa1f1a315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 147:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           sentiment|\n",
      "+--------------------+\n",
      "|            Negative|\n",
      "|             Neutral|\n",
      "|             Neutral|\n",
      "|            Positive|\n",
      "|             Neutral|\n",
      "|             Neutral|\n",
      "|             Neutral|\n",
      "|             Neutral|\n",
      "|             Neutral|\n",
      "|             Neutral|\n",
      "|             Neutral|\n",
      "|             Neutral|\n",
      "|             Neutral|\n",
      "|             Neutral|\n",
      "|The size of tenso...|\n",
      "|            Positive|\n",
      "|             Neutral|\n",
      "|             Neutral|\n",
      "|             Neutral|\n",
      "|             Neutral|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "first_key = next(iter(sentiment_results))\n",
    "\n",
    "first_sentiment_df = sentiment_results[first_key]\n",
    "\n",
    "first_sentiment_df.select(\"sentiment\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "47f91970-a683-4f23-9f23-3e056e177b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  count\n",
       "0  Negative      8\n",
       "1   Neutral     60\n",
       "2  Positive      4"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distinct_sentiments = first_sentiment_df.select(\"sentiment\").distinct()\n",
    "\n",
    "sentiment_counts_df = (first_sentiment_df.filter(col(\"sentiment\").isin(valid_sentiments))\n",
    "                              .groupBy(\"sentiment\")\n",
    "                              .count()\n",
    "                              .orderBy(\"sentiment\"))\n",
    "\n",
    "sentiment_counts_pd = sentiment_counts_df.toPandas()\n",
    "\n",
    "output_directory = \"../../website-source/img/ml-plots\"\n",
    "\n",
    "output_filename = os.path.join(output_directory, \"sentiment_analysis_plot.png\")\n",
    "\n",
    "plt.savefig(output_filename, format='png')\n",
    "\n",
    "sentiment_counts_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "658dd74f-4a21-4acb-845c-36882185def0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#code for processing data was adapted with assistance from ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd420537-c9d0-4b9f-9733-bc3cac8e62a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
