{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1405a471-c3fd-47cd-9b38-60b728041350",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091a8809-54c7-4e24-baff-9fb4ca5599f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-29 23:43:16 sagemaker-studio-692960231031-wo7kgoszj2g\n",
      "2023-08-29 23:50:01 sagemaker-us-east-1-692960231031\n",
      "2023-08-30 00:34:21 vad49\n",
      "2023-09-16 16:02:10 vad49-labdata\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78bd8edb-def2-4f8d-95c2-14d9cbbeee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE mapping/\n",
      "                           PRE processed-data/\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://project17-bucket-alex/stories-and-books-nlp/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e901466e-a7b6-43c2-9b26-3d57f34fe058",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True is False: # set to true only for the first un\n",
    "    # Setup - Run only once per Kernel App\n",
    "    %conda install openjdk -y\n",
    "\n",
    "    # install PySpark\n",
    "    %pip install pyspark==3.2.0 s3fs pyarrow torch\n",
    "\n",
    "    # restart kernel\n",
    "    from IPython.core.display import HTML\n",
    "    HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e9d083-5324-40ea-8aee-3cbdbfe0ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, length, isnan, when, count, regexp_extract, weekofyear, hour, avg, to_date, unix_timestamp, lit, corr\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import boto3\n",
    "import pickle\n",
    "from io import BytesIO\n",
    "from pyspark.sql.functions import col, explode\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', 150) \n",
    "#pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db918676-d370-4796-8e76-9e1f6cfae9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.aws.credentials.provider\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/conda/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/conda/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9a8eb2d6-4ae9-4eac-8986-1380c86a13f4;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.2.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.563 in central\n",
      ":: resolution report :: resolve 397ms :: artifacts dl 36ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.563 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.2.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9a8eb2d6-4ae9-4eac-8986-1380c86a13f4\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/12ms)\n",
      "23/11/18 20:49:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/18 20:49:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/11/18 20:49:33 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.0\n"
     ]
    }
   ],
   "source": [
    "# Import pyspark and build Spark session\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"PySparkApp\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.2.2\")\n",
    "    .config(\n",
    "        \"fs.s3a.aws.credentials.provider\",\n",
    "        \"com.amazonaws.auth.ContainerCredentialsProvider\",\n",
    "    )\n",
    "    #.config(\"spark-jars-packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3\")\\\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b93534d-2ad1-4b41-8f9a-f696f7f0a794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/18 20:49:36 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                text|       custom_tokens|         text_as_int|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|       Metamorphosis|     [metamorphosis]|[29, 21, 36, 17, ...|\n",
      "|      by Franz Kafka|[by,  , franz,  ,...|[18, 41, 1, 22, 3...|\n",
      "|Translated by Dav...|[translated,  , b...|[36, 34, 17, 30, ...|\n",
      "|                   I|                 [i]|                [25]|\n",
      "|One morning, when...|[one,  , morning,...|[31, 30, 21, 1, 2...|\n",
      "|“What’s happened ...|[whats,  , happen...|[39, 24, 17, 36, ...|\n",
      "|Gregor then turne...|[gregor,  , then,...|[23, 34, 21, 23, ...|\n",
      "|“Oh, God”, he tho...|[oh, ,,  , god, ,...|[31, 24, 3, 1, 23...|\n",
      "|He slid back into...|[he,  , slid,  , ...|[24, 21, 1, 35, 2...|\n",
      "|And he looked ove...|[and,  , he,  , l...|[17, 30, 20, 1, 2...|\n",
      "|He was still hurr...|[he,  , was,  , s...|[24, 21, 1, 39, 1...|\n",
      "|The first thing h...|[the,  , first,  ...|[36, 24, 21, 1, 2...|\n",
      "|It was a simple m...|[it,  , was,  , a...|[25, 36, 1, 39, 1...|\n",
      "|The first thing h...|[the,  , first,  ...|[36, 24, 21, 1, 2...|\n",
      "|So then he tried ...|[so,  , then,  , ...|[35, 31, 1, 36, 2...|\n",
      "|It took just as m...|[it,  , took,  , ...|[25, 36, 1, 36, 3...|\n",
      "|But then he said ...|[but,  , then,  ,...|[18, 37, 36, 1, 3...|\n",
      "|When Gregor was a...|[when,  , gregor,...|[39, 24, 21, 30, ...|\n",
      "|After a while he ...|[after,  , a,  , ...|[17, 22, 36, 21, ...|\n",
      "|“Something’s fall...|[somethings,  , f...|[35, 31, 29, 21, ...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read in the data\n",
    "\n",
    "all_model_text = spark.read.parquet(\"s3a://project17-bucket-alex/stories-and-books-nlp/processed-data/\")\n",
    "\n",
    "#display(f\"shape: ({all_model_text.count()}, {len(all_model_text.columns)})\")\n",
    "all_model_text.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75ebb430-c476-424e-a1e0-cd333bfcfb90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# work on a subset of the data\n",
    "\n",
    "all_model_text = all_model_text.sample(False, 0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd04ae0-9320-478a-b37d-a26a4125fc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "783adab2-99f1-4e25-b8b8-9c36371e2522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4b909c7-0d33-4d5e-bd14-fefea6c7317d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Collect all sequences into one long sequence\n",
    "flattened_seq = all_model_text.select(\"text_as_int\").rdd.flatMap(lambda x: x[0]).collect()\n",
    "\n",
    "# Convert the flattened sequence into a PyTorch tensor\n",
    "char_dataset = torch.tensor(flattened_seq, dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bc665e2-50c7-4a38-948b-ce97ce8bc098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize a boto3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket_name = 'project17-bucket-alex'\n",
    "object_key = 'stories-and-books-nlp/mapping/char2idx.pkl'\n",
    "\n",
    "# Create a buffer\n",
    "char2idx_buffer = BytesIO()\n",
    "\n",
    "# Download the file from S3 to the buffer\n",
    "s3.download_fileobj(bucket_name, object_key, char2idx_buffer)\n",
    "\n",
    "# Set buffer's position to the start\n",
    "char2idx_buffer.seek(0)\n",
    "\n",
    "# Deserialize the file to load the char2idx dictionary\n",
    "char2idx = pickle.load(char2idx_buffer)\n",
    "\n",
    "# define the reverse too\n",
    "idx2char = {idx: char for char, idx in char2idx.items()}\n",
    "\n",
    "\n",
    "# check\n",
    "#for key, value in list(char2idx.items())[:20]:\n",
    "#    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42f25daa-2746-4c54-a60a-c63c338126a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Collect all unique tokens\n",
    "all_tokens = all_model_text.select(explode(col(\"custom_tokens\"))).distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Create the vocabulary from these tokens\n",
    "vocab = sorted(set(all_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f2a4188-c2a2-4971-aa76-50b95bc25132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define sequences\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(char_dataset) // (seq_length + 1)\n",
    "\n",
    "\n",
    "# create the dataset\n",
    "#char_dataset = torch.tensor(text_as_int, dtype=torch.long)\n",
    "\n",
    "sequences = []\n",
    "targets = []\n",
    "for i in range(0, len(char_dataset) - seq_length, seq_length):\n",
    "    sequences.append(char_dataset[i:i+seq_length])\n",
    "    targets.append(char_dataset[i+1:i+seq_length+1])\n",
    "\n",
    "dataset = TensorDataset(torch.stack(sequences), torch.stack(targets))\n",
    "\n",
    "\n",
    "\n",
    "# split it\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "# turn into dataloader\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f448df4-6ec9-4417-8e36-0160a441699c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        \n",
    "        # output\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f4984bf-a4f2-4705-8c46-82a285c7651b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(8269, 128)\n",
       "  (rnn): LSTM(128, 256, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=8269, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of parameters: 4105165\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# hyperparameters\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "\n",
    "# instantiate\n",
    "model = RNN(vocab_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "\n",
    "display(model)\n",
    "\n",
    "\n",
    "total_params = count_parameters(model)\n",
    "print(f'total number of parameters: {total_params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8f25aed-e158-4f17-b2b5-3ea99ddcc1be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/5, train loss: 3.4777, train perplexity: 32.3865, val loss: 2.9471, val perplexity: 19.0505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2/5, train loss: 2.9440, train perplexity: 18.9915, val loss: 2.9387, val perplexity: 18.8917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3/5, train loss: 2.9246, train perplexity: 18.6266, val loss: 2.9008, val perplexity: 18.1884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4/5, train loss: 2.8682, train perplexity: 17.6056, val loss: 2.8336, val perplexity: 17.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5/5, train loss: 2.8026, train perplexity: 16.4879, val loss: 2.7707, val perplexity: 15.9698\n",
      "test loss: 2.7738, test perplexity: 16.0195\n",
      "CPU times: user 6min 27s, sys: 1min 37s, total: 8min 5s\n",
      "Wall time: 8min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# training params\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "# training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    \n",
    "    # progress bar\n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # loop through data loader\n",
    "    for batch_idx, (data, target) in loop:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        output = output.permute(0, 2, 1)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # acummulate loss\n",
    "        running_train_loss += loss.item()\n",
    "        \n",
    "        # update tqdm bar\n",
    "        loop.set_description(f\"epoch [{epoch+1}/{num_epochs}]\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    # get avg loss for the epoch\n",
    "    train_loss = running_train_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_perplexity = torch.exp(torch.tensor(train_loss))\n",
    "    \n",
    "    \n",
    "    # validate\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    val_loop = tqdm(enumerate(val_loader), total=len(val_loader), leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # loop through validation\n",
    "        for batch_idx, (data, target) in val_loop:\n",
    "            \n",
    "            output = model(data)\n",
    "            output = output.permute(0, 2, 1)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            running_val_loss += loss.item()\n",
    "            \n",
    "            \n",
    "            # tqdm\n",
    "            val_loop.set_description(f\"validation epoch [{epoch+1}/{num_epochs}]\")\n",
    "            val_loop.set_postfix(val_loss=loss.item())\n",
    "    \n",
    "    \n",
    "    # get avg loss for the epoch\n",
    "    val_loss = running_val_loss / len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_perplexity = torch.exp(torch.tensor(val_loss))\n",
    "    \n",
    "    # report\n",
    "    print(f\"epoch {epoch+1}/{num_epochs}, train loss: {train_loss:.4f}, train perplexity: {train_perplexity:.4f}, val loss: {val_loss:.4f}, val perplexity: {val_perplexity:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# eval\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        \n",
    "        output = model(data)\n",
    "        output = output.permute(0, 2, 1)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        \n",
    "test_loss /= len(test_loader)\n",
    "\n",
    "# perplexity\n",
    "test_perplexity = torch.exp(torch.tensor(test_loss))\n",
    "\n",
    "\n",
    "# report\n",
    "print(f\"test loss: {test_loss:.4f}, test perplexity: {test_perplexity:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d84c355f-595c-43f7-a8f5-597fe963b09b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, length, temperature=1.0):\n",
    "\n",
    "    \n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Convert start_string characters to indices\n",
    "    input_eval = [char2idx.get(s, char2idx['UNK']) for s in start_string]\n",
    "    input_eval = torch.tensor(input_eval, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    generated_text = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(length):\n",
    "            output = model(input_eval)\n",
    "            output = output[:, -1, :] / temperature\n",
    "            probabilities = F.softmax(output, dim=-1)\n",
    "            predicted_id = torch.multinomial(probabilities, num_samples=1)\n",
    "\n",
    "            # Append to the input for the next character prediction\n",
    "            input_eval = torch.cat([input_eval, predicted_id], dim=1)\n",
    "\n",
    "            generated_text.append(idx2char[predicted_id.item()])\n",
    "\n",
    "    return start_string + ''.join(generated_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e73f8f8-4d6b-47bf-842e-d86aad5de220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a timed twkaafdh wtlg t ,eob pius l d!er rd, h oen n,aute velrawcrled udog ui cavtr neuhelerh  lh. rotgrah\n"
     ]
    }
   ],
   "source": [
    "#  usage\n",
    "prompt = \"Once upon a time\"\n",
    "generated = generate_text(model, prompt, 100)  # Generates 100 characters\n",
    "print(generated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40784a97-eb71-4e8e-aee0-d0898a209767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
