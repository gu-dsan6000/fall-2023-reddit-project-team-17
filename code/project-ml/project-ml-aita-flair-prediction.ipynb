{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c824ebc-31c5-4c6d-bd3d-82b7370f6bdd",
   "metadata": {},
   "source": [
    "# Flair Prediction for r/AmItheAsshole\n",
    "\n",
    "This notebook works through the application of machine learning classification models to attempt to predict the flairs of posts in r/AmItheAsshole (r/AITA) based on their CountVectorized text content.\n",
    "\n",
    "Session setup is done below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b1874d-8384-473a-b434-25c89157e9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.10.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.10.0\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyspark==3.4.0 in /opt/conda/lib/python3.10/site-packages (3.4.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark==3.4.0) (0.10.9.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spark-nlp==5.1.3 in /opt/conda/lib/python3.10/site-packages (5.1.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup - Run only once per Kernel App\n",
    "%conda install openjdk -y\n",
    "\n",
    "# install PySpark\n",
    "%pip install pyspark==3.4.0\n",
    "\n",
    "# install spark-nlp\n",
    "%pip install spark-nlp==5.1.3\n",
    "\n",
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51971cfb-090d-478d-a93d-4dc0e187b4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6be99374-89e1-49fd-b5d9-e0a715683919",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier#, MultilayerPerceptronClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import pyspark.sql.functions as F\n",
    "from sparknlp.base import *\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.annotator import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from pyspark.sql.functions import col, when\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0ee6e29-98a9-4fdb-b266-fa58f3fc2f97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.aws.credentials.provider\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/conda/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-dbe30aa1-52f9-4885-acfa-9a41f9701cc3;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.2.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.563 in central\n",
      ":: resolution report :: resolve 398ms :: artifacts dl 23ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.563 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.2.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-dbe30aa1-52f9-4885-acfa-9a41f9701cc3\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/11ms)\n",
      "23/11/28 17:46:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Import pyspark and build Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"32G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.2.2\")\\\n",
    "    .config(\"fs.s3a.aws.credentials.provider\", \"com.amazonaws.auth.ContainerCredentialsProvider\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcca11a1-443a-44e2-ba8a-db881d8b5124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.4.0\n",
      "sparknlp version: 5.1.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"sparknlp version: {sparknlp.version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e00fbdb-face-4d28-b02f-7e2b2a8f13d5",
   "metadata": {},
   "source": [
    "## Reading in the Data\n",
    "\n",
    "Below, the CountVectorized data of text submissions are read in, then filtered to only posts in r/AITA with one of the 4 primary flairs attached (i.e., what we are trying to predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7c4796-37bf-4e51-a81e-11fbd3a53b72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/28 17:46:16 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "23/11/28 17:46:24 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+--------------------+-------------------+------------+---------------+\n",
      "|    subreddit|              author|               title|            selftext|        created_utc|num_comments|link_flair_text|\n",
      "+-------------+--------------------+--------------------+--------------------+-------------------+------------+---------------+\n",
      "|AmItheAsshole|         Squeakitout|AITA for being pi...|my boyfriendmand ...|2022-03-18 00:34:50|          24| Everyone Sucks|\n",
      "|AmItheAsshole| Foreign_Quarter8959|WIBTA if I don't ...|so if have been d...|2022-03-18 00:35:50|          28|No A-holes here|\n",
      "|AmItheAsshole|         100000nopes|AITA for giving a...|i moved into a qu...|2022-03-18 00:38:16|          19| Not the A-hole|\n",
      "|AmItheAsshole|      MonkeyBeBoolin|AITA for leaving ...|tldr i live with ...|2022-03-18 00:39:29|         107| Not the A-hole|\n",
      "|AmItheAsshole|Potential-Persimmon3|AITA for wanting ...|for background i’...|2022-03-18 00:44:07|          25| Not the A-hole|\n",
      "|AmItheAsshole| Upset_Mechanic_5544|AITA for telling ...|i’m in a friend g...|2022-03-18 00:53:44|          22| Not the A-hole|\n",
      "|AmItheAsshole|    bionicalseahorse|AITA for wanting ...|so i f haven’t sa...|2022-03-18 01:00:12|          16| Not the A-hole|\n",
      "|AmItheAsshole|     baileythekiller|AITA for refusing...|yup its exactly a...|2022-03-18 01:01:23|         601| Not the A-hole|\n",
      "|AmItheAsshole|            Jenius52|AITA for thinking...|if love my mom a ...|2022-03-18 01:05:02|          10| Not the A-hole|\n",
      "|AmItheAsshole|       Jellyandbwead|AITA- I got Mad A...|im a minor and my...|2022-03-18 01:05:19|          15|        Asshole|\n",
      "|AmItheAsshole|  Extension-Shock-19|AITA for moving o...|aita for moving o...|2022-03-18 01:06:18|          15| Not the A-hole|\n",
      "|AmItheAsshole|      TrenchcoatMice|AITA for not want...|my  nby journalis...|2022-03-18 01:08:53|          20| Not the A-hole|\n",
      "|AmItheAsshole|        Fearless0394|WIBTA for calling...|my ex and i share...|2022-03-02 02:51:36|          15| Not the A-hole|\n",
      "|AmItheAsshole|Infinite-Shower-8227|AITA for not text...|my fiancé has alw...|2022-03-02 02:55:36|          67|        Asshole|\n",
      "|AmItheAsshole|    btb-throwaway422|WIBTA for not wan...|my friend is gett...|2022-03-02 03:12:47|         140| Not the A-hole|\n",
      "|AmItheAsshole|      joke_not_found|WIBTA for telling...|i m have been goi...|2022-03-02 03:13:02|          14|        Asshole|\n",
      "|AmItheAsshole|     Buttercuptrilll|AITA for not want...|i f am currently ...|2022-03-02 03:16:35|         106| Not the A-hole|\n",
      "|AmItheAsshole|Different_Breath5730|AITA for getting ...|to put this into ...|2022-03-02 03:21:35|          11| Not the A-hole|\n",
      "|AmItheAsshole|     freddyfazzballs|AITA for telling ...|so im going to tr...|2022-03-02 03:25:13|          15|No A-holes here|\n",
      "|AmItheAsshole|  West_Apartment5458|AITA for wanting ...|i m have been pla...|2022-03-02 03:30:21|          52| Not the A-hole|\n",
      "+-------------+--------------------+--------------------+--------------------+-------------------+------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:====================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the subsetted submissions dataframe of appropriately flaired posts is 110,386x570\n",
      "CPU times: user 46.8 ms, sys: 5.29 ms, total: 52.1 ms\n",
      "Wall time: 32.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read in data from project bucket\n",
    "bucket = \"project17-bucket-alex\"\n",
    "directory = \"matt-submissions-cv\"\n",
    "\n",
    "s3_path = f\"s3a://{bucket}/{directory}\"\n",
    "submissions_cv = spark.read.parquet(s3_path, header = True)\n",
    "# Here we subset the submissions to only include posts from r/AmItheAsshole for the subsequent analysis\n",
    "raw_aita = submissions_cv.filter(F.col('subreddit') == \"AmItheAsshole\")\n",
    "\n",
    "# filter submissions to remove deleted/removed posts\n",
    "aita = raw_aita.filter((F.col('selftext') != '[removed]') & (F.col('selftext') != '[deleted]' ))\n",
    "\n",
    "# Filter submissions to only include posts tagged with the 4 primary flairs\n",
    "acceptable_flairs = ['Everyone Sucks', 'Not the A-hole', 'No A-holes here', 'Asshole']\n",
    "df_flairs = aita.where(F.col('link_flair_text').isin(acceptable_flairs))\n",
    "df_flairs.select(\"subreddit\", \"author\", \"title\", \"selftext\", \"created_utc\", \"num_comments\", \"link_flair_text\").show()\n",
    "print(f\"shape of the subsetted submissions dataframe of appropriately flaired posts is {df_flairs.count():,}x{len(df_flairs.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4b00a-e613-45fa-9edb-983e9f5b3c60",
   "metadata": {},
   "source": [
    "Next, we look at a small sample of the words in the vocabulary that will be used to predict the flairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d936f674-d682-4953-8778-c56bccb5dab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First ten vocabulary words: like, feel, want, know, time, tell, get, im, think, friend\n"
     ]
    }
   ],
   "source": [
    "# extract vocabulary from dataframe\n",
    "word_cols = [col for col in df_flairs.columns if 'word_' in col]\n",
    "vocabulary = [word.replace('word_', '') for word in word_cols]\n",
    "\n",
    "# print the first ten vocabulary words\n",
    "print(f\"First ten vocabulary words: {', '.join(vocabulary[:10])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1979a-63c5-4686-9cd1-1b705fb43c31",
   "metadata": {},
   "source": [
    "From this from this vocabulary and word columns, we can establish a SparkML pipeline an employ a multi-class classification model to predict the flairs associated with each subreddit. We have an unbalanced dataset where the flair Not the A-hole is overrepresented, so we will use a weight column to account for this to ensure more accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "368ff6a9-f4e5-4dfe-a827-357d43817f10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Find weights of classes depending on their prevalence in the original dataset\n",
    "class_counts = df_flairs.groupBy(\"link_flair_text\").count().collect()\n",
    "total_count = df_flairs.count()\n",
    "class_weights = {row[\"link_flair_text\"]: total_count / (row[\"count\"] * len(class_counts)) for row in class_counts}\n",
    "\n",
    "# Add a new column for class weights\n",
    "df_flairs = df_flairs.withColumn(\"class_weight\", when(col('link_flair_text') == 'Not the A-hole', class_weights['Not the A-hole'])\n",
    "                                 .when(col('link_flair_text') == 'Everyone Sucks', class_weights['Everyone Sucks'])\n",
    "                                 .when(col('link_flair_text') == 'Asshole', class_weights['Asshole'])\n",
    "                                 .otherwise(class_weights['No A-holes here']))\n",
    "\n",
    "\n",
    "# Add a new column to the existing dataframe with class weights\n",
    "#for label, weight in class_weights.items():\n",
    "#    df_flairs = df_flairs.withColumn(\"classWeight\", F.when(F.col(\"link_flair_text\") == label, weight).otherwise(F.col(\"classWeight\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6fea4a0-8b7b-42b2-864e-3c36bbabdf40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, test_data = df_flairs.randomSplit([0.8, 0.2], 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fa4e330-5bc3-4192-90bb-e5eda77f507f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.1 ms, sys: 9.18 ms, total: 27.3 ms\n",
      "Wall time: 13.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stringIndexer_flair = StringIndexer(inputCol = \"link_flair_text\", outputCol = \"flair_idx\")\n",
    "subreddit_labels = stringIndexer_flair.fit(df_flairs).labels\n",
    "#print(subreddit_labels)\n",
    "# create a vector assembler with the appropriate input variables\n",
    "vectorAssembler_features = VectorAssembler(\n",
    "    inputCols = word_cols, \n",
    "    outputCol = 'input_features')\n",
    "# create the random forest classification model\n",
    "model = RandomForestClassifier(\n",
    "    labelCol = 'flair_idx',\n",
    "    featuresCol = 'input_features',\n",
    "    numTrees = 50,\n",
    "    weightCol = \"class_weight\")\n",
    "# create a label converter to bring the numeric predictions back to string labels\n",
    "labelConverter = IndexToString(\n",
    "    inputCol = 'prediction', \n",
    "    outputCol = 'predicted_flair', \n",
    "    labels = subreddit_labels)\n",
    "# create the pipline with appropriate stages\n",
    "pipeline_model = Pipeline(\n",
    "    stages = [stringIndexer_flair,\n",
    "              vectorAssembler_features, \n",
    "              model, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06c72f71-0de7-4bad-9b33-70c7730a32f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 208 ms, sys: 48.2 ms, total: 256 ms\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fit the model\n",
    "model = pipeline_model.fit(train_data)\n",
    "                                                                                \n",
    "# transform the data by applying the model\n",
    "train_predictions = model.transform(train_data)\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ed75f-2ac6-4399-9458-23e8d5f473a9",
   "metadata": {},
   "source": [
    "Below are the calculations of metrics for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3aaf0dd7-0be5-4131-b5f5-3a8159074e76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 85.3 ms, sys: 29 ms, total: 114 ms\n",
      "Wall time: 2min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'accuracy')\n",
    "train_accuracy = evaluator.evaluate(train_predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'f1')\n",
    "train_f1 = evaluator.evaluate(train_predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'weightedPrecision')\n",
    "train_precision = evaluator.evaluate(train_predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'weightedRecall')\n",
    "train_recall = evaluator.evaluate(train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "786c54d3-3949-4d27-a87c-c4c350d5a876",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[43mtrain_accuracy\u001b[49m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining F1:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(train_f1))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Weighted Precision:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(train_precision))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy:\"+str(train_accuracy))\n",
    "print(\"Training F1:\"+str(train_f1))\n",
    "print(\"Training Weighted Precision:\"+str(train_precision))\n",
    "print(\"Training Weighted Recall:\"+str(train_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b55d19f-ce8f-4284-82d3-7a86868264ab",
   "metadata": {},
   "source": [
    "With our model constructed and fitted, we can now see how accurate it fit to and classified our testing subset of the r/AITA posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "919b5447-2523-4294-b0be-0164d22b0b73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94.8 ms, sys: 11.5 ms, total: 106 ms\n",
      "Wall time: 2min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'accuracy')\n",
    "test_accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'f1')\n",
    "test_f1 = evaluator.evaluate(predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'weightedPrecision')\n",
    "test_precision = evaluator.evaluate(predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'weightedRecall')\n",
    "test_recall = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dccd7df6-bd4a-4e59-9baa-23e6c72973d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:0.24400018010716376\n",
      "Model F1:0.3117948574507945\n",
      "Model Weighted Precision:0.679297818646778\n",
      "Model Weighted Recall:0.24400018010716376\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy:\"+str(accuracy))\n",
    "print(\"Testing F1:\"+str(f1))\n",
    "print(\"Testing Weighted Precision:\"+str(precision))\n",
    "print(\"Testing Weighted Recall:\"+str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24349a57-701f-4bc0-8f49-5eae0a30a257",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flair_pred = predictions.select(\"predicted_flair\").collect()\n",
    "flair_orig = predictions.select(\"link_flair_text\").collect()                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "746c9b07-da68-4723-9b55-aacb29a2c87e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Asshole  Everyone Sucks  No A-holes here  Not the A-hole\n",
      "Asshole              320             883             1411             465\n",
      "Everyone Sucks        96             422              227             139\n",
      "No A-holes here       79             162              655             162\n",
      "Not the A-hole      1422            5105             6639            4022\n"
     ]
    }
   ],
   "source": [
    "cm_labels = ['Asshole', 'Everyone Sucks', 'No A-holes here', 'Not the A-hole']\n",
    "cm = confusion_matrix(flair_orig, flair_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pd.DataFrame(cm, columns = cm_labels, index = cm_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439bc30e-6e7c-47e5-a011-e0fa4aa68884",
   "metadata": {
    "tags": []
   },
   "source": [
    "From the above metrics and confusion matrix, we can see that this Random Forest model does not do a very good job at predicting the flair based on the text content of the posts when accounting for the frequency of the classes. The weighted precision score is relatively good compared to the F1, accuracy, and recall scores, but the model clearly does not adequately predict the flairs well.\n",
    "\n",
    "Below, we attempt another classification model, but instead using number of comments as a predictor."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
