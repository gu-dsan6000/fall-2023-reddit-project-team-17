{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c824ebc-31c5-4c6d-bd3d-82b7370f6bdd",
   "metadata": {},
   "source": [
    "# Flair Prediction for r/AmItheAsshole\n",
    "\n",
    "This notebook works through the application of machine learning classification models to attempt to predict the flairs of posts in r/AmItheAsshole (r/AITA) based on their CountVectorized text content.\n",
    "\n",
    "Session setup is done below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b1874d-8384-473a-b434-25c89157e9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.10.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.10.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - openjdk\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.08.22 |       h06a4308_0         123 KB\n",
      "    certifi-2023.11.17         |  py310h06a4308_0         158 KB\n",
      "    openjdk-11.0.13            |       h87a67e3_0       341.0 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       341.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  openjdk            pkgs/main/linux-64::openjdk-11.0.13-h87a67e3_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2023.7.2~ --> pkgs/main::ca-certificates-2023.08.22-h06a4308_0 \n",
      "  certifi            conda-forge/noarch::certifi-2023.7.22~ --> pkgs/main/linux-64::certifi-2023.11.17-py310h06a4308_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "openjdk-11.0.13      | 341.0 MB  |                                       |   0% \n",
      "certifi-2023.11.17   | 158 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "openjdk-11.0.13      | 341.0 MB  | 3                                     |   1% \u001b[A\u001b[A\n",
      "\n",
      "ca-certificates-2023 | 123 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "ca-certificates-2023 | 123 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "certifi-2023.11.17   | 158 KB    | ##################################### | 100% \u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pyspark==3.4.0\n",
      "  Using cached pyspark-3.4.0-py2.py3-none-any.whl\n",
      "Collecting py4j==0.10.9.7 (from pyspark==3.4.0)\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting spark-nlp==5.1.3\n",
      "  Obtaining dependency information for spark-nlp==5.1.3 from https://files.pythonhosted.org/packages/cd/7d/bc0eca4c9ec4c9c1d9b28c42c2f07942af70980a7d912d0aceebf8db32dd/spark_nlp-5.1.3-py2.py3-none-any.whl.metadata\n",
      "  Using cached spark_nlp-5.1.3-py2.py3-none-any.whl.metadata (53 kB)\n",
      "Using cached spark_nlp-5.1.3-py2.py3-none-any.whl (537 kB)\n",
      "Installing collected packages: spark-nlp\n",
      "Successfully installed spark-nlp-5.1.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup - Run only once per Kernel App\n",
    "%conda install openjdk -y\n",
    "\n",
    "# install PySpark\n",
    "%pip install pyspark==3.4.0\n",
    "\n",
    "# install spark-nlp\n",
    "%pip install spark-nlp==5.1.3\n",
    "\n",
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51971cfb-090d-478d-a93d-4dc0e187b4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6be99374-89e1-49fd-b5d9-e0a715683919",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier#, MultilayerPerceptronClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import pyspark.sql.functions as F\n",
    "from sparknlp.base import *\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.annotator import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from pyspark.sql.functions import col, when\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0ee6e29-98a9-4fdb-b266-fa58f3fc2f97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.aws.credentials.provider\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/conda/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-dbed4efb-d4b8-41d5-bcd3-25bc98d8a482;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.2.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.563 in central\n",
      ":: resolution report :: resolve 470ms :: artifacts dl 19ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.563 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.2.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-dbed4efb-d4b8-41d5-bcd3-25bc98d8a482\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/14ms)\n",
      "23/11/29 15:52:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Import pyspark and build Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"32G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.2.2\")\\\n",
    "    .config(\"fs.s3a.aws.credentials.provider\", \"com.amazonaws.auth.ContainerCredentialsProvider\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcca11a1-443a-44e2-ba8a-db881d8b5124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.4.0\n",
      "sparknlp version: 5.1.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"sparknlp version: {sparknlp.version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e00fbdb-face-4d28-b02f-7e2b2a8f13d5",
   "metadata": {},
   "source": [
    "## Reading in the Data\n",
    "\n",
    "Below, the CountVectorized data of text submissions are read in, then filtered to only posts in r/AITA with one of the 4 primary flairs attached (i.e., what we are trying to predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7c4796-37bf-4e51-a81e-11fbd3a53b72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/29 15:52:40 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "23/11/29 15:52:46 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+--------------------+-------------------+------------+---------------+\n",
      "|    subreddit|              author|               title|            selftext|        created_utc|num_comments|link_flair_text|\n",
      "+-------------+--------------------+--------------------+--------------------+-------------------+------------+---------------+\n",
      "|AmItheAsshole|         Squeakitout|AITA for being pi...|my boyfriendmand ...|2022-03-18 00:34:50|          24| Everyone Sucks|\n",
      "|AmItheAsshole| Foreign_Quarter8959|WIBTA if I don't ...|so if have been d...|2022-03-18 00:35:50|          28|No A-holes here|\n",
      "|AmItheAsshole|         100000nopes|AITA for giving a...|i moved into a qu...|2022-03-18 00:38:16|          19| Not the A-hole|\n",
      "|AmItheAsshole|      MonkeyBeBoolin|AITA for leaving ...|tldr i live with ...|2022-03-18 00:39:29|         107| Not the A-hole|\n",
      "|AmItheAsshole|Potential-Persimmon3|AITA for wanting ...|for background i’...|2022-03-18 00:44:07|          25| Not the A-hole|\n",
      "|AmItheAsshole| Upset_Mechanic_5544|AITA for telling ...|i’m in a friend g...|2022-03-18 00:53:44|          22| Not the A-hole|\n",
      "|AmItheAsshole|    bionicalseahorse|AITA for wanting ...|so i f haven’t sa...|2022-03-18 01:00:12|          16| Not the A-hole|\n",
      "|AmItheAsshole|     baileythekiller|AITA for refusing...|yup its exactly a...|2022-03-18 01:01:23|         601| Not the A-hole|\n",
      "|AmItheAsshole|            Jenius52|AITA for thinking...|if love my mom a ...|2022-03-18 01:05:02|          10| Not the A-hole|\n",
      "|AmItheAsshole|       Jellyandbwead|AITA- I got Mad A...|im a minor and my...|2022-03-18 01:05:19|          15|        Asshole|\n",
      "|AmItheAsshole|  Extension-Shock-19|AITA for moving o...|aita for moving o...|2022-03-18 01:06:18|          15| Not the A-hole|\n",
      "|AmItheAsshole|      TrenchcoatMice|AITA for not want...|my  nby journalis...|2022-03-18 01:08:53|          20| Not the A-hole|\n",
      "|AmItheAsshole|        Fearless0394|WIBTA for calling...|my ex and i share...|2022-03-02 02:51:36|          15| Not the A-hole|\n",
      "|AmItheAsshole|Infinite-Shower-8227|AITA for not text...|my fiancé has alw...|2022-03-02 02:55:36|          67|        Asshole|\n",
      "|AmItheAsshole|    btb-throwaway422|WIBTA for not wan...|my friend is gett...|2022-03-02 03:12:47|         140| Not the A-hole|\n",
      "|AmItheAsshole|      joke_not_found|WIBTA for telling...|i m have been goi...|2022-03-02 03:13:02|          14|        Asshole|\n",
      "|AmItheAsshole|     Buttercuptrilll|AITA for not want...|i f am currently ...|2022-03-02 03:16:35|         106| Not the A-hole|\n",
      "|AmItheAsshole|Different_Breath5730|AITA for getting ...|to put this into ...|2022-03-02 03:21:35|          11| Not the A-hole|\n",
      "|AmItheAsshole|     freddyfazzballs|AITA for telling ...|so im going to tr...|2022-03-02 03:25:13|          15|No A-holes here|\n",
      "|AmItheAsshole|  West_Apartment5458|AITA for wanting ...|i m have been pla...|2022-03-02 03:30:21|          52| Not the A-hole|\n",
      "+-------------+--------------------+--------------------+--------------------+-------------------+------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:====================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the subsetted submissions dataframe of appropriately flaired posts is 110,386x570\n",
      "CPU times: user 38 ms, sys: 4.53 ms, total: 42.6 ms\n",
      "Wall time: 26.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read in data from project bucket\n",
    "bucket = \"project17-bucket-alex\"\n",
    "directory = \"matt-submissions-cv\"\n",
    "\n",
    "s3_path = f\"s3a://{bucket}/{directory}\"\n",
    "submissions_cv = spark.read.parquet(s3_path, header = True)\n",
    "# Here we subset the submissions to only include posts from r/AmItheAsshole for the subsequent analysis\n",
    "raw_aita = submissions_cv.filter(F.col('subreddit') == \"AmItheAsshole\")\n",
    "\n",
    "# filter submissions to remove deleted/removed posts\n",
    "aita = raw_aita.filter((F.col('selftext') != '[removed]') & (F.col('selftext') != '[deleted]' ))\n",
    "\n",
    "# Filter submissions to only include posts tagged with the 4 primary flairs\n",
    "acceptable_flairs = ['Everyone Sucks', 'Not the A-hole', 'No A-holes here', 'Asshole']\n",
    "df_flairs = aita.where(F.col('link_flair_text').isin(acceptable_flairs))\n",
    "df_flairs.select(\"subreddit\", \"author\", \"title\", \"selftext\", \"created_utc\", \"num_comments\", \"link_flair_text\").show()\n",
    "print(f\"shape of the subsetted submissions dataframe of appropriately flaired posts is {df_flairs.count():,}x{len(df_flairs.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4b00a-e613-45fa-9edb-983e9f5b3c60",
   "metadata": {},
   "source": [
    "Next, we look at a small sample of the words in the vocabulary that will be used to predict the flairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d936f674-d682-4953-8778-c56bccb5dab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First ten vocabulary words: like, feel, want, know, time, tell, get, im, think, friend\n"
     ]
    }
   ],
   "source": [
    "# extract vocabulary from dataframe\n",
    "word_cols = [col for col in df_flairs.columns if 'word_' in col]\n",
    "vocabulary = [word.replace('word_', '') for word in word_cols]\n",
    "\n",
    "# print the first ten vocabulary words\n",
    "print(f\"First ten vocabulary words: {', '.join(vocabulary[:10])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1979a-63c5-4686-9cd1-1b705fb43c31",
   "metadata": {},
   "source": [
    "From this from this vocabulary and word columns, we can establish a SparkML pipeline an employ a multi-class classification model to predict the flairs associated with each subreddit. We have an unbalanced dataset where the flair Not the A-hole is overrepresented, so we will generate a balanced sample to account for this to ensure more accurate predictions. This resulting \"balanced\" dataframe contains about 15% of all properly flaired r/AITA posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03df046b-a2d6-4642-92d4-457455b8f47d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+-----+--------------------+-------------------+------------+---------------+\n",
      "|    subreddit|              author|               title|score|            selftext|        created_utc|num_comments|link_flair_text|\n",
      "+-------------+--------------------+--------------------+-----+--------------------+-------------------+------------+---------------+\n",
      "|AmItheAsshole|         Squeakitout|AITA for being pi...|    2|my boyfriendmand ...|2022-03-18 00:34:50|          24| Everyone Sucks|\n",
      "|AmItheAsshole| Foreign_Quarter8959|WIBTA if I don't ...|    1|so if have been d...|2022-03-18 00:35:50|          28|No A-holes here|\n",
      "|AmItheAsshole|     freddyfazzballs|AITA for telling ...|    7|so im going to tr...|2022-03-02 03:25:13|          15|No A-holes here|\n",
      "|AmItheAsshole|   Gold-Seaweed-7673|AITA for pesterin...|   22|i am a picture/me...|2022-03-12 23:23:46|         134|        Asshole|\n",
      "|AmItheAsshole|Embarrassed_Push_768|AITA For throwing...|    9|this is my first ...|2022-03-09 23:17:06|          21|        Asshole|\n",
      "|AmItheAsshole|Zealousideal-Net9939|AITA for leaving ...|    2|so i came into a ...|2022-03-09 23:19:45|          21| Not the A-hole|\n",
      "|AmItheAsshole| sprinkleofdoom12189|AITA for insultin...|   32|for starters i f ...|2022-03-18 04:36:46|          40| Not the A-hole|\n",
      "|AmItheAsshole|    Imaginary_Ad4861|WIBTA if I refere...|    6|ok i’m aware that...|2022-03-18 04:36:57|          29|        Asshole|\n",
      "|AmItheAsshole| Firm-Sprinkles-6317|AITA for Abandoni...|    5|this happened abo...|2022-03-05 21:03:23|          21|        Asshole|\n",
      "|AmItheAsshole|       Sunburst12345|AITA for eating a...|  417|i am a relatively...|2022-03-05 21:15:21|         228| Everyone Sucks|\n",
      "|AmItheAsshole|   No-Lifeguard-5479|WIBTA if I don’t ...|    4|throwaway account...|2022-03-05 21:29:13|          16|        Asshole|\n",
      "|AmItheAsshole|      chasinggardens|AITA for refusing...|   12|my wife is an imm...|2022-03-13 23:35:25|          19|No A-holes here|\n",
      "|AmItheAsshole|          bearchildd|AITA for wanting ...|    8|almost two years ...|2022-03-14 00:02:49|          19|        Asshole|\n",
      "|AmItheAsshole|          senakise09|AITA for feeling ...|    5|my brother m had ...|2022-03-27 08:44:36|          28|No A-holes here|\n",
      "|AmItheAsshole| Longjumping-Ad-5740|AITA for calling ...|    7|if you look throu...|2022-03-10 23:16:07|          12| Everyone Sucks|\n",
      "|AmItheAsshole|            Siren_95|AITA for this con...|    4|so i was just hav...|2022-03-13 18:37:12|           8| Everyone Sucks|\n",
      "|AmItheAsshole|            iffyloob|AITA if I'm not 1...| 2100|myf parent came o...|2022-03-21 05:03:31|         390| Not the A-hole|\n",
      "|AmItheAsshole|     RainbowsAreNear|AITA for feeling ...|    3|so i recently had...|2022-03-07 19:53:49|           5|No A-holes here|\n",
      "|AmItheAsshole|           Jay_Quest|AITA for getting ...|    3|context my w frie...|2022-03-07 19:58:55|           3|No A-holes here|\n",
      "|AmItheAsshole|         HyruleVolga|AITA for being ok...|    5|my m bf m quit hi...|2022-03-10 21:18:27|           9|No A-holes here|\n",
      "+-------------+--------------------+--------------------+-----+--------------------+-------------------+------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 4.88 ms, sys: 2.53 ms, total: 7.41 ms\n",
      "Wall time: 912 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "min_count = df_flairs.groupBy(\"link_flair_text\").count().agg({\"count\": \"min\"}).collect()[0][0]\n",
    "\n",
    "# Create a dataframe with an equal amount of each category\n",
    "balanced_df = df_flairs.sampleBy(\"link_flair_text\", fractions={val: min_count / df_flairs.filter(col(\"link_flair_text\") == val).count() for val in ['Asshole', 'No A-holes here', 'Everyone Sucks', 'Not the A-hole']})\n",
    "\n",
    "# Show the result\n",
    "balanced_df.select(\"subreddit\", \"author\", \"title\", \"score\", \"selftext\", \"created_utc\", \"num_comments\", \"link_flair_text\").show()\n",
    "\n",
    "### OLD CODE ###\n",
    "# Find weights of classes depending on their prevalence in the original dataset\n",
    "#class_counts = df_flairs.groupBy(\"link_flair_text\").count().collect()\n",
    "#total_count = df_flairs.count()\n",
    "#class_weights = {row[\"link_flair_text\"]: total_count / (row[\"count\"] * len(class_counts)) for row in class_counts}\n",
    "\n",
    "# Add a new column for class weights\n",
    "#df_flairs = df_flairs.withColumn(\"class_weight\", when(col('link_flair_text') == 'Not the A-hole', class_weights['Not the A-hole'])\n",
    "#                                 .when(col('link_flair_text') == 'Everyone Sucks', class_weights['Everyone Sucks'])\n",
    "#                                 .when(col('link_flair_text') == 'Asshole', class_weights['Asshole'])\n",
    "#                                 .otherwise(class_weights['No A-holes here']))\n",
    "\n",
    "\n",
    "# Add a new column to the existing dataframe with class weights\n",
    "#for label, weight in class_weights.items():\n",
    "#    df_flairs = df_flairs.withColumn(\"classWeight\", F.when(F.col(\"link_flair_text\") == label, weight).otherwise(F.col(\"classWeight\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6fea4a0-8b7b-42b2-864e-3c36bbabdf40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, test_data = balanced_df.randomSplit([0.8, 0.2], 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fa4e330-5bc3-4192-90bb-e5eda77f507f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asshole', 'Everyone Sucks', 'No A-holes here', 'Not the A-hole']\n",
      "CPU times: user 26.5 ms, sys: 395 µs, total: 26.9 ms\n",
      "Wall time: 12.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stringIndexer_flair = StringIndexer(inputCol = \"link_flair_text\", outputCol = \"flair_idx\")\n",
    "subreddit_labels = stringIndexer_flair.fit(balanced_df).labels\n",
    "print(subreddit_labels)\n",
    "# create a vector assembler with the appropriate input variables\n",
    "vectorAssembler_features = VectorAssembler(\n",
    "    inputCols = word_cols, \n",
    "    outputCol = 'input_features')\n",
    "# create the random forest classification model\n",
    "model = RandomForestClassifier(\n",
    "    labelCol = 'flair_idx',\n",
    "    featuresCol = 'input_features',\n",
    "    numTrees = 50)\n",
    "# create a label converter to bring the numeric predictions back to string labels\n",
    "labelConverter = IndexToString(\n",
    "    inputCol = 'prediction', \n",
    "    outputCol = 'predicted_flair', \n",
    "    labels = subreddit_labels)\n",
    "# create the pipline with appropriate stages\n",
    "pipeline_model = Pipeline(\n",
    "    stages = [stringIndexer_flair,\n",
    "              vectorAssembler_features, \n",
    "              model, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06c72f71-0de7-4bad-9b33-70c7730a32f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 203 ms, sys: 61.9 ms, total: 265 ms\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fit the model\n",
    "model = pipeline_model.fit(train_data)\n",
    "                                                                                \n",
    "# transform the data by applying the model\n",
    "train_predictions = model.transform(train_data)\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ed75f-2ac6-4399-9458-23e8d5f473a9",
   "metadata": {},
   "source": [
    "Below are the calculations of metrics for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3aaf0dd7-0be5-4131-b5f5-3a8159074e76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 71:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.7 ms, sys: 48.7 ms, total: 106 ms\n",
      "Wall time: 2min 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'accuracy')\n",
    "train_accuracy = evaluator.evaluate(train_predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'f1')\n",
    "train_f1 = evaluator.evaluate(train_predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'weightedPrecision')\n",
    "train_precision = evaluator.evaluate(train_predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'weightedRecall')\n",
    "train_recall = evaluator.evaluate(train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "786c54d3-3949-4d27-a87c-c4c350d5a876",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:0.4202260384558931\n",
      "Training F1:0.3827044971013094\n",
      "Training Weighted Precision:0.45925773965325956\n",
      "Training Weighted Recall:0.4202260384558931\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy:\"+str(train_accuracy))\n",
    "print(\"Training F1:\"+str(train_f1))\n",
    "print(\"Training Weighted Precision:\"+str(train_precision))\n",
    "print(\"Training Weighted Recall:\"+str(train_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b55d19f-ce8f-4284-82d3-7a86868264ab",
   "metadata": {},
   "source": [
    "With our model constructed and fitted, we can now see how accurate it fit to and classified our testing subset of the r/AITA posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "919b5447-2523-4294-b0be-0164d22b0b73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 79:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 70 ms, sys: 32.8 ms, total: 103 ms\n",
      "Wall time: 2min 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'accuracy')\n",
    "test_accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'f1')\n",
    "test_f1 = evaluator.evaluate(predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'weightedPrecision')\n",
    "test_precision = evaluator.evaluate(predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'weightedRecall')\n",
    "test_recall = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dccd7df6-bd4a-4e59-9baa-23e6c72973d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:0.32919254658385094\n",
      "Testing F1:0.2811499269831472\n",
      "Testing Weighted Precision:0.3094235533580229\n",
      "Testing Weighted Recall:0.3291925465838509\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy:\"+str(test_accuracy))\n",
    "print(\"Testing F1:\"+str(test_f1))\n",
    "print(\"Testing Weighted Precision:\"+str(test_precision))\n",
    "print(\"Testing Weighted Recall:\"+str(test_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24349a57-701f-4bc0-8f49-5eae0a30a257",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Collect data for confusion matrix plot\n",
    "train_flair_pred = train_predictions.select(\"predicted_flair\").collect()\n",
    "train_flair_orig = train_predictions.select(\"link_flair_text\").collect()                                           \n",
    "flair_pred = predictions.select(\"predicted_flair\").collect()\n",
    "flair_orig = predictions.select(\"link_flair_text\").collect()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "746c9b07-da68-4723-9b55-aacb29a2c87e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix:\n",
      "                 Asshole  Everyone Sucks  No A-holes here  Not the A-hole\n",
      "Asshole             1531             998              508             311\n",
      "Everyone Sucks       959            1977              408              81\n",
      "No A-holes here     2309             649              401              69\n",
      "Not the A-hole      1281             924             1129              91\n"
     ]
    }
   ],
   "source": [
    "cm_labels = ['Asshole', 'Everyone Sucks', 'No A-holes here', 'Not the A-hole']\n",
    "train_cm = confusion_matrix(train_flair_orig, train_flair_pred)\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(pd.DataFrame(train_cm, columns = cm_labels, index = cm_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11a4ee37-2f98-4602-ad04-f01fc38899f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Confusion Matrix:\n",
      "                 Asshole  Everyone Sucks  No A-holes here  Not the A-hole\n",
      "Asshole              416             289              168              29\n",
      "Everyone Sucks       238             388              150              36\n",
      "No A-holes here      494             165              108              22\n",
      "Not the A-hole       346             302              202              28\n"
     ]
    }
   ],
   "source": [
    "cm_labels = ['Asshole', 'Everyone Sucks', 'No A-holes here', 'Not the A-hole']\n",
    "test_cm = confusion_matrix(flair_orig, flair_pred)\n",
    "print(\"Testing Confusion Matrix:\")\n",
    "print(pd.DataFrame(test_cm, columns = cm_labels, index = cm_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e485892d-e034-4173-89b4-3381877de421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save confusion mx data to repo  \n",
    "pd.DataFrame(train_cm, columns = cm_labels, index = cm_labels).to_csv('../../data/ml-data/flair-text-cm-train.csv')\n",
    "pd.DataFrame(test_cm, columns = cm_labels, index = cm_labels).to_csv('../../data/ml-data/flair-text-cm-test.csv')\n",
    "# Save model metrics to dataframe\n",
    "model_metrics = {\"training\": [train_accuracy, train_f1, train_precision, train_recall],\n",
    "                \"test\": [test_accuracy, test_f1, test_precision, test_recall]}\n",
    "metric_df = pd.DataFrame(model_metrics, index = ['accuracy', 'f1', 'precision', 'recall'])\n",
    "metric_df.to_csv('../../data/ml-data/flair-text-model-metrics-df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd3399e-dbc3-432a-9cdd-d23b5bc2b56f",
   "metadata": {
    "tags": []
   },
   "source": [
    "From the above metrics and confusion matrix, we can see that this Random Forest model does not do a very good job at predicting the flair based on the text content of the posts when accounting for the frequency of the classes, but it still performs better than performing a purely random selection (in which case the accuracy would be 0.25). Based on the confusion matrices, we can see that the model does not predict \"Not the A-hole\" posts very well, and in turn struggles to differentiate between posts that are rated as \"Asshole\" and \"No A-holes here\". However, the model performs relatively better when predicting the flair \"Everyone Sucks\" for both the training and testing data sets. While this model is slightly better than pure random assignment of flairs, it is still not a very effective method at predicting the Reddit judgment of these posts (i.e., what flair is assigned). Visualizations related to this section are generated in a separate notebook.\n",
    "\n",
    "Below, we attempt another classification model, but instead using number of comments and post score as predictors. The order of steps is identical to the text based predictions above, but we instead look at user engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29fcebda-c478-4c06-987c-fc0205728d10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No A-holes here', 'Not the A-hole', 'Everyone Sucks', 'Asshole']\n",
      "CPU times: user 21 ms, sys: 5.8 ms, total: 26.8 ms\n",
      "Wall time: 13.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stringIndexer_flair = StringIndexer(inputCol = \"link_flair_text\", outputCol = \"flair_idx\")\n",
    "subreddit_labels = stringIndexer_flair.fit(balanced_df).labels\n",
    "print(subreddit_labels)\n",
    "# create a vector assembler with the appropriate input variables\n",
    "vectorAssembler_features = VectorAssembler(\n",
    "    inputCols = ['num_comments', 'score'], \n",
    "    outputCol = 'input_features')\n",
    "# create the random forest classification model\n",
    "model = RandomForestClassifier(\n",
    "    labelCol = 'flair_idx',\n",
    "    featuresCol = 'input_features',\n",
    "    numTrees = 50)\n",
    "# create a label converter to bring the numeric predictions back to string labels\n",
    "labelConverter = IndexToString(\n",
    "    inputCol = 'prediction', \n",
    "    outputCol = 'predicted_flair', \n",
    "    labels = subreddit_labels)\n",
    "# create the pipline with appropriate stages\n",
    "pipeline_model = Pipeline(\n",
    "    stages = [stringIndexer_flair,\n",
    "              vectorAssembler_features, \n",
    "              model, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a7d8741-2dc8-4e6c-a32a-9b027f315971",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 129 ms, sys: 31.3 ms, total: 161 ms\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fit the model\n",
    "model = pipeline_model.fit(train_data)\n",
    "                                                                                \n",
    "# transform the data by applying the model\n",
    "train_predictions = model.transform(train_data)\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b11919df-01fc-4079-8c18-48c4ee5ad6da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:=============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78.6 ms, sys: 31.7 ms, total: 110 ms\n",
      "Wall time: 2min 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'accuracy')\n",
    "train_accuracy = evaluator.evaluate(train_predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'f1')\n",
    "train_f1 = evaluator.evaluate(train_predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'weightedPrecision')\n",
    "train_precision = evaluator.evaluate(train_predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'weightedRecall')\n",
    "train_recall = evaluator.evaluate(train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6836ed6-6cdc-4042-9846-a81b8cdc5128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:0.3963784183296378\n",
      "Training F1:0.39380938939184995\n",
      "Training Weighted Precision:0.39584127929986934\n",
      "Training Weighted Recall:0.3963784183296378\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy:\"+str(train_accuracy))\n",
    "print(\"Training F1:\"+str(train_f1))\n",
    "print(\"Training Weighted Precision:\"+str(train_precision))\n",
    "print(\"Training Weighted Recall:\"+str(train_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73586779-b968-436d-aade-ed3b1383ffae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 72.1 ms, sys: 35.3 ms, total: 107 ms\n",
      "Wall time: 2min 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'accuracy')\n",
    "test_accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'f1')\n",
    "test_f1 = evaluator.evaluate(predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'weightedPrecision')\n",
    "test_precision = evaluator.evaluate(predictions)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'flair_idx',\n",
    "                                              predictionCol = 'prediction',\n",
    "                                              metricName = 'weightedRecall')\n",
    "test_recall = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a82585fa-64ad-423d-8be1-21e232e7d41a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:0.39613670133729567\n",
      "Testing F1:0.392595251057266\n",
      "Testing Weighted Precision:0.3948058303170742\n",
      "Testing Weighted Recall:0.3961367013372957\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy:\"+str(test_accuracy))\n",
    "print(\"Testing F1:\"+str(test_f1))\n",
    "print(\"Testing Weighted Precision:\"+str(test_precision))\n",
    "print(\"Testing Weighted Recall:\"+str(test_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bce1701-9c83-4877-b055-6deb35679633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Collect data for confusion matrix plot\n",
    "train_flair_pred = train_predictions.select(\"predicted_flair\").collect()\n",
    "train_flair_orig = train_predictions.select(\"link_flair_text\").collect()                                           \n",
    "flair_pred = predictions.select(\"predicted_flair\").collect()\n",
    "flair_orig = predictions.select(\"link_flair_text\").collect()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0367807-b6bb-4ab4-bfbc-36b1ab93f433",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix:\n",
      "                 Asshole  Everyone Sucks  No A-holes here  Not the A-hole\n",
      "Asshole             1609             705              468             570\n",
      "Everyone Sucks       833            1079              617             865\n",
      "No A-holes here      619            1261              802             696\n",
      "Not the A-hole       393             984             1628             401\n"
     ]
    }
   ],
   "source": [
    "cm_labels = ['Asshole', 'Everyone Sucks', 'No A-holes here', 'Not the A-hole']\n",
    "train_cm = confusion_matrix(train_flair_orig, train_flair_pred)\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(pd.DataFrame(train_cm, columns = cm_labels, index = cm_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ed79e7e-6ccd-4d48-b971-b983d9008d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Confusion Matrix:\n",
      "                 Asshole  Everyone Sucks  No A-holes here  Not the A-hole\n",
      "Asshole              406             182              101             150\n",
      "Everyone Sucks       191             280              175             197\n",
      "No A-holes here      153             317              206             167\n",
      "Not the A-hole        91             247              413              89\n"
     ]
    }
   ],
   "source": [
    "cm_labels = ['Asshole', 'Everyone Sucks', 'No A-holes here', 'Not the A-hole']\n",
    "test_cm = confusion_matrix(flair_orig, flair_pred)\n",
    "print(\"Testing Confusion Matrix:\")\n",
    "print(pd.DataFrame(test_cm, columns = cm_labels, index = cm_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0db8c9a7-81f0-47d5-b3e3-c96dd9ccfa5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save confusion mx data to repo  \n",
    "pd.DataFrame(train_cm, columns = cm_labels, index = cm_labels).to_csv('../../data/ml-data/flair-engagement-cm-train.csv')\n",
    "pd.DataFrame(test_cm, columns = cm_labels, index = cm_labels).to_csv('../../data/ml-data/flair-engagement-cm-test.csv')\n",
    "# Save model metrics to dataframe\n",
    "model_metrics = {\"training\": [train_accuracy, train_f1, train_precision, train_recall],\n",
    "                \"test\": [test_accuracy, test_f1, test_precision, test_recall]}\n",
    "metric_df = pd.DataFrame(model_metrics, index = ['accuracy', 'f1', 'precision', 'recall'])\n",
    "metric_df.to_csv('../../data/ml-data/flair-engagement-model-metrics-df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2445249c-1615-40cb-ac4a-9929998c0d21",
   "metadata": {},
   "source": [
    "Based on the model metrics and confusion matrices above, we can see that this model performs slightly better than the flair predictions based on the text content of the posts given the ~40% accuracy for both the training and test data sets. All of the model metrics for the engagement based model exceed that of the CountVectorizer/word based model. This engagement based model continues to struggle to correctly identify Not the A-hole posts, but performs reasonably well at predicting Asshole flaired posts, identifying them correctly the majority of the time. While this model still is not extremely useful given its suboptimal accuracy, it is better performing than a random guess and a word/text-based model. Visualizations of these model metrics and confusion matrices are performed in a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598dd6b0-18be-4b64-a842-5dbd440ab336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d5736-217a-46b0-877b-3b7375f6d33e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
