{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lando\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lando\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"../../data/ml-data/nsq/\"\n",
    "\n",
    "dirs = [d for d in os.listdir(base) if d.endswith('.parquet')]\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for p in dirs:\n",
    "    path = os.path.join(base, p)\n",
    "    df_name = p.split('.')[0]\n",
    "    dfs[df_name] = pd.read_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_01_1st 1231\n",
      "df_2022_01_2nd 865\n",
      "df_2022_02_1st 814\n",
      "df_2022_02_2nd 405\n",
      "df_2022_03_1st 462\n",
      "df_2022_03_2nd 365\n",
      "df_2022_04_1st 343\n",
      "df_2022_04_2nd 552\n",
      "df_2022_05_1st 286\n",
      "df_2022_05_2nd 300\n",
      "df_2022_06_1st 435\n",
      "df_2022_06_2nd 310\n",
      "df_2022_07_1st 311\n",
      "df_2022_07_2nd 292\n",
      "df_2022_08_1st 248\n",
      "df_2022_08_2nd 382\n",
      "df_2022_09_1st 309\n",
      "df_2022_09_2nd 468\n",
      "df_2022_10_1st 308\n",
      "df_2022_10_2nd 524\n",
      "df_2022_11_1st 383\n",
      "df_2022_11_2nd 516\n",
      "df_2022_12_1st 379\n",
      "df_2022_12_2nd 864\n"
     ]
    }
   ],
   "source": [
    "#print the length of every dataframe\n",
    "for k in dfs:\n",
    "    print(k, len(dfs[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_01_1st\n",
      "0    There are two implicit parts to your question....\n",
      "1    As someone who works in a pharmacy, it fucking...\n",
      "2    I was diagnosed with cancer December 2019. Sur...\n",
      "3    Oh my god. I'm Australian and I can't even fat...\n",
      "4    “For Profit” has bled into EVERY SINGLE INDUST...\n",
      "Name: body, dtype: object\n",
      "There are two implicit parts to your question.  First, you're not distinguishing between the US, and each individual state in the US, and second, you're assuming that states can ban abortion but can't require vaccination.\n",
      "\n",
      "First, each state has much greater power to regulate its citizens than the national government does.  States can require people to buy health insurance; the national government can't (and Obamacare had to be reinterpreted as a tax penalty that didn't force anyone to do anything).  States can ban alcohol; the national government can't.  The Supreme Court will be deciding whether any arm of the federal government can generally obligate vaccination, but it's undisputed that the state can (*see Jacobson v. Massachusetts*).\n",
      "\n",
      "Second, *Roe v. Wade* says that the state has an interest in prenatal life that is balanced against the health and autonomy of the mother.  *Jacobson v. Massachusetts* says that the state has a compelling interest in vaccinating against contagious diseases that overcomes the autonomy rights of the citizen.  Basically, states *can* force people to be vaccinated, much more than they can be forced to carry a pregnancy.  But vaccination mandates haven't been tried, likely because of the risk of political blowback or violence.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for df_name, df in dfs.items():\n",
    "    print(df_name)\n",
    "    first_row_body = df['body'][0]\n",
    "    #show the first 5 rows of every dataframe in 'body'\n",
    "    print(df['body'].head())\n",
    "    print(first_row_body)\n",
    "    \n",
    "    \n",
    "    i += 1\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, BartTokenizer\n",
    "\n",
    "# Init\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "max_tokens = 512  # Reduced max tokens\n",
    "\n",
    "summaries = {}\n",
    "\n",
    "rows_to_sum = 5\n",
    "\n",
    "for df_name, df in dfs.items():\n",
    "    print(df_name)\n",
    "    if len(df) < rows_to_sum:\n",
    "        summaries[df_name] = \"Number of rows is less than i\"\n",
    "        continue\n",
    "\n",
    "    for i in range(0, rows_to_sum):\n",
    "        #get body i \n",
    "        body_i = df['body'].iloc[i] if not df['body'].empty else None\n",
    "        \n",
    "        # Check for empty text\n",
    "        if not body_i:\n",
    "            summaries[df_name] = \"Empty body text\"\n",
    "            continue\n",
    "\n",
    "        # Truncate the text more aggressively\n",
    "        tokens = tokenizer(body_i, truncation=True, max_length=max_tokens, return_tensors=\"pt\")[\"input_ids\"]\n",
    "        truncated_text = tokenizer.decode(tokens[0])\n",
    "\n",
    "        #get the length of the truncated text\n",
    "        truncated_text_length = len(truncated_text)\n",
    "        #dynamically resize the summary based on length of the input body\n",
    "        min_len = min(int(truncated_text_length * 0.25), 80)\n",
    "\n",
    "        # Summarize the truncated text\n",
    "        summary = summarizer(truncated_text, max_length=min_len+50, min_length=min_len, do_sample=False)[0]['summary_text']\n",
    "        summaries[df_name] = summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2022_01_1st\n"
     ]
    }
   ],
   "source": [
    "test1_body = next(iter(dfs))\n",
    "\n",
    "print(test1_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are two implicit parts to your question.  First, you're not distinguishing between the US, and each individual state in the US, and second, you're assuming that states can ban abortion but can't require vaccination.\n",
      "\n",
      "First, each state has much greater power to regulate its citizens than the national government does.  States can require people to buy health insurance; the national government can't (and Obamacare had to be reinterpreted as a tax penalty that didn't force anyone to do anything).  States can ban alcohol; the national government can't.  The Supreme Court will be deciding whether any arm of the federal government can generally obligate vaccination, but it's undisputed that the state can (*see Jacobson v. Massachusetts*).\n",
      "\n",
      "Second, *Roe v. Wade* says that the state has an interest in prenatal life that is balanced against the health and autonomy of the mother.  *Jacobson v. Massachusetts* says that the state has a compelling interest in vaccinating against contagious diseases that overcomes the autonomy rights of the citizen.  Basically, states *can* force people to be vaccinated, much more than they can be forced to carry a pregnancy.  But vaccination mandates haven't been tried, likely because of the risk of political blowback or violence.\n",
      "---Start Summary---\n",
      "df_2022_01_1st: \n",
      " “For Profit” has bled into EVERY SINGLE INDUSTRY. Basic human needs aren’t a given anymore. The Golden era of the US is over. The pandemic has exposed all of our weaknesses and really shown the ugly teeth of capitalism. I HATE the politicians in the US congress. They’re mostly millionaires as well. It used to be the military industrial complex funneling money from taxes into the pockets of corporations and politicians. Now we have the pharmaceutical industrial complex, the financial industrial complex and the drug industrial complex.\n"
     ]
    }
   ],
   "source": [
    "test1 = next(iter(summaries))\n",
    "\n",
    "print(dfs['df_2022_01_1st']['body'][0])\n",
    "\n",
    "print(\"---Start Summary---\")\n",
    "\n",
    "print(f\"{test1}: \\n {summaries[test1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "#print the length of (dfs['df_2022_01_1st']['body'][0])\n",
    "print(len(dfs['df_2022_01_1st']['body'][0].split()))\n",
    "\n",
    "print(len(summaries[test1].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>body</th>\n",
       "      <th>can_gild</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>edited</th>\n",
       "      <th>...</th>\n",
       "      <th>permalink</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>score</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ThenaCykez</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>There are two implicit parts to your question....</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-09 19:31:44</td>\n",
       "      <td>None</td>\n",
       "      <td>false</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/NoStupidQuestions/comments/rzyuz0/serious_i...</td>\n",
       "      <td>2022-02-21 22:28:32</td>\n",
       "      <td>744</td>\n",
       "      <td>False</td>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>t5_2w844</td>\n",
       "      <td>[there, are, two, implicit, parts, to, your, q...</td>\n",
       "      <td>[two, implicit, parts, question., , first,, di...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sanddem</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>As someone who works in a pharmacy, it fucking...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-03 01:54:36</td>\n",
       "      <td>None</td>\n",
       "      <td>false</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/NoStupidQuestions/comments/ruoss6/is_the_am...</td>\n",
       "      <td>2022-02-22 19:15:14</td>\n",
       "      <td>665</td>\n",
       "      <td>False</td>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>t5_2w844</td>\n",
       "      <td>[as, someone, who, works, in, a, pharmacy,, it...</td>\n",
       "      <td>[someone, works, pharmacy,, fucking, sucks., p...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gracefulmunchkin</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I was diagnosed with cancer December 2019. Sur...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-03 02:49:03</td>\n",
       "      <td>None</td>\n",
       "      <td>1.641189532E9</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/NoStupidQuestions/comments/ruoss6/is_the_am...</td>\n",
       "      <td>2022-02-22 19:06:16</td>\n",
       "      <td>181</td>\n",
       "      <td>False</td>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>t5_2w844</td>\n",
       "      <td>[i, was, diagnosed, with, cancer, december, 20...</td>\n",
       "      <td>[diagnosed, cancer, december, 2019., surgery, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fatlantis</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Oh my god. I'm Australian and I can't even fat...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-03 04:06:02</td>\n",
       "      <td>None</td>\n",
       "      <td>1.641183384E9</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/NoStupidQuestions/comments/ruoss6/is_the_am...</td>\n",
       "      <td>2022-02-22 18:55:42</td>\n",
       "      <td>164</td>\n",
       "      <td>False</td>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>t5_2w844</td>\n",
       "      <td>[oh, my, god., i'm, australian, and, i, can't,...</td>\n",
       "      <td>[oh, god., australian, even, fathom, this., la...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BooRadleysFriend</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>“For Profit” has bled into EVERY SINGLE INDUST...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-03 15:57:59</td>\n",
       "      <td>None</td>\n",
       "      <td>false</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/NoStupidQuestions/comments/ruoss6/is_the_am...</td>\n",
       "      <td>2022-02-22 17:42:40</td>\n",
       "      <td>116</td>\n",
       "      <td>False</td>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>t5_2w844</td>\n",
       "      <td>[“for, profit”, has, bled, into, every, single...</td>\n",
       "      <td>[“for, profit”, bled, every, single, industry....</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>LordSinguloth</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>For a while they were just getting unemploymen...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-10 13:31:27</td>\n",
       "      <td>None</td>\n",
       "      <td>false</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/NoStupidQuestions/comments/s0gdbk/i_keep_he...</td>\n",
       "      <td>2022-02-21 20:12:07</td>\n",
       "      <td>-4</td>\n",
       "      <td>False</td>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>t5_2w844</td>\n",
       "      <td>[for, a, while, they, were, just, getting, une...</td>\n",
       "      <td>[getting, unemployment, government., , , nowad...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>Sexual-Thunder69</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>There has never been a better time to be alive...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-12 00:46:14</td>\n",
       "      <td>None</td>\n",
       "      <td>false</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/NoStupidQuestions/comments/s1sf24/do_you_th...</td>\n",
       "      <td>2022-02-21 15:23:04</td>\n",
       "      <td>-4</td>\n",
       "      <td>False</td>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>t5_2w844</td>\n",
       "      <td>[there, has, never, been, a, better, time, to,...</td>\n",
       "      <td>[never, better, time, alive., , global, infant...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>Ravens1112003</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Because they are still receiving pandemic rela...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-10 14:49:32</td>\n",
       "      <td>None</td>\n",
       "      <td>false</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/NoStupidQuestions/comments/s0gdbk/i_keep_he...</td>\n",
       "      <td>2022-02-21 20:01:46</td>\n",
       "      <td>-5</td>\n",
       "      <td>False</td>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>t5_2w844</td>\n",
       "      <td>[because, they, are, still, receiving, pandemi...</td>\n",
       "      <td>[still, receiving, pandemic, related, assistan...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>Jhadiro</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Nah, there are a HUGE number of people who are...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-13 15:26:52</td>\n",
       "      <td>None</td>\n",
       "      <td>false</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/NoStupidQuestions/comments/s31qa9/is_joe_ro...</td>\n",
       "      <td>2022-02-21 10:52:05</td>\n",
       "      <td>-7</td>\n",
       "      <td>False</td>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>t5_2w844</td>\n",
       "      <td>[nah,, there, are, a, huge, number, of, people...</td>\n",
       "      <td>[nah,, huge, number, people, vaccine, hesitant...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>markelorenz</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Trump acts like an arse, no doubt, but he unde...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-09 20:24:27</td>\n",
       "      <td>None</td>\n",
       "      <td>false</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/NoStupidQuestions/comments/s007ec/would_don...</td>\n",
       "      <td>2022-02-21 22:20:11</td>\n",
       "      <td>-7</td>\n",
       "      <td>False</td>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>t5_2w844</td>\n",
       "      <td>[trump, acts, like, an, arse,, no, doubt,, but...</td>\n",
       "      <td>[trump, acts, like, arse,, doubt,, undeniably,...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1231 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                author author_cakeday author_flair_css_class  \\\n",
       "0           ThenaCykez           None                   None   \n",
       "1              sanddem           None                   None   \n",
       "2     gracefulmunchkin           None                   None   \n",
       "3            Fatlantis           True                   None   \n",
       "4     BooRadleysFriend           None                   None   \n",
       "...                ...            ...                    ...   \n",
       "1226     LordSinguloth           None                   None   \n",
       "1227  Sexual-Thunder69           None                   None   \n",
       "1228     Ravens1112003           None                   None   \n",
       "1229           Jhadiro           None                   None   \n",
       "1230       markelorenz           None                   None   \n",
       "\n",
       "     author_flair_text                                               body  \\\n",
       "0                 None  There are two implicit parts to your question....   \n",
       "1                 None  As someone who works in a pharmacy, it fucking...   \n",
       "2                 None  I was diagnosed with cancer December 2019. Sur...   \n",
       "3                 None  Oh my god. I'm Australian and I can't even fat...   \n",
       "4                 None  “For Profit” has bled into EVERY SINGLE INDUST...   \n",
       "...                ...                                                ...   \n",
       "1226              None  For a while they were just getting unemploymen...   \n",
       "1227              None  There has never been a better time to be alive...   \n",
       "1228              None  Because they are still receiving pandemic rela...   \n",
       "1229              None  Nah, there are a HUGE number of people who are...   \n",
       "1230              None  Trump acts like an arse, no doubt, but he unde...   \n",
       "\n",
       "      can_gild  controversiality         created_utc distinguished  \\\n",
       "0         True                 0 2022-01-09 19:31:44          None   \n",
       "1         True                 0 2022-01-03 01:54:36          None   \n",
       "2         True                 0 2022-01-03 02:49:03          None   \n",
       "3         True                 0 2022-01-03 04:06:02          None   \n",
       "4         True                 0 2022-01-03 15:57:59          None   \n",
       "...        ...               ...                 ...           ...   \n",
       "1226      True                 0 2022-01-10 13:31:27          None   \n",
       "1227      True                 0 2022-01-12 00:46:14          None   \n",
       "1228      True                 1 2022-01-10 14:49:32          None   \n",
       "1229      True                 0 2022-01-13 15:26:52          None   \n",
       "1230      True                 0 2022-01-09 20:24:27          None   \n",
       "\n",
       "             edited  ...                                          permalink  \\\n",
       "0             false  ...  /r/NoStupidQuestions/comments/rzyuz0/serious_i...   \n",
       "1             false  ...  /r/NoStupidQuestions/comments/ruoss6/is_the_am...   \n",
       "2     1.641189532E9  ...  /r/NoStupidQuestions/comments/ruoss6/is_the_am...   \n",
       "3     1.641183384E9  ...  /r/NoStupidQuestions/comments/ruoss6/is_the_am...   \n",
       "4             false  ...  /r/NoStupidQuestions/comments/ruoss6/is_the_am...   \n",
       "...             ...  ...                                                ...   \n",
       "1226          false  ...  /r/NoStupidQuestions/comments/s0gdbk/i_keep_he...   \n",
       "1227          false  ...  /r/NoStupidQuestions/comments/s1sf24/do_you_th...   \n",
       "1228          false  ...  /r/NoStupidQuestions/comments/s0gdbk/i_keep_he...   \n",
       "1229          false  ...  /r/NoStupidQuestions/comments/s31qa9/is_joe_ro...   \n",
       "1230          false  ...  /r/NoStupidQuestions/comments/s007ec/would_don...   \n",
       "\n",
       "            retrieved_on  score stickied          subreddit subreddit_id  \\\n",
       "0    2022-02-21 22:28:32    744    False  NoStupidQuestions     t5_2w844   \n",
       "1    2022-02-22 19:15:14    665    False  NoStupidQuestions     t5_2w844   \n",
       "2    2022-02-22 19:06:16    181    False  NoStupidQuestions     t5_2w844   \n",
       "3    2022-02-22 18:55:42    164    False  NoStupidQuestions     t5_2w844   \n",
       "4    2022-02-22 17:42:40    116    False  NoStupidQuestions     t5_2w844   \n",
       "...                  ...    ...      ...                ...          ...   \n",
       "1226 2022-02-21 20:12:07     -4    False  NoStupidQuestions     t5_2w844   \n",
       "1227 2022-02-21 15:23:04     -4    False  NoStupidQuestions     t5_2w844   \n",
       "1228 2022-02-21 20:01:46     -5    False  NoStupidQuestions     t5_2w844   \n",
       "1229 2022-02-21 10:52:05     -7    False  NoStupidQuestions     t5_2w844   \n",
       "1230 2022-02-21 22:20:11     -7    False  NoStupidQuestions     t5_2w844   \n",
       "\n",
       "                                                  words  \\\n",
       "0     [there, are, two, implicit, parts, to, your, q...   \n",
       "1     [as, someone, who, works, in, a, pharmacy,, it...   \n",
       "2     [i, was, diagnosed, with, cancer, december, 20...   \n",
       "3     [oh, my, god., i'm, australian, and, i, can't,...   \n",
       "4     [“for, profit”, has, bled, into, every, single...   \n",
       "...                                                 ...   \n",
       "1226  [for, a, while, they, were, just, getting, une...   \n",
       "1227  [there, has, never, been, a, better, time, to,...   \n",
       "1228  [because, they, are, still, receiving, pandemi...   \n",
       "1229  [nah,, there, are, a, huge, number, of, people...   \n",
       "1230  [trump, acts, like, an, arse,, no, doubt,, but...   \n",
       "\n",
       "                                         filtered_words  month day  \n",
       "0     [two, implicit, parts, question., , first,, di...      1   9  \n",
       "1     [someone, works, pharmacy,, fucking, sucks., p...      1   3  \n",
       "2     [diagnosed, cancer, december, 2019., surgery, ...      1   3  \n",
       "3     [oh, god., australian, even, fathom, this., la...      1   3  \n",
       "4     [“for, profit”, bled, every, single, industry....      1   3  \n",
       "...                                                 ...    ...  ..  \n",
       "1226  [getting, unemployment, government., , , nowad...      1  10  \n",
       "1227  [never, better, time, alive., , global, infant...      1  12  \n",
       "1228  [still, receiving, pandemic, related, assistan...      1  10  \n",
       "1229  [nah,, huge, number, people, vaccine, hesitant...      1  13  \n",
       "1230  [trump, acts, like, arse,, doubt,, undeniably,...      1   9  \n",
       "\n",
       "[1231 rows x 25 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['df_2022_01_1st']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 <class 'dict'> dict_keys(['df_2022_01_1st', 'df_2022_01_2nd', 'df_2022_02_1st', 'df_2022_02_2nd', 'df_2022_03_1st', 'df_2022_03_2nd', 'df_2022_04_1st', 'df_2022_04_2nd', 'df_2022_05_1st', 'df_2022_05_2nd', 'df_2022_06_1st', 'df_2022_06_2nd', 'df_2022_07_1st', 'df_2022_07_2nd', 'df_2022_08_1st', 'df_2022_08_2nd', 'df_2022_09_1st', 'df_2022_09_2nd', 'df_2022_10_1st', 'df_2022_10_2nd', 'df_2022_11_1st', 'df_2022_11_2nd', 'df_2022_12_1st', 'df_2022_12_2nd'])\n"
     ]
    }
   ],
   "source": [
    "#print dfs size, type, and keys\n",
    "print(len(dfs), type(dfs), dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['df_2022_01_1st', 'df_2022_01_2nd', 'df_2022_02_1st', 'df_2022_02_2nd', 'df_2022_03_1st', 'df_2022_03_2nd', 'df_2022_04_1st', 'df_2022_04_2nd', 'df_2022_05_1st', 'df_2022_05_2nd', 'df_2022_06_1st', 'df_2022_06_2nd', 'df_2022_07_1st', 'df_2022_07_2nd', 'df_2022_08_1st', 'df_2022_08_2nd', 'df_2022_09_1st', 'df_2022_09_2nd', 'df_2022_10_1st', 'df_2022_10_2nd', 'df_2022_11_1st', 'df_2022_11_2nd', 'df_2022_12_1st', 'df_2022_12_2nd'])\n",
      "<class 'dict'>\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "#show summaries size, type, and keys\n",
    "print(summaries.keys())\n",
    "print(type(summaries))\n",
    "print(len(summaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Rogue to evaluate the summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'reference_summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'reference_summary'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lando\\Documents\\Georgetown\\Fall 2023\\DSAN 6000 - Big Data and Cloud Computing\\fall-2023-reddit-project-team-17\\code\\project-ml\\topic-summarization-and-sentiment.ipynb Cell 10\u001b[0m line \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lando/Documents/Georgetown/Fall%202023/DSAN%206000%20-%20Big%20Data%20and%20Cloud%20Computing/fall-2023-reddit-project-team-17/code/project-ml/topic-summarization-and-sentiment.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m generated_summary \u001b[39m=\u001b[39m summaries[df_name]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lando/Documents/Georgetown/Fall%202023/DSAN%206000%20-%20Big%20Data%20and%20Cloud%20Computing/fall-2023-reddit-project-team-17/code/project-ml/topic-summarization-and-sentiment.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Assuming each DataFrame in dfs has a column 'reference_summary' with the reference summaries\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lando/Documents/Georgetown/Fall%202023/DSAN%206000%20-%20Big%20Data%20and%20Cloud%20Computing/fall-2023-reddit-project-team-17/code/project-ml/topic-summarization-and-sentiment.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m reference_summary \u001b[39m=\u001b[39m dfs[df_name][\u001b[39m'\u001b[39;49m\u001b[39mreference_summary\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]  \u001b[39m# Adjust this line as per your DataFrame structure\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lando/Documents/Georgetown/Fall%202023/DSAN%206000%20-%20Big%20Data%20and%20Cloud%20Computing/fall-2023-reddit-project-team-17/code/project-ml/topic-summarization-and-sentiment.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Calculate ROUGE scores\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lando/Documents/Georgetown/Fall%202023/DSAN%206000%20-%20Big%20Data%20and%20Cloud%20Computing/fall-2023-reddit-project-team-17/code/project-ml/topic-summarization-and-sentiment.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m scores \u001b[39m=\u001b[39m rouge\u001b[39m.\u001b[39mget_scores(generated_summary, reference_summary)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3804\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'reference_summary'"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "rouge_scores = {}\n",
    "\n",
    "for df_name in summaries:\n",
    "    generated_summary = summaries[df_name]\n",
    "\n",
    "    # Assuming each DataFrame in dfs has a column 'reference_summary' with the reference summaries\n",
    "    reference_summary = dfs[df_name]['reference_summary'].iloc[0]  # Adjust this line as per your DataFrame structure\n",
    "\n",
    "    # Calculate ROUGE scores\n",
    "    scores = rouge.get_scores(generated_summary, reference_summary)\n",
    "    \n",
    "    # Store the scores\n",
    "    rouge_scores[df_name] = scores\n",
    "\n",
    "# Printing or processing the ROUGE scores\n",
    "for df_name, scores in rouge_scores.items():\n",
    "    print(f\"ROUGE scores for {df_name}:\")\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
