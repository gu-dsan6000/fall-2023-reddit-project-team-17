# Introduction

![Image generated with OpenAI DALL·E 3 with prompt "a group of four friends around a campfire sharing stories in modern digital illustration style"](img/website-images/front-image.png){#fig-front-image width=70%}



## The Project

Society in the social media era generates vast amounts of data and potential insights. Reddit, with its large following, candid discourse, and strong communities provides an espceially substantial opportunity to make sense of valuable data. However, understanding such a large amount of data creates a challenge because of the nuanced posts and niche communities. Our exploratory data analysis, natural language processing, and machine learning models will take multiple approaches to manage this large amount of data and generate powerful insights in the most digestible manner possible.

In this project, we dive into the intersection of story telling in Reddit and machine learning (ML). Our exploration spans various aspects from classifying posts into specific subreddits to predicting the age and gender of posters based on their language. We're also examining the influence of NSFW posts on user engagement and the correlation between post score and its comments. The project will utilize advanced Natural Language Processing (NLP) techniques to unearth trends within communities, predict post flairs, and delve into the sentiment analysis of subreddit posts. We also aim to use ML to distill meaningful insights from vast quantities of data.


We selected the following subreddits for the project:

| Subreddit               | Members       |
|---                      |---            |
| `r/relationship_advice` | 10,380,573    |
| `r/socialskills`        | 3,823,567     |
| `r/NoStupidQuestions`   | 4,066,116     |
| `r/AskMen`              | 5,763,889     |
| `r/TrueOffMyChest`      | 2,198,361     |
| `r/explainlikeimfive`   | 22,635,152    |
| `r/AITA`                | 11,969,361    |
| `r/tifu`                | 18,480,872    |
| `r/antiwork`            | 2,775,125     |
| `r/OutOfTheLoop`        | 3,234,415     |
| `r/unpopularopinion`    | 4,002,725     |
| `r/AskWomen`            | 5,519,321     |

: Shows the subreddits chosen for the projects, as well as the number of members on each as of November 23, 2023. {#tbl-subrredits-and-members}


![Shows the banner of the twelve subreddits chosen for the projects"](img/website-images/subreddit-banners.png){#fig-subreddit-banners width=100%}




## Project Goals

In this work, we explore various ideas centered around storytelling on Reddit. We subset our data only to contain high-membership storytelling subreddits detailed in @tbl-subrredits-and-members. First, we perform EDA on the data. Our first idea is to develop a new engagement metric by correlating the number of comments with post scores. Next, we compare NSFW and non-NSFW posts to assess how not-safe-for-work content affects user engagement. Another goal is to identify peak engagement times by analyzing the temporal patterns of posts. We also investigate the link between engagement and the controversial nature of comments. We then use NLP to determine the age and gender of post authors and analyze sentiments of posts in specific subreddits, like `r/AmItheA**hole`, correlating them with user engagement and post flairs. We also create feature sets using NLP for ML tasks such as predicting the subreddit a post belongs to, determining post flairs based on text content, and generating Reddit-style stories from given prompts. Finally, we summarize top comments on specific topics using a pre-trained model, evaluating the summaries with accuracy metrics.

For a complete list of analytical goals and technical proposals, see @sec-appendix-a





## Appendix A: Analytical Goals and Technical Proposals {#sec-appendix-a}

### Topics

The questions we address in this work are:


**Idea 1**

EDA

* `Business goal`: Establish a new engagement metric employing the relationship between the number of comments and the score of Reddit posts.
* `Technical approach`: We plan to analyze the relationship between the number of comments and post scores on social media platforms. This involves collecting data grouped by subreddits or similar categories and using `pyspark.sql.functions` to calculate the correlation between these two metrics. We will develop an `interaction_score` metric based on our findings, averaging the number of comments and post scores. This new metric aims to provide a unified measure of user engagement across various posts and platforms.
* For more on this goal, click [here](eda.qmd#sec-relationship-comments-score).


**Idea 2**

* `Business goal`: Assess the impact of not-safe-for-work (NSFW) content on user engagement.
* `Technical approach`: To analyze the influence of NSFW content on user engagement, we will utilize a dataset of submissions, focusing on those marked with the `over_18` flag. Considering the limited proportion of such posts, we'll create a balanced dataset by randomly selecting an equivalent number of submissions without the NSFW tag. This approach ensures a fair comparison between NSFW and non-NSFW content. We will employ the `interaction_score` from Topic 1 as a primary measure of user engagement. Our methodology includes generating a boxplot to visualize the distribution of interaction scores for both NSFW and non-NSFW posts. 
* For more on this goal, click [here](eda.qmd#sec-nsfw-content).


**Idea 3**

* `Business goal`: Identify the times of the day when posts typically receive the most engagement.
* `Technical approach`: Implement a data analysis process that focuses on understanding the temporal patterns of user engagement on social media posts. Utilize the `created_utc` column from the dataset to create two new variables: `week_of_the_year` and `hour_of_the_day`. Exclude the first two days of 2022 to maintain accurate weekly categorization, as these days are part of week 53 of 2021. Aggregate and analyze the data based on these new variables to reveal patterns in user engagement across different times of the day and weeks of the year. The outcome will be visualized through a comprehensive plot, illustrating the times when posts receive the most engagement, thus guiding content strategies for optimal post timing.
* For more on this goal, click [here](eda.qmd#sec-times-of-day).


**Idea 4**

* `Business goal`: Is there any correlation between engagement and how controversial a comment is?
* `Technical approach`: Use NLP to determine if a controversial comment is more likely to correlate with different engagement metrics. 
* For more on this goal, click [here](eda.qmd#sec-controversial-comments).


**Idea 5**

* `Business goal`: Given a textual post, extract the age and gender of the author of the post.
* `Technical approach`: Use NLP techniques to extract the age and gender of the author of a post, if available (as an example: “My brother (24M) and I (23M) went to the store…”). Use NLP techniques to construct a feature set from the textual components of a post. Again, these features may be word “dummy variables” (the existence or non-existence of a word), word counts, n-grams (sequences of `n` words), or other types of features.
* For more on this goal, click [here](nlp.qmd#sec-extracting-age-and-gender).


**Idea 6**

* `Business Goal`: Determine and analyze the sentiments of r/AmItheA**hole posts with respect to user engagement and “flairs.”
* `Technical Proposal`: Apply a pretrained sentiment model to all non empty text posts in r/AmItheAsshole created in 2022. Compare and contrast sentiments by the levels of the four primary “flairs” (Asshole, Not the A-hole, Everyone Sucks, No A-holes here) and by various measures of user engagement (e.g., number of comments). Create various visualizations displaying these comparisons and draw conclusions.
* For more on this goal, click [here](nlp.qmd#sec-flair-sentiment-model).


**Idea 7**

* `Business goal`: Create a feature set from the textual components of a Reddit post.
* `Technical approach`: Use NLP techniques, including `CountVectorizer`, to construct a feature set from the textual components of a post. These features may be word “dummy variables” (the existence or non-existence of a word), word counts, n-grams (sequences of `n` words), or other types of features.
* For more on this goal, click [here](nlp.qmd#sec-nlp-with-countvectorizer).


**Idea 8**

* `Business goal`: Given a textual post, classify the subreddit to which it belongs.
* `Technical approach`: Using a feature set as a result of NLP goals, build a multi-class classification model capable of classifying the subreddit to which a post belongs. This model must be capable of handling multiple, imbalanced classes and cannot be limited to just binary classification.
* For more on this goal, click [here](ml.qmd#sec-subreddit-prediction).


**Idea 9**

* `Business goal`: Determine/predict “flairs” of Reddit posts in r/AITA based on their text content.
* `Technical approach`: Focusing primarily on the subreddit r/AITA and its flairs (Asshole, Not the A-hole, Everyone Sucks, No A-holes here), apply NLP techniques such as tokenization on text-based submissions to extract the important contents of each post. Apply a multi-class classification model trained on labelled r/AITA posts (i.e., text posts with a flair) to predict which flair a given post will receive based on its text content. Present confusion matrices on testing dataset and identify the words/phrases most commonly associated with each flair type.
* For more on this goal, click [here](ml.qmd#sec-flair-prediction).


**Idea 10**

* `Business goal`: For a provided input prompt, generate a the text of story that can posted on Reddit.
* `Technical approach`: We will subset, preprocess, and tokenize both Reddit stories and content from externally sourced books, preparing them to be fed into a Recurrent Neural Network. Utilizing Pytorch, we aim to train the model by minimizing loss and perplexity as accuracy measures. The trained model should be capable of accepting an input prompt and generating a new story text accordingly.
* For more on this goal, click [here](ml.qmd#sec-story-generation).


**Idea 11**

* `Business goal`: Summarize top comments of interest for a particular topic using a pre-trained model
* `Technical approach`: Identify an open-source model that can accurately summarize top comments related to a particular topic of interest. Since we don't want to label summaries by hand and accuracy can be subjective, we are using an API call to GPT-4 to get reference summaries, and then with those summaries, we generate rouge 1, 2, and L scores to evaluate the model. Hyperparameters are tuned to keep both summaries close to 25% of the original text.
* For more on this goal, click [here](ml.qmd#sec-pre-trained-models).



