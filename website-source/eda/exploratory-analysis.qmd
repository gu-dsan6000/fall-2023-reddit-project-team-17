```{python}
#| echo: false

import pandas as pd
from tabulate import tabulate
import IPython.display as d
from IPython.display import display, HTML, IFrame
from IPython.display import Markdown


```

# Exploratory Analysis

## The Data Subset

We selected a subset of the data related to subreddits dedicated to storytelling during 2022. Namely, we chose the 12 subreddits `AITA`, `AskMen`, `AskWomen`, `TrueOffMyChest`, `unpopularopinion`, `tifu`, `socialskills`, `antiwork`, `relationship_advice`, `explainlikeimfive`, `OutOfTheLoop`, and `NoStupidQuestions`. The data we acquired has a shape of 3,444,283 x 68 for the submissions table and 76,503,363 x 21 for the comments table.

## External Data

We have two primary sources of external data. The first is a community members dataset detailing the number of members each of the 12 subreddits has. By combining this data into the submissions table, we will get a valuable extra data point for our analysis related to the engagement of posts. This data was collected from Reddit itself. Our second source is the text of the books Metamorphosis by Franz Kafka and The Scarlet Letter by Nathaniel Hawthorne. We aim to perform an NLP time-series sentiment analysis on these books and the most engaging long-form story posts, and by calculating the correlations, we'll be able to determine if these take the reader through a similar sentiment pattern and infer whether that is the reason for their popularity. This data was collected from Project Gutenberg. These data sources are available at [here](https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17/tree/main/data/external-data).

## Cleaning 


Our cleaning process includes removing from the `comments` database both datasets the columns that are not needed for each particular set of analyses. Also, in the `comments` table, we remove the rows where the `body` has been either removed or deleted. In the `submissions` table, we also remove where the `selftext` has been removed or deleted. The resulting rows are 977,181 for the `submissions` table and 70,594,314 for the `comments` table. 

The count of posts per each subreddit is detailed in @tbl-subreddit-counts:

```{python}
#| echo: false
#| label: tbl-subreddit-counts
#| tbl-cap-location: bottom
#| tbl-cap: Displays the count of posts in each subreddit.


df = pd.read_csv("../../data/eda-data/subreddit-counts.csv")
# format
df = df.rename(columns={"subreddit": "Subreddit", "count": "Count"})
df = df.sort_values(by="Count", ascending=False)
df['Count'] = df['Count'].astype(int)
df['Count'] = df['Count'].apply(lambda x: f"{x:,}")

# show
md = tabulate(df, headers='keys', tablefmt='pipe', showindex=False)
Markdown(md)

```




Another component of the data that we’d like to observe is how many submissions and comments we can actually extract textual information from. Below, we can see the distribution of “valid” versus “invalid” posts for each subreddit, with “invalid” posts being those that have been removed or deleted. It seems very common that posts are actually removed or deleted. @fig-validity-counts shows the count of valid comments per Subreddit:

```{python}
#| echo: false
#| label: fig-validity-counts
#| fig-cap: "Shows the count of valid status of comments per subreddit."


width_percentage = "100%"
IFrame(src='../img/eda-plots/validity-counts.html', width=width_percentage, height=500)


```




::: {.callout-note appearance="simple"}
The code used for this section is available [here](https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17/blob/main/code/project-eda/project-eda-predicting-subreddits.ipynb).
::: 


## Data transformations and additional variables 

Although we summarize the new variables below, they are are described within the EDA sections below.


* `engagements`: the sum of submissions and comments for a particular subreddit.
* `interaction_score` an equal-weighted average of the number of comments and the score in each post.
* `week_of_the_year`: created from the `created_utc` column, it describes the week of the year corresponding to the particular post's date.
* `hour_of_the_day`: created from the `created_utc` column, it describes the hour of the day corresponding to the particular post's date.



## Regex Search and Dummies

To gauge the overall engagement in the posts, we used regex to create dummy variables that indicate whether the words 'fascinating,' 'entertaining,' and 'boring' appear on a post. We then aggregated them, with the results shown in @tbl-keyword-counts:


```{python}
#| echo: false
#| label: tbl-keyword-counts
#| tbl-cap-location: bottom
#| tbl-cap: Displays the results of the dummy variable excercise using Regex.


# load
fascinating = pd.read_csv("../../data/eda-data/keyword_counts_fascinating.csv", header=None)
entertaining = pd.read_csv("../../data/eda-data/keyword_counts_entertaining.csv", header=None)
boring = pd.read_csv("../../data/eda-data/keyword_counts_boring.csv", header=None)

# use first col as key
fascinating.columns = ['count', 'fascinating']
entertaining.columns = ['count', 'entertaining']
boring.columns = ['count', 'boring']

# convert count to string
fascinating['count'] = fascinating['count'].astype(str)
entertaining['count'] = entertaining['count'].astype(str)
boring['count'] = boring['count'].astype(str)

# merge
combined = fascinating.merge(entertaining, on='count').merge(boring, on='count')

# format
combined['fascinating'] = combined['fascinating'].apply(lambda x: "{:,}".format(int(x)))
combined['entertaining'] = combined['entertaining'].apply(lambda x: "{:,}".format(int(x)))
combined['boring'] = combined['boring'].apply(lambda x: "{:,}".format(int(x)))


md = tabulate(combined, headers='keys', tablefmt='pipe', showindex=False)
Markdown(md)



```



::: {.callout-note appearance="simple"}
The code used for this section is available [here](https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17/blob/main/code/project-eda/project-eda-exploratory.ipynb).
::: 



## The relationship between the number of comments and the score of Reddit posts

The number of comments (`num_comments`) and the score of a post (`score`), which is the upvotes minus the downvotes the post has received, are ways to gauge engagement with the post. Determining whether these variables are correlated can justify their combination into an aggregate engagement metric. To do this, we group the submissions by subreddit and leverage the `corr` function from `pyspark.sql.functions`. @tbl-correlation-by-subreddit shows the results:


```{python}
#| echo: false
#| label: tbl-correlation-by-subreddit
#| tbl-cap-location: bottom
#| tbl-cap: Displays the results of the correlation calculation for number of comments and scores.



df = pd.read_csv("../../data/eda-data/correlation_by_subreddit.csv")
# format
df = df.rename(columns={"subreddit": "Subreddit", "correlation_coefficient": "Correlation Coefficient"})
df = df.sort_values(by="Correlation Coefficient", ascending=False)
df['Correlation Coefficient'] = df['Correlation Coefficient'].round(2)

# show
md = tabulate(df, headers='keys', tablefmt='pipe', showindex=False)
Markdown(md)

```




We can also visualize them separately as in @fig-mean-score-comments-by-subreddit:

![Shows the mean score comments by subreddit](../img/eda-plots/mean-score-comments-by-subreddit.png){#fig-mean-score-comments-by-subreddit}



We can see in both the table and figure that they are significantly correlated, which leads to the creation of the `interaction_score` **additional variable**. This metric is an equal-weighted average of the number of comments and the score in each post.


::: {.callout-note appearance="simple"}
The code used for this section is available [here](https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17/blob/main/code/project-eda/project-eda-exploratory.ipynb).
::: 




## The impact of not-safe-for-work (NSFW) content on user engagement.


To determine if not safe for work post affects user interactions, first, we filter the `submissions` dataset for where the `over_18` flag is true (which in this tiny percentage of them). Then, we randomly sample an equal amount of false cases, and with this, we create a small, balanced dataset with the same amount of posts flagged as NSFW as those that are not. 

We can create a boxplot with this small dataset to see the distribution. Since we know from Topic 1 that the `interaction_score` is a good gauge of overall interaction, we can plot that variable as shown in @fig-boxplot-comments-and-score:

![Shows the distribution of comments and score by `over_18` status](../img/eda-plots/boxplot-comments-and-score-by-over-18-status.png){#fig-boxplot-comments-and-score}



We can infer from the plot that NSFW content increases the engagement with the post, although more analysis will be conducted in subsequent sections.



::: {.callout-note appearance="simple"}
The code used for this section is available [here](https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17/blob/main/code/project-eda/project-eda-exploratory.ipynb).
::: 


## The times of the day when posts typically receive the most engagement.

To determine the times of day when a post typically receives the most engagement, we create two **additional variables**: `week_of_the_year` and `hour_of_the_day`, both coming from the `created_utc` column. We remove the first two days of 2022 as these would be considered part of week 53 of 2021. Then, we can group and pivot the count of our new variables, resulting in the @fig-average-comments-hour-and-week:

![Shows the average comments per hour and per week.](../img/eda-plots/average-comments-hour-and-week-data.png){#fig-average-comments-hour-and-week}


This analysis clearly shows from roughly 6:00 AM to 11:00 AM UTC (or 1:00 AM to 6:00 AM Eastern time) is low on activity in the story time subreddits.



::: {.callout-note appearance="simple"}
The code used for this section is available [here](https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17/blob/main/code/project-eda/project-eda-exploratory.ipynb).
::: 



## Subreddit community prediction

One interesting task that we have our sights set on is predicting the subreddit to which a post belongs, given the textual components of the post. In doing so, there are many components of the data that we would like to explore. For this, we also generated additional variable `engagements` as the sum of submissions and comments for a particular subreddit.

One component of the data that we’d like to look at is the distribution of subreddits among submissions and comments. In @fig-aita-counts-over-time, we can see this distribution, with many engagements coming from the `AmItheAsshole`, `relationship_advice`, and `antiwork` subreddits. These subreddits invoke a lot of engagement from other users, in the form of comments, so this level of engagement can be expected.


```{python}
#| echo: false
#| label: fig-aita-counts-over-time
#| fig-cap: "Shows the counts of subreddit engagement per month."

width_percentage = "100%"
IFrame(src='../img/eda-plots/counts-over-time.html', width=width_percentage, height=700)


```


::: {.callout-tip}
## Tip with Title

Click on the bars of each Subreddit to focus them!

:::


::: {.callout-note appearance="simple"}
The code used for this section is available [here](https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17/blob/main/code/project-eda/project-eda-predicting-subreddits.ipynb).
::: 



## Flair prediction

In this section we take a closer look at the subreddit r/AmItheAsshole (henceforth referred to as r/AITA) with the goal of both analyzing and predicting what “flair” is assigned to each post based on its text content. The exploratory segment of this analysis involves analyzing and visualizing the frequency counts of each “flair” in r/AITA for 2022.

In r/AITA, users post stories about situations in the real world where they have performed some sort of action or behaved in some certain manner, but are questioning whether their actions are good/bad, in a sense. Other users on the subreddit then comment on these story-like submissions and state whether they think the way the original poster acted was good or bad. Thus, each post is assigned a “flair” (i.e., tag) denoting the “judgment” of the post and can be any one of the following: Asshole, Not the A-hole, Everyone Sucks, and Not the A-hole. The first flair indicates the original poster acted in a reprehensible/poor manner, the second is the opposite, the third flair denotes a situation in which all parties are at fault, and the final flair indicates that no one acted in a particularly poor manner.

The number of posts that are flaired as each of the flairs in the r/AITA is show in @fig-aita-flairs-barchart:

![Shows the subreddit's flairs in barchart form.](../img/eda-plots/AITA-flairs-barchart-2022.png){#fig-aita-flairs-barchart}


@fig-aita-flairs-treemap shows the relative proportion of them:

![Shows the subreddit's flairs in treemap form.](../img/eda-plots/AITA-flairs-treemap-2022.png){#fig-aita-flairs-treemap}


As we can see, Redditors by and large “judge” the majority of original posters to be “Not the A-hole,” but there are certainly plenty of posts where the judgments resulted in different outcomes. The frequency of these flairs’ occurrences as well as the possible reasons behind these occurrences will be explored further in the NLP and ML sections.


::: {.callout-note appearance="simple"}
The code used for this section is available [here](https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17/blob/main/code/project-eda/project-eda-aita-texts.ipynb).
::: 



## NLP EDA for Emerging Trends and Controversial Comments

@fig-current-events shows a regex count of the current events per Subreddit:

![Shows the topic ocurrence counts in different subreddits.](../img/eda-plots/current-events.png){#fig-current-events}

@fig-engagement-comparison shows the performance of controversial posts:

![Shows the engagement by varying metrics.](../img/eda-plots/engagement-comparison.png){#fig-engagement-comparison}



::: {.callout-note appearance="simple"}

The code used for this section is available [here](https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17/blob/main/code/project-eda/topic_trends.ipynb) and [here](https://github.com/gu-dsan6000/fall-2023-reddit-project-team-17/blob/main/code/project-eda/engagement_sentiment_corr.ipynb).

::: 


